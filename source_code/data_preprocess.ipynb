{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "import torch.utils.data\n",
    "from torch.utils.data import DataLoader\n",
    "from torchtext import data\n",
    "import io,os\n",
    "from torch import nn\n",
    "from gensim.models import word2vec\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import visdom\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "tag_to_ix = {'start_tag':0,'stop_tag':29,'pad_tag':30}\n",
    "\n",
    "train_path = '/home/jongsu/Desktop/ijcnlp_dailydialog/train/'\n",
    "test_path = '/home/jongsu/Desktop/ijcnlp_dailydialog/test/'\n",
    "Desktop_path = '/home/jongsu/Desktop/'\n",
    "\n",
    "\n",
    "\n",
    "START_TAG = 0\n",
    "STOP_TAG = 1\n",
    "PAD_TAG = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def argmax(vec):\n",
    "    # return the argmax as a python int\n",
    "    _, idx = torch.max(vec, 1)\n",
    "    return idx.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def sent_loader(sentence): #pre_process per sentence\n",
    "    result = []\n",
    "    for elem in sentence.split(' '):\n",
    "        if elem != '':\n",
    "            result = np.append(result, elem)\n",
    "    return result,len(result)\n",
    "\n",
    "def cal_dialogue(data):\n",
    "    i = 0\n",
    "    maxleng = 0\n",
    "    while(i < len(data.Text)):\n",
    "        if len(data.Text[i]) > maxleng:\n",
    "            maxleng = len(data.Text[i])\n",
    "        i = i + 1\n",
    "    return maxleng\n",
    "\n",
    "def batchload(dataset, repeat, BATCH_SIZE):\n",
    "    \n",
    "    '''\n",
    "    while True:\n",
    "        i = BATCH_SIZE\n",
    "        while(i < len(dataset)):\n",
    "            batch = []\n",
    "            batch_seq = 0\n",
    "            batchnum = a[i-BATCH_SIZE:i]\n",
    "            while(batch_seq < BATCH_SIZE):\n",
    "                batch.append(dataset[batchnum[batch_seq]])\n",
    "                batch_seq = batch_seq + 1\n",
    "            yield batch\n",
    "            i = i + BATCH_SIZE\n",
    "\n",
    "        batch = []\n",
    "        batch_seq = 0\n",
    "        batchnum = a[i-BATCH_SIZE:len(dataset)-1]\n",
    "        while (batch_seq < len(batchnum)):\n",
    "            batch.append(dataset[batchnum[batch_seq]])\n",
    "            batch_seq = batch_seq + 1\n",
    "            \n",
    "        yield batch\n",
    "\n",
    "        if repeat == False:\n",
    "            break\n",
    "    '''\n",
    "    a = torch.arange(len(dataset)-1000,dtype=torch.int)\n",
    "    while True:\n",
    "        i = BATCH_SIZE\n",
    "        while(i < len(dataset)-1000):\n",
    "            batch = []\n",
    "            batch_seq = 0\n",
    "            batchnum = a[i-BATCH_SIZE:i]\n",
    "            while(batch_seq < BATCH_SIZE):\n",
    "                batch.append(dataset[batchnum[batch_seq]])\n",
    "                batch_seq = batch_seq + 1\n",
    "            yield batch\n",
    "            i = i + BATCH_SIZE\n",
    "        \n",
    "        if repeat == False:\n",
    "            break\n",
    "\n",
    "    \n",
    "def pad_batch(minibatch):\n",
    "    i = 0\n",
    "    new_batch = []\n",
    "    leng_set = []\n",
    "    maxleng = 1\n",
    "    sentnum_per_dialogue = []\n",
    "    while(i < len(minibatch)): #almost equal to BATCH_SIZE\n",
    "        j = 0\n",
    "        temp = []\n",
    "        sentnum_per_dialogue.append(len(minibatch[i].Text)-1)\n",
    "        #save sentnum per dialogue\n",
    "        while(j < len(minibatch[i].Text)-1):\n",
    "            sent, leng = sent_loader(minibatch[i].Text[j])  \n",
    "            #convert text to word_list, word_list_length\n",
    "            leng_set.append(leng)\n",
    "            if leng > maxleng:\n",
    "                maxleng = leng\n",
    "\n",
    "            temp.append(sent)\n",
    "            j = j + 1\n",
    "        stop_tag = [\"<stop_tag>\"]\n",
    "        temp.append(stop_tag) #append stoptag per dialogue\n",
    "        new_batch.append(temp)\n",
    "        i = i + 1\n",
    "\n",
    "    i = 0\n",
    "    while (i < len(minibatch)): #almost equal to BATCH_SIZE\n",
    "        j = 0\n",
    "        while (j < len(new_batch[i])):\n",
    "\n",
    "            while(len(new_batch[i][j]) < maxleng):\n",
    "                new_batch[i][j] = np.append(new_batch[i][j],\"<pad>\")\n",
    "\n",
    "            j = j + 1\n",
    "        i = i + 1\n",
    "    #batch * sentnum * (word_list+pad) -> new_batch\n",
    "    #batch * sentnum * (word_list_length) -> leng_set\n",
    "    #batch * (sentnum) -> sentnum_per_dialogue\n",
    "    print(\"max sentence in this batch:\",maxleng)\n",
    "    return new_batch, leng_set ,sentnum_per_dialogue\n",
    "\n",
    "\n",
    "wv_model = word2vec.Word2Vec(size = 100, window = 5, min_count = 5, workers = 4)\n",
    "wv_model = word2vec.Word2Vec.load('/home/jongsu/Desktop/dialogue_wv')\n",
    "\n",
    "def numerize_sent(sent, len_sent):\n",
    "    i = 0\n",
    "    n_sent = []\n",
    "    while(i < len_sent):\n",
    "        if(sent[i] == '<pad>'):\n",
    "            n_sent.append(np.zeros(100))\n",
    "        else:\n",
    "            try:\n",
    "                n_sent.append(wv_model.wv[sent[i]])\n",
    "            except:\n",
    "\n",
    "                n_sent.append(np.zeros(100))\n",
    "\n",
    "        i = i + 1\n",
    "    return n_sent\n",
    "\n",
    "def batch_numerical(sent_set):\n",
    "    numeric_batch = []#numerized batch\n",
    "    i = 0\n",
    "    while(i < len(sent_set) ): #BATCH_SIZE\n",
    "        dial = []#numerized dialogue\n",
    "        j = 0\n",
    "        while(j < len(sent_set[i])): #per dialogue\n",
    "            dial.append(numerize_sent(sent_set[i][j], len(sent_set[i][j]))) #numerized_sentence\n",
    "            j = j + 1\n",
    "        numeric_batch.append(dial)\n",
    "        i = i + 1\n",
    "    #batch * sent_num * sent_leng * wv -> numeric_batch\n",
    "    return numeric_batch\n",
    "\n",
    "def select_sent_output(new_sent, all_seq_len):\n",
    "    remake = torch.transpose(new_sent, 0, 1)\n",
    "    i = 0\n",
    "    while(i < len(remake)):\n",
    "        if i == 0:\n",
    "            tensor = remake[0][all_seq_len[0]-1].view(1,200)\n",
    "        else:\n",
    "            tensor = torch.cat((tensor, remake[i][all_seq_len[i]-1].view(1,200)), 0)\n",
    "        i = i + 1\n",
    "    return tensor\n",
    "\n",
    "def make_batch2sent(new):\n",
    "    for_sentmodel = []\n",
    "    batchnum = 0\n",
    "    while (batchnum < len(new)): #BATCH_SIZE\n",
    "        for_sentmodel = for_sentmodel + new[batchnum]\n",
    "        batchnum = batchnum + 1\n",
    "    sentbatch_len = len(for_sentmodel)\n",
    "    #batch * sent_num * sent_leng * wv -> all_sent_num * sent_leng * wv\n",
    "    return sentbatch_len, for_sentmodel\n",
    "\n",
    "def pad_dial(last_v):\n",
    "    leng_set = []\n",
    "    i = 0\n",
    "    last_seq_vec = torch.ones([1,100], dtype=torch.float32, requires_grad=False).cuda()#stoptag\n",
    "\n",
    "    while(i < len(last_v)):#BATCH_SIZE\n",
    "        \n",
    "        leng_set.append(len(last_v[i]))#sentence num\n",
    "\n",
    "        #pad_vec = torch.cat((last_v[i],last_seq_vec),dim=0)#append stoptag vector\n",
    "        #if i == 0:\n",
    "        #    my_vec = pad_vec.unsqueeze(0)\n",
    "        #else:\n",
    "        #    my_vec = torch.cat((my_vec,pad_vec.unsqueeze(0)))\n",
    "        i = i + 1\n",
    "    padded_dial = pad_sequence(last_v, batch_first = True)#append padtag vector\n",
    "    print('max_dialogue_length',len(padded_dial[0]))\n",
    "    \n",
    "    return padded_dial, leng_set\n",
    "\n",
    "def sent_loader(sentence): #pre_process per sentence\n",
    "    result = []\n",
    "    for elem in sentence.split(' '):\n",
    "        if elem != '':\n",
    "            result = np.append(result, elem)\n",
    "    return result,len(result)\n",
    "\n",
    "def pad_cat_tag(emotion, act): \n",
    "    i = 0\n",
    "    new_tag = []\n",
    "    while(i < len(emotion)): #BATCH_SIZE\n",
    "        emo, lenge = sent_loader(emotion[i][0])\n",
    "        ac, lenga = sent_loader(act[i][0])\n",
    "        j = 0\n",
    "        inte = []\n",
    "        inte.append(tag_to_ix['start_tag']) #append stop tag\n",
    "        while(j < len(emo)): #sent length\n",
    "            inte.append(int(emo[j]) * 4 + int(ac[j]))\n",
    "            j = j + 1\n",
    "        inte.append(tag_to_ix['stop_tag']) #append stop tag\n",
    "        torch_inte = torch.tensor(inte)\n",
    "        new_tag.append(torch_inte) #str to int\n",
    "        i = i + 1\n",
    "\n",
    "            \n",
    "    padded_tag = pad_sequence(new_tag, batch_first = True, padding_value = tag_to_ix['pad_tag'])\n",
    "    \n",
    "    #emotion+action string -> emotion+action numb + padding\n",
    "    #batch*tag\n",
    "    return padded_tag\n",
    "\n",
    "def make_mask(leng):\n",
    "    '''\n",
    "    make one-hot vector of mask from lengset\n",
    "    '''\n",
    "    var = np.zeros(shape = (len(leng), leng[0]+1)) #len(leng) = BATCH_SIZE, leng[0]+1= largest dialogue + stop\n",
    "    i = 0\n",
    "    while(i < len(leng)):#BATCH_SIZE\n",
    "        j = 0\n",
    "        while(j < leng[0]+1): \n",
    "            if(j <= leng[i]): # <= stop tag\n",
    "                var[i][j] = 1\n",
    "            j = j + 1\n",
    "        \n",
    "        i = i + 1\n",
    "    return var\n",
    "\n",
    "def log_sum_exp(x):\n",
    "    max_score, _ = torch.max(x, -1)\n",
    "    max_score_broadcast = max_score.unsqueeze(-1).expand_as(x)\n",
    "    return max_score + torch.log(torch.sum(torch.exp(x - max_score_broadcast), -1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Example(object):\n",
    "    @classmethod\n",
    "    def fromdict(cls, data, fields):\n",
    "        ex = cls()\n",
    "        for key, vals in fields.items():\n",
    "            if key not in data:\n",
    "                raise ValueError(\"Specified key {} was not found in \"\n",
    "                                 \"the input data\".format(key))\n",
    "            if vals is not None:\n",
    "                if not isinstance(vals, list):\n",
    "                    vals = [vals]\n",
    "                for val in vals:\n",
    "                    name, field = val\n",
    "                    setattr(ex, name, field.preprocess(data[key]))\n",
    "        return ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Defines a dataset composed of Examples along with its Fields.\n",
    "    Attributes:\n",
    "        sort_key (callable): A key to use for sorting dataset examples for batching\n",
    "            together examples with similar lengths to minimize padding.\n",
    "        examples (list(Example)): The examples in this dataset.\n",
    "        fields (dict[str, Field]): Contains the name of each column or field, together\n",
    "            with the corresponding Field object. Two fields with the same Field object\n",
    "            will have a shared vocabulary.\n",
    "    \"\"\"\n",
    "    sort_key = None\n",
    "\n",
    "    def __init__(self, examples, fields, filter_pred=None):\n",
    "        \"\"\"Create a dataset from a list of Examples and Fields.\n",
    "        Arguments:\n",
    "            examples: List of Examples.\n",
    "            fields (List(tuple(str, Field))): The Fields to use in this tuple. The\n",
    "                string is a field name, and the Field is the associated field.\n",
    "            filter_pred (callable or None): Use only examples for which\n",
    "                filter_pred(example) is True, or use all examples if None.\n",
    "                Default is None.\n",
    "        \"\"\"\n",
    "\n",
    "        self.examples = examples\n",
    "\n",
    "        self.fields = dict(fields)\n",
    "\n",
    "        # Unpack field tuples\n",
    "        for n, f in list(self.fields.items()):\n",
    "            if isinstance(n, tuple):\n",
    "                self.fields.update(zip(n, f))\n",
    "                del self.fields[n]\n",
    "        self.pp = tuple(d for d in self.examples if d is not None)\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def splits(cls, path=None, root='.data', train=None, **kwargs):\n",
    "\n",
    "        train_data = cls(os.path.join(path, train), **kwargs)\n",
    "        #print(train_data.examples) #여기엔 field example둘다 들어있음\n",
    "        #print(tuple(d for d in train_data if d is not None)) #여기엔 example만 나열된 튜플이됨\n",
    "        return tuple(d for d in train_data if d is not None)\n",
    "\n",
    "    def split(self, split_ratio=0.7, stratified=False, strata_field='label',\n",
    "              random_state=None):\n",
    "        \"\"\"Create train-test(-valid?) splits from the instance's examples.\n",
    "        Arguments:\n",
    "            split_ratio (float or List of floats): a number [0, 1] denoting the amount\n",
    "                of data to be used for the training split (rest is used for validation),\n",
    "                or a list of numbers denoting the relative sizes of train, test and valid\n",
    "                splits respectively. If the relative size for valid is missing, only the\n",
    "                train-test split is returned. Default is 0.7 (for th train set).\n",
    "            stratified (bool): whether the sampling should be stratified.\n",
    "                Default is False.\n",
    "            strata_field (str): name of the examples Field stratified over.\n",
    "                Default is 'label' for the conventional label field.\n",
    "            random_state (int): the random seed used for shuffling.\n",
    "        Returns:\n",
    "            Tuple[Dataset]: Datasets for train, validation, and\n",
    "                test splits in that order, if the splits are provided.\n",
    "        \"\"\"\n",
    "        train_ratio, test_ratio, val_ratio = check_split_ratio(split_ratio)\n",
    "\n",
    "        # For the permutations\n",
    "        rnd = RandomShuffler(random_state)\n",
    "        if not stratified:\n",
    "            train_data, test_data, val_data = rationed_split(self.examples, train_ratio,\n",
    "                                                             test_ratio, val_ratio, rnd)\n",
    "        else:\n",
    "            if strata_field not in self.fields:\n",
    "                raise ValueError(\"Invalid field name for strata_field {}\"\n",
    "                                 .format(strata_field))\n",
    "            strata = stratify(self.examples, strata_field)\n",
    "            train_data, test_data, val_data = [], [], []\n",
    "            for group in strata:\n",
    "                # Stratify each group and add together the indices.\n",
    "                group_train, group_test, group_val = rationed_split(group, train_ratio,\n",
    "                                                                    test_ratio, val_ratio,\n",
    "                                                                    rnd)\n",
    "                train_data += group_train\n",
    "                test_data += group_test\n",
    "                val_data += group_val\n",
    "\n",
    "        splits = tuple(Dataset(d, self.fields)\n",
    "                       for d in (train_data, val_data, test_data) if d)\n",
    "\n",
    "        # In case the parent sort key isn't none\n",
    "        if self.sort_key:\n",
    "            for subset in splits:\n",
    "                subset.sort_key = self.sort_key\n",
    "        return splits\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.examples[i]\n",
    "\n",
    "    def __len__(self):\n",
    "        try:\n",
    "            return len(self.examples)\n",
    "        except TypeError:\n",
    "            return 2 ** 32\n",
    "\n",
    "    def __iter__(self):\n",
    "        for x in self.examples:\n",
    "            yield x\n",
    "\n",
    "    def __getattr__(self, attr):\n",
    "        if attr in self.fields:\n",
    "            for x in self.examples:\n",
    "                yield getattr(x, attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class my_TabularDataset(Dataset):\n",
    "\n",
    "    def __init__(self, path,  fields,  **kwargs):\n",
    "\n",
    "\n",
    "        with open(path, encoding=\"utf8\") as f:\n",
    "            for line in f:\n",
    "                examples = [Example.fromdict(per_data, my_fields) for per_data in json.loads(line)]\n",
    "\n",
    "\n",
    "        if isinstance(fields, dict):\n",
    "            fields, field_dict = [], fields\n",
    "            for field in field_dict.values():\n",
    "                if isinstance(field, list):\n",
    "                    fields.extend(field)\n",
    "                else:\n",
    "                    fields.append(field)\n",
    "\n",
    "\n",
    "        super(my_TabularDataset, self).__init__(examples, fields, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class makesent_gru(nn.Module):\n",
    "    def __init__(self, hidden_size, bidirectional):\n",
    "        super(makesent_gru, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        if (bidirectional == True):\n",
    "            self.bidirectional = 2\n",
    "        else:\n",
    "            self.bidirectional = 1\n",
    "        self.gru = nn.GRU(100, 100, bidirectional=bidirectional)\n",
    "\n",
    "    def forward(self, char, h0):\n",
    "        gru_out, h0 = self.gru(char, h0)\n",
    "        return gru_out, h0\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(self.bidirectional, 1, self.hidden_size, device=device, requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class last_sent_net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(last_sent_net, self).__init__()\n",
    "        self.lastnet = nn.Linear(200, 100)\n",
    "\n",
    "    def forward(self, last_hidden_state):\n",
    "        last_w = self.lastnet(last_hidden_state)\n",
    "        return last_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class BiGru_CRF(nn.Module):\n",
    "    def __init__(self, tag_to_ix, hidden_dim):\n",
    "        super(BiGru_CRF, self).__init__()\n",
    "\n",
    "        self.gru = nn.GRU(100, 100, bidirectional=True)\n",
    "        self.hidden2tag = nn.Linear(200, 31)\n",
    "        self.transitions = nn.Parameter(torch.randn(31, 31))# [a,b] trans from b to a\n",
    "        self.transitions.data[0, :] = -10000 #all to start\n",
    "        self.transitions.data[:, 29] = -10000 #stop to all\n",
    "        self.transitions.data[:, 30] = -10000 #pad to all\n",
    "        self.transitions.data[30][30] = 0 #pad to pad\n",
    "        self.transitions.data[29][30] = 0 #stop to pad\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.tag_to_ix = tag_to_ix\n",
    "        \n",
    "\n",
    "    def init_hidden(self,batch):\n",
    "        return Variable(torch.zeros(2, batch, 100).cuda(),requires_grad=False)\n",
    "    \n",
    "    def _get_gru_features(self, batch, sentence_set):\n",
    "        \n",
    "        hidden = self.init_hidden(batch)\n",
    "        gru_out, hidden = self.gru(sentence_set, hidden)\n",
    "\n",
    "        gru_feats = self.hidden2tag(gru_out)\n",
    "\n",
    "        return gru_feats\n",
    "\n",
    "    def for_score(self, pre_mask, feats):\n",
    "        score = Variable(torch.zeros((BATCH_SIZE, 31)).fill_(-10000.).cuda(),requires_grad=False)\n",
    "        score[:, self.tag_to_ix['start_tag']] = 0. #start to all is 0\n",
    "        \n",
    "        mask = Variable(torch.Tensor(pre_mask).cuda(),requires_grad=False)\n",
    "        \n",
    "        for t in range(feats.size(0)):  # 안에서 연산하는데이터들은 batch*featuresize*featuresize\n",
    "            \n",
    "            mask_t = mask[:, t].unsqueeze(-1).expand_as(score) #batch_size -> batch_size*featuresize\n",
    "            \n",
    "            score_t = score.unsqueeze(1).expand(-1, *self.transitions.size()) #batch_size*f -> batch_size*f*f\n",
    "            \n",
    "            emit = feats[t].unsqueeze(-1).expand_as(score_t) #b*f-> b*f*f\n",
    "            \n",
    "            trans = self.transitions.unsqueeze(0).expand_as(score_t) #b*f*f\n",
    "            \n",
    "            score_t = log_sum_exp(score_t + emit + trans)\n",
    "            \n",
    "            score = score_t * mask_t + score * (1 - mask_t) #no updating in masked score,all b*f\n",
    "\n",
    "        score = log_sum_exp(score)\n",
    "        return score\n",
    "\n",
    "    def cal_score(self, mask, feats, tag):\n",
    "        score = Variable(torch.FloatTensor(BATCH_SIZE).fill_(0.).cuda(),requires_grad=False)\n",
    "        \n",
    "        temp_tag = Variable(tag.cuda(),requires_grad=False)\n",
    "\n",
    "        mask_tensor = torch.transpose(torch.FloatTensor(mask), 0, 1) #seq*batch\n",
    "        mask_tensor = Variable(mask_tensor.cuda(), requires_grad=False)\n",
    "        \n",
    "        \n",
    "        for i, feat in enumerate(feats): #seq*batch*feat->batch*feat\n",
    "            \n",
    "            transit = torch.cat(\n",
    "                [torch.tensor([self.transitions[temp_tag[batch][i + 1], temp_tag[batch][i]]]) for batch in range(BATCH_SIZE)])\n",
    "            \n",
    "            transit = transit.cuda()\n",
    "            \n",
    "            transit = transit * mask_tensor[i] #batch*batch->batch\n",
    "            \n",
    "            emit = torch.cat([feat[batch][temp_tag[batch][i + 1]].view(1, -1) for batch in range(BATCH_SIZE)]).squeeze(1)\n",
    "\n",
    "            emit = emit * mask_tensor[i]#batch*batch->batch\n",
    "            \n",
    "            score = score + transit + emit\n",
    "\n",
    "        return score\n",
    "\n",
    "    def neg_log_likelihood(self, mask, sentence, tags, batch):\n",
    "\n",
    "        feats = self._get_gru_features(batch, sentence)\n",
    "   \n",
    "        forward_score = self.for_score(mask, feats)\n",
    "\n",
    "        gold_score = self.cal_score(mask, feats, tags)\n",
    "\n",
    "        return forward_score - gold_score\n",
    "\n",
    "    def _viterbi_decode(self, mask, feats):\n",
    "        backpointers = []\n",
    "\n",
    "        # Initialize the viterbi variables in log space\n",
    "        init_vvars = Variable(torch.full((1, 31), -10000.).cuda(),requires_grad=False)\n",
    "        init_vvars[0][0] = 0\n",
    "\n",
    "        # forward_var at step i holds the viterbi variables for step i-1\n",
    "        forward_var = init_vvars\n",
    "\n",
    "        for i, feat in enumerate(feats):\n",
    "            if mask[i] == 0:\n",
    "                print('breaked')\n",
    "                break\n",
    "            bptrs_t = []  # holds the backpointers for this step\n",
    "            viterbivars_t = []  # holds the viterbi variables for this step\n",
    "\n",
    "            for next_tag in range(31):\n",
    "                next_tag_var = forward_var + self.transitions[next_tag]\n",
    "                best_tag_id = argmax(next_tag_var)\n",
    "                bptrs_t.append(best_tag_id)\n",
    "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
    "\n",
    "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
    "            backpointers.append(bptrs_t)\n",
    "\n",
    "        terminal_var = forward_var + self.transitions[self.tag_to_ix['stop_tag']]\n",
    "        best_tag_id = argmax(terminal_var)\n",
    "        path_score = terminal_var[0][best_tag_id]\n",
    "\n",
    "        best_path = [best_tag_id]\n",
    "        for bptrs_t in reversed(backpointers):\n",
    "            best_tag_id = bptrs_t[best_tag_id]\n",
    "            best_path.append(best_tag_id)\n",
    "        # Pop off the start tag (we dont want to return that to the caller)\n",
    "        start = best_path.pop()\n",
    "        assert start == 0  # Sanity check\n",
    "        best_path.reverse()\n",
    "        return path_score, best_path\n",
    "\n",
    "    def forward(self,batch, dummy_input):  # dont confuse this with _forward_alg above.\n",
    "        # Get the emission scores from the BiLSTM\n",
    "        lstm_feats = self._get_gru_features(batch,dummy_input[1])\n",
    "        \n",
    "        \n",
    "        \n",
    "        lstm_feats = torch.transpose(lstm_feats,0,1)\n",
    "        mask = dummy_input[0]\n",
    "\n",
    "        \n",
    "        \n",
    "        # Find the best path, given thhttps://github.com/kkugosu/7proue features.\n",
    "        score, tag_seq = self._viterbi_decode(mask[5], lstm_feats[5])\n",
    "        return score, tag_seq\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def all_preprocess(sent, lasent, batch_d):\n",
    "\n",
    "    batch_data = sorted(batch_d, key = lambda  x: -len(x.Text))\n",
    "    #sorted with dialogue length\n",
    "    #print(batch_data[0].Text)\n",
    "    #######################################################\n",
    "    emotion_set = []\n",
    "    action_set = []\n",
    "    i = 0\n",
    "    while(i < len(batch_data)): #equals to BATCH_SIZE except last dataset\n",
    "        emotion_set.append(batch_data[i].labels_1)\n",
    "        action_set.append(batch_data[i].labels_2)\n",
    "        i = i + 1\n",
    "\n",
    "    new_tag = pad_cat_tag(emotion_set, action_set)\n",
    "    #batch*tag\n",
    "    new_tag = Variable(new_tag.cuda(), requires_grad=False)\n",
    "\n",
    "    \n",
    "    #####################################################tag_preprocess\n",
    "    \n",
    "    \n",
    "    new, all_seq_len, sentnum_per_batch = pad_batch(batch_data)\n",
    "    #batch * sentnum * (word_list+pad) -> new\n",
    "    #batch * sentnum * (word_list_length) -> all_seq_len\n",
    "    #batch * (sentnum) -> sentnum_per_batch\n",
    "\n",
    "    \n",
    "    new2 = batch_numerical(new)\n",
    "    #batch * sent_num * sent_leng * wv -> new2\n",
    "\n",
    "    \n",
    "    sentbatch_len, for_sentmodel = make_batch2sent(new2)\n",
    "    #batch * sent_num * sent_leng * wv -> all_sent_num(new_batch) * sent_leng * wv\n",
    "    \n",
    "    hidden_state = torch.tensor(np.zeros((2, sentbatch_len, 100)), dtype=torch.float, device= device, requires_grad=False)\n",
    "    for_sentmodel2 = torch.tensor(np.transpose(for_sentmodel, [1, 0, 2]), dtype=torch.float, device= device, requires_grad=False)\n",
    "    \n",
    "    new_sent, hidden_state = sent(for_sentmodel2, hidden_state)\n",
    "    \n",
    "    ##################################################first network\n",
    "    \n",
    "    out_sent_set = select_sent_output(new_sent, all_seq_len)\n",
    "    #select last state according to masking\n",
    "    \n",
    "    pre_crf_gru = lasent(out_sent_set) #linear layer\n",
    "    \n",
    "    #################################################sec network\n",
    "    #all_sent_num(new_batch) * sent_leng * wv -> all_sent_num(new_batch) * wv\n",
    "    \n",
    "    last_var = torch.split(pre_crf_gru, sentnum_per_batch)\n",
    "    #all_sent_num(new_batch) * wv -> batch * sent_num * wv\n",
    "\n",
    "    new_dial, dial_leng = pad_dial(last_var)\n",
    "    #batch * sent_num * wv -> batch * (sent_num + pad) * wv\n",
    "    #save dial_leng for masking\n",
    "    \n",
    "    new_dial = torch.transpose(new_dial, 0, 1)\n",
    "    \n",
    "    \n",
    "    return new_dial, new_tag, dial_leng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_fields={'dial': ('Text', data.Field(sequential=True)),\n",
    "        'emo': ('labels_1', data.Field(sequential=False)),\n",
    "        'act': ('labels_2', data.Field(sequential=False))}\n",
    "\n",
    "train = my_TabularDataset.splits(path = Desktop_path, train = 'full_data.json',\n",
    "                          fields=my_fields) #train에 fields라는 어트리뷰트가 없다는데?\n",
    "\n",
    "train = sorted(train, key = lambda  x: cal_dialogue(x))\n",
    "optimizer1 = optim.SGD(sent_to_vextor_bigru_net.parameters(), lr=0.00001, weight_decay=1e-4)\n",
    "optimizer2 = optim.SGD(sent_to_vector_linear_net.parameters(), lr=0.00001, weight_decay=1e-4)\n",
    "optimizer3 = optim.SGD(my_grucrf_model.parameters(), lr=0.00001, weight_decay=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max sentence in this batch: 7\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 0: Sizes of tensors must match except in dimension 0. Got 5 and 11 in dimension 1 at /opt/conda/conda-bld/pytorch_1524580978845/work/aten/src/THC/generic/THCTensorMath.cu:111",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-56f48154c7a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmy_grucrf_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mnew_dial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_tag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdial_leng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_to_vextor_bigru_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_to_vector_linear_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;31m#load batch*(dialogue_length*sent_vec(float)) -> new_dial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#load batch*tag -> new_tag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-a69919ba255c>\u001b[0m in \u001b[0;36mall_preprocess\u001b[0;34m(sent, lasent, batch_d)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m#all_sent_num(new_batch) * wv -> batch * sent_num * wv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mnew_dial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdial_leng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_dial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0;31m#batch * sent_num * wv -> batch * (sent_num + pad) * wv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m#save dial_leng for masking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-cf22e32e7060>\u001b[0m in \u001b[0;36mpad_dial\u001b[0;34m(last_v)\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mmy_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0mmy_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_vec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpad_vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0mpadded_dial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#append padtag vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 0: Sizes of tensors must match except in dimension 0. Got 5 and 11 in dimension 1 at /opt/conda/conda-bld/pytorch_1524580978845/work/aten/src/THC/generic/THCTensorMath.cu:111"
     ]
    }
   ],
   "source": [
    "\n",
    "k = 0\n",
    "for batch_data in batchload(train, repeat=True, BATCH_SIZE = BATCH_SIZE ):\n",
    "    #load txt data from jsonfile\n",
    "    sent_to_vextor_bigru_net.zero_grad()\n",
    "    sent_to_vector_linear_net.zero_grad()\n",
    "    my_grucrf_model.zero_grad()\n",
    "\n",
    "    new_dial, new_tag, dial_leng = all_preprocess(sent_to_vextor_bigru_net, sent_to_vector_linear_net, batch_data)\n",
    "    #load batch*(dialogue_length*sent_vec(float)) -> new_dial\n",
    "    #load batch*tag -> new_tag\n",
    "    #load batch * dial_leng\n",
    "\n",
    "    loss = my_grucrf_model.neg_log_likelihood(make_mask(dial_leng), new_dial, new_tag, BATCH_SIZE)\n",
    "\n",
    "    #print(loss)\n",
    "    batch_loss = torch.sum(loss)\n",
    "    print(batch_loss)\n",
    "    batch_loss.backward(retain_graph=True)\n",
    "\n",
    "    optimizer1.step()\n",
    "    optimizer2.step()\n",
    "    optimizer3.step()\n",
    "\n",
    "    unuselist = [new_dial, new_tag, dial_leng]\n",
    "    del unuselist\n",
    "    \n",
    "    \n",
    "    #torch.save(a.state_dict(),'./log_dir/first.ckpt')\n",
    "    #torch.save(b.state_dict(),'./log_dir/sec.ckpt')\n",
    "    #torch.save(my_grucrf_model.state_dict(),'./log_dir/third.ckpt')\n",
    "    \n",
    "    #dummy_input = [make_mask(dial_leng),new_dial]\n",
    "    #print(my_grucrf_model(dummy_input))\n",
    "    \n",
    "    #with SummaryWriter(comment='crf_gru') as w:\n",
    "    #    w.add_graph(my_grucrf_model, (dummy_input, ))\n",
    "\n",
    "    \n",
    "    k = k + 1\n",
    "    print(k)\n",
    "    if k%100 == 10:\n",
    "        torch.save(sent_to_vextor_bigru_net.state_dict(),'./first.pth')\n",
    "        torch.save(sent_to_vector_linear_net.state_dict(),'./sec.pth')\n",
    "        torch.save(my_grucrf_model.state_dict(),'./third.pth')\n",
    "        print(new_tag[5])\n",
    "        dummy_input = [make_mask(dial_leng),new_dial]\n",
    "        print(my_grucrf_model(100,dummy_input))\n",
    "        print(loss)\n",
    "    if k == 3000:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(os.environ.get('http_proxy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tag_to_ix = {'start_tag':0,'stop_tag':29,'pad_tag':30}\n",
    "tag_to_ix['start_tag']+tag_to_ix['stop_tag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#k = 0\n",
    "#vis = visdom.Visdom()\n",
    "#vis.text('Hello, world!')\n",
    "#vis.image(np.ones((3, 10, 10)))\n",
    "[2, 21,2, 21, 2,21,2, 21,25, 3,  3, 4,  29]\n",
    "[2, 1, 2, 1, 2, 1, 2, 1, 17, 20, 17, 20]\n",
    "\n",
    "\n",
    "[1,26, 3, 4, 26,1,  2, 1, 2,1,  17,1,  29]\n",
    "[1, 2, 1, 1, 2, 1, 2, 3, 2, 1, 17, 20]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
