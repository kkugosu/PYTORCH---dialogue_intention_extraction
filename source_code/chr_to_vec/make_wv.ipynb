{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "#import tensorflow as tf\n",
    "\n",
    "import io\n",
    "from gensim.models import word2vec\n",
    "\n",
    "from io import StringIO\n",
    "from pprint import pprint\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import types\n",
    "from IPython import get_ipython #for import notebook\n",
    "from nbformat import read #for import notebook\n",
    "from IPython.core.interactiveshell import InteractiveShell #for import notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncount = [(\\'UNK\\', -1)]\\ncount.extend(collections.Counter(tokens).most_common(13544 - 1))\\n\\nprint(count)\\n\\ncount[13543]\\ndictionary = dict()\\n\\nfor word, _ in count:\\n    dictionary[word] = len(dictionary)\\n    \\nprint(dictionary)\\nlen(dictionary)\\n\\n\\npp = dict()\\nlen(pp)\\npp[\"k\"] = len(pp)\\ndictionary[\\'UNK\\']\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## how make word2vec\n",
    "'''\n",
    "count = [('UNK', -1)]\n",
    "count.extend(collections.Counter(tokens).most_common(13544 - 1))\n",
    "\n",
    "print(count)\n",
    "\n",
    "count[13543]\n",
    "dictionary = dict()\n",
    "\n",
    "for word, _ in count:\n",
    "    dictionary[word] = len(dictionary)\n",
    "    \n",
    "print(dictionary)\n",
    "len(dictionary)\n",
    "\n",
    "\n",
    "pp = dict()\n",
    "len(pp)\n",
    "pp[\"k\"] = len(pp)\n",
    "dictionary['UNK']\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The kitchen stinks  .  ', \" I'll throw out the garbage  .  \", ''],\n",
       " ['So Dick , how about getting some coffee for tonight ? ',\n",
       "  ' Coffee ? I don ’ t honestly like that kind of stuff  .  ',\n",
       "  ' Come on , you can at least try a little , besides your cigarette  .  ',\n",
       "  ' What ’ s wrong with that ? Cigarette is the thing I go crazy for  .  ',\n",
       "  ' Not for me , Dick  .  ',\n",
       "  ''],\n",
       " ['Are things still going badly with your houseguest ? ',\n",
       "  ' Getting worse  .  Now he ’ s eating me out of house and home  .  I ’ Ve tried talking to him but it all goes in one ear and out the other  .  He makes himself at home , which is fine  .  But what really gets me is that yesterday he walked into the living room in the raw and I had company over ! That was the last straw  .  ',\n",
       "  ' Leo , I really think you ’ re beating around the bush with this guy  .  I know he used to be your best friend in college , but I really think it ’ s time to lay down the law  .  ',\n",
       "  ' You ’ re right  .  Everything is probably going to come to a head tonight  .  I ’ ll keep you informed  .  ',\n",
       "  ''],\n",
       " ['Would you mind waiting a while ? ',\n",
       "  ' Well , how long will it be ? ',\n",
       "  \" I'm not sure  .  But I'll get a table ready as fast as I can  .  \",\n",
       "  \" OK  .  We'll wait  .  \",\n",
       "  ''],\n",
       " ['Are you going to the annual party ? I can give you a ride if you need one  .  ',\n",
       "  \" Thanks a lot  .  That's the favor I was going to ask you for  .  \",\n",
       "  ' The pleasure is mine  .  ',\n",
       "  ''],\n",
       " ['Isn ’ t he the best instructor ? I think he ’ s so hot  .  Wow ! I really feel energized , don ’ t you ? ',\n",
       "  ' I swear , I ’ m going to kill you for this  .  ',\n",
       "  ' What ’ s wrong ? Didn ’ t you think it was fun ? ! ',\n",
       "  ' Oh , yeah ! I had a blast ! I love sweating like a pig with a bunch of pot bellies who all smell bad  .  Sorry , I ’ m just not into this health kick  .  ',\n",
       "  ' Oh , no , get off it  .  It wasn ’ t such a killer class  .  You just have to get into it  .  Like they say , no pain , no gain  .  ',\n",
       "  ' I am wiped out  .  Thank you  .  ',\n",
       "  ' Look , next time get yourself some comfy shoes  .  You ’ re gonna come back again with me , aren ’ t you ? ',\n",
       "  ' Never ! But thank you for inviting me  .  ',\n",
       "  ' Come on  .  You ’ ll feel better after we hit the showers  .  ',\n",
       "  ''],\n",
       " ['Can I take your order now or do you still want to look at the menu ? ',\n",
       "  \" Well , I want a fillet steak , medium , but my little girl doesn't care for steak  .  Could she have something else instead ? \",\n",
       "  ' Certainly  .  How about spaghetti with clams and shrimps  .  ',\n",
       "  \" Sounds delicious  .  OK  .  She'll try that  .  \",\n",
       "  ''],\n",
       " ['Can you manage chopsticks ? ',\n",
       "  ' Why not ? See  .  ',\n",
       "  ' Good mastery  .  How do you like our Chinese food ? ',\n",
       "  \" Oh , great ! It's delicious  .  You see , I am already putting on weight  .  There is one thing I don't like however , MSG  .  \",\n",
       "  \" What's wrong with MSG ? It helps to bring out the taste of the food  .  \",\n",
       "  ' According to some studies it may cause cancer  .  ',\n",
       "  \" Oh , don't let that worry you  .  If that were true , China wouldn't have such a large population  .  \",\n",
       "  ' I just happen to have a question for you guys  .  Why do the Chinese cook the vegetables ? You see what I mean is that most vitamin are destroyed when heated  .  ',\n",
       "  \" I don't know exactly  .  It's a tradition  .  Maybe it's for sanitary reasons  .  \",\n",
       "  ''],\n",
       " [\"I'm exhausted  .  \", \" Okay , let's go home  .  \", ''],\n",
       " [\"Good evening  .  Welcome to Cherry's  .  Do you have a reservation ? \",\n",
       "  \" No , we don't  .  \",\n",
       "  ' How many of you , please ? ',\n",
       "  ' Six , including two kids  .  ',\n",
       "  \" I'm afraid all the big tables are taken  .  \",\n",
       "  '']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenize dialogues_train.txt\n",
    "\n",
    "results = []\n",
    "\n",
    "with open('/home/jongsu/Desktop/intention_extraction/ijcnlp_dailydialog/dialogues_text.txt') as inputfile:\n",
    "    for line in inputfile:\n",
    "        results.append(line.strip().replace('.',' . ').split('__eou__'))\n",
    "\n",
    "results[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'kitchen', 'stinks', '.']\n"
     ]
    }
   ],
   "source": [
    "lenn = 0\n",
    "lenm = 0\n",
    "new_list = []\n",
    "\n",
    "while(lenm < len(results)):\n",
    "    lenn = 0\n",
    "    while(lenn < len(results[lenm])):\n",
    "        pp = [ele for ele in results[lenm][lenn].split(' ') if ele != '']\n",
    "        lenn = lenn + 1\n",
    "        if pp != []:\n",
    "            new_list.append(pp)\n",
    "    #print(lenm)\n",
    "    lenm = lenm + 1\n",
    "    \n",
    "print(new_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102980\n"
     ]
    }
   ],
   "source": [
    "print(len(new_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['So',\n",
       " 'Dick',\n",
       " ',',\n",
       " 'how',\n",
       " 'about',\n",
       " 'getting',\n",
       " 'some',\n",
       " 'coffee',\n",
       " 'for',\n",
       " 'tonight',\n",
       " '?']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_list[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wv_model_en = word2vec.Word2Vec(size=100, window=5, min_count=5, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making en_model..\n"
     ]
    }
   ],
   "source": [
    "print(\"making en_model..\")\n",
    "wv_model_en.build_vocab(new_list)\n",
    "wv_model_en.train(new_list, total_examples=len(new_list), epochs=50)\n",
    "wv_model_en.save('dialogue_wv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if ( os.path.isfile(\"./dialogue_wv\") == False): ##wvmodel for english\n",
    "    \n",
    "    print(\"making en_model..\")\n",
    "    wv_model_en.build_vocab(new_list)\n",
    "    wv_model_en.train(new_list, total_examples=len(new_list), epochs=50)\n",
    "    wv_model_en.save('dialogue_wv')\n",
    "\n",
    "wv_model_en = word2vec.Word2Vec.load('dialogue_wv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jongsu/.pyenv/versions/anaconda3-4.2.0/lib/python3.5/site-packages/ipykernel/__main__.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('he', 0.8745657205581665),\n",
       " ('She', 0.699367880821228),\n",
       " ('He', 0.6014183163642883),\n",
       " ('it', 0.5898851156234741),\n",
       " ('nobody', 0.5045297741889954),\n",
       " ('her', 0.5018121600151062),\n",
       " ('that', 0.4851095974445343),\n",
       " ('father', 0.4793975353240967),\n",
       " ('mother', 0.4640048146247864),\n",
       " ('everyone', 0.46047621965408325)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv_model_en.most_similar('she')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8525"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wv_model_en.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3-4.2.0]",
   "language": "python",
   "name": "conda-env-anaconda3-4.2.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
