{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "#import tensorflow as tf\n",
    "\n",
    "import io\n",
    "from gensim.models import word2vec\n",
    "\n",
    "from io import StringIO\n",
    "from pprint import pprint\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import types\n",
    "from IPython import get_ipython #for import notebook\n",
    "from nbformat import read #for import notebook\n",
    "from IPython.core.interactiveshell import InteractiveShell #for import notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_notebook(fullname, path=None): #for import notebook\n",
    "    \"\"\"find a notebook, given its fully qualified name and an optional path\n",
    "\n",
    "    This turns \"foo.bar\" into \"foo/bar.ipynb\"\n",
    "    and tries turning \"Foo_Bar\" into \"Foo Bar\" if Foo_Bar\n",
    "    does not exist.\n",
    "    \"\"\"\n",
    "    name = fullname.rsplit('.', 1)[-1]\n",
    "    if not path:\n",
    "        path = ['']\n",
    "    for d in path:\n",
    "        nb_path = os.path.join(d, name + \".ipynb\")\n",
    "        if os.path.isfile(nb_path):\n",
    "            return nb_path\n",
    "        # let import Notebook_Name find \"Notebook Name.ipynb\"\n",
    "        nb_path = nb_path.replace(\"_\", \" \")\n",
    "        if os.path.isfile(nb_path):\n",
    "            return nb_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NotebookLoader(object): #for import notebook\n",
    "    \"\"\"Module Loader for Jupyter Notebooks\"\"\"\n",
    "    def __init__(self, path=None):\n",
    "        self.shell = InteractiveShell.instance()\n",
    "        self.path = path\n",
    "\n",
    "    def load_module(self, fullname):\n",
    "        \"\"\"import a notebook as a module\"\"\"\n",
    "        path = find_notebook(fullname, self.path)\n",
    "\n",
    "        print (\"importing Jupyter notebook from %s\" % path)\n",
    "\n",
    "        # load the notebook object\n",
    "        with io.open(path, 'r', encoding='utf-8') as f:\n",
    "            nb = read(f, 4)\n",
    "\n",
    "\n",
    "        # create the module and add it to sys.modules\n",
    "        # if name in sys.modules:\n",
    "        #    return sys.modules[name]\n",
    "        mod = types.ModuleType(fullname)\n",
    "        mod.__file__ = path\n",
    "        mod.__loader__ = self\n",
    "        mod.__dict__['get_ipython'] = get_ipython\n",
    "        sys.modules[fullname] = mod\n",
    "\n",
    "        # extra work to ensure that magics that would affect the user_ns\n",
    "        # actually affect the notebook module's ns\n",
    "        save_user_ns = self.shell.user_ns\n",
    "        self.shell.user_ns = mod.__dict__\n",
    "\n",
    "        try:\n",
    "          for cell in nb.cells:\n",
    "            if cell.cell_type == 'code':\n",
    "                # transform the input to executable Python\n",
    "                code = self.shell.input_transformer_manager.transform_cell(cell.source)\n",
    "                # run the code in themodule\n",
    "                exec(code, mod.__dict__)\n",
    "        finally:\n",
    "            self.shell.user_ns = save_user_ns\n",
    "        return mod\n",
    "class NotebookFinder(object):\n",
    "    \"\"\"Module finder that locates Jupyter Notebooks\"\"\"\n",
    "    def __init__(self):\n",
    "        self.loaders = {}\n",
    "\n",
    "    def find_module(self, fullname, path=None):\n",
    "        nb_path = find_notebook(fullname, path)\n",
    "        if not nb_path:\n",
    "            return\n",
    "\n",
    "        key = path\n",
    "        if path:\n",
    "            # lists aren't hashable\n",
    "            key = os.path.sep.join(path)\n",
    "\n",
    "        if key not in self.loaders:\n",
    "            self.loaders[key] = NotebookLoader(path)\n",
    "        return self.loaders[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.meta_path.append(NotebookFinder())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "import torch.utils.data\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from pre_process.ipynb\n",
      "\n",
      " [[1561, 1, 1089, 1, 102, 33, 74, 14, 7, 229, 3510, 218, 354, 4], [32, 39, 16, 10, 4904, 43, 10, 68, 44, 60, 14, 81, 2579, 0], [29, 21, 3, 225, 4, 41, 35, 93, 149, 6, 1314, 0], [71, 3, 68, 38, 40, 4, 2, 64, 0, 41, 35, 51, 106, 149, 1473, 8, 2582, 1735, 0, 1409, 177, 61, 4], [2, 325, 3, 19, 6800, 57, 654, 30, 21, 4, 2, 64, 207, 24, 1492, 36, 224, 0], [2, 746, 7, 547, 144, 6, 5, 1215, 230, 30, 23, 348, 4963, 8, 273, 56, 12, 81, 358, 0], [97, 7, 60, 228, 0, 2, 318, 476, 8, 2153, 364, 47, 46, 6, 348, 'pingpong.Perhaps', 30, 23, 106, 7, 'foursome', 28, 99, 0], [609, 133, 6, 20, 17, 140, 88, 19, 1180, 1, 30, 121, 250, 99, 6, 47, 1383, 28, 'us.That', 10, 771, 645, 8, 449, 1, 78, 0], ['Good.Let', 161, 34, 47, 92, 0], [219, 55, 0], []]\n",
      "\n",
      " [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1], [0, 1, 1, 1, 1, 1], [1, 1, 1], []]\n",
      "\n",
      " 0 0 0 0 0 0 4 4 4 4\n",
      "\n",
      " 3 4 2 2 2 3 4 1 3 4\n",
      "\n",
      " [[108, 3, 21, 5877, 4], [263, 160, 2, 23, 0, 72, 7, 953, 12, 1108, 17, 2262, 9, 85, 44, 1, 2, 23, 21, 908, 5877, 7, 498, 0], [287, 4, 2, 38, 201, 2176, 17], [32, 225, 908, 5877, 4], [165, 17], [72, 394, 0, 140, 3, 21, 645, 1595, 1, 3, 23, 106, 9, 1, 78, 0], []]\n",
      "\n",
      " [[1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], []]\n",
      "\n",
      " 0 0 6 0 0 0\n",
      "\n",
      " 2 1 2 2 1 1\n",
      "\n",
      " [[108, 3, 644, 28, 5, 1621, 25, 4], [65, 1, 2, 893, 6, 1697, 453, 0], [29, 10, 5, 1005, 4], [63, 1621, 115, 78, 157, 'comerials', 0], [97, 419, 1, 43, 119, 3, 15, 6, 196, 7, 1263, 1275, 0], []]\n",
      "\n",
      " [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 0, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], []]\n",
      "\n",
      " 0 0 0 0 0\n",
      "\n",
      " 2 1 2 1 1\n",
      "\n",
      " [[137, 3, 50, 55, 4], [2, 35, 22, 50, 55, 295, 0, 2, 48, 5380, 113, 2, 1746, 99, 1299, 84, 5, 4763, 0], [269, 'worry.He', 10, 80, 'acrobat', 3056], [2, 54, 0], []]\n",
      "\n",
      " [[1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 0, 1, 1, 0, 1], [1, 1, 1], []]\n",
      "\n",
      " 0 0 0 0\n",
      "\n",
      " 2 1 1 1\n"
     ]
    }
   ],
   "source": [
    "import pre_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_dataset = pre_process.transformed_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11118"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(my_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class chr_rnn(nn.Module):\n",
    "    def __init__(self, hidden_size, bidirectional):\n",
    "        super(chr_rnn, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        if(bidirectional == True):\n",
    "            self.bidirectional = 2\n",
    "        else:\n",
    "            self.bidirectional = 1\n",
    "        self.chr_rnn = nn.GRU(100, 100, bidirectional = bidirectional)\n",
    "        \n",
    "        \n",
    "    def forward(self,char,h0):\n",
    "        _,h0 = self.chr_rnn(char,h0)\n",
    "        return h0\n",
    "        \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(self.bidirectional , 1, self.hidden_size, device=device)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "class last_net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(last_net, self).__init__()\n",
    "        self.lastnet = nn.Linear(200,100)\n",
    "        \n",
    "    def forward(self,last_hidden_state):\n",
    "        last_w = self.lastnet(last_hidden_state)\n",
    "        return last_w\n",
    "  \n",
    "    \n",
    "chr_rnn_1 = chr_rnn(100, True).cuda()\n",
    "last_net_1 = last_net().cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading chr\n",
      "loading last\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile('/home/jongsu/Desktop/intention_extraction/chr_parameter/my_character_rnn_526.pth'):\n",
    "    print(\"loading chr\")\n",
    "    chr_rnn_1.load_state_dict(torch.load('/home/jongsu/Desktop/intention_extraction/chr_parameter/my_character_rnn_526.pth'))\n",
    "\n",
    "if os.path.isfile('/home/jongsu/Desktop/intention_extraction/chr_parameter/my_character_linear_526.pth'):\n",
    "    print(\"loading last\")\n",
    "    last_net_1.load_state_dict(torch.load('/home/jongsu/Desktop/intention_extraction/chr_parameter/my_character_linear_526.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wv_model_en = word2vec.Word2Vec(size=100, window=5, min_count=5, workers=4)\n",
    "wv_model_en = word2vec.Word2Vec.load('/home/jongsu/Desktop/intention_extraction/wv_parameter/dialogue_wv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class makesent_gru(nn.Module):\n",
    "    def __init__(self, hidden_size, bidirectional):\n",
    "        super(makesent_gru, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        if(bidirectional == True):\n",
    "            self.bidirectional = 2\n",
    "        else:\n",
    "            self.bidirectional = 1\n",
    "        self.gru = nn.GRU(100, 100, bidirectional = bidirectional)\n",
    "        \n",
    "        \n",
    "    def forward(self,char,h0):\n",
    "        gru,h0 = self.gru(char,h0)\n",
    "        return h0\n",
    "        \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(self.bidirectional , 1, self.hidden_size, device=device)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def log_sum_exp(vec):\n",
    "    max_score = vec[0, argmax(vec)]\n",
    "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
    "    return max_score + \\\n",
    "        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n",
    "def argmax(vec):\n",
    "    # return the argmax as a python int\n",
    "    _, idx = torch.max(vec, 1)\n",
    "    return idx.item()\n",
    "\n",
    "\n",
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = [to_ix[w] for w in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class BiGru_CRF(nn.Module):\n",
    "    def __init__(self, tagset_set ,hidden_dim):\n",
    "        super(BiGru_CRF, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.tagset_size = len(tagset_set)\n",
    "\n",
    "        \n",
    "        self.gru = nn.GRU(100, 100, bidirectional=True)\n",
    "        self.gru_postp = nn.Linear(200,100)\n",
    "        \n",
    "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size+2)\n",
    "        self.transitions = nn.Parameter(torch.randn(self.tagset_size + 2, self.tagset_size + 2))\n",
    "        self.hidden = self.init_hidden()\n",
    "        \n",
    "        self.transitions.data[0, :] = -10000\n",
    "        self.transitions.data[:, 29] = -10000\n",
    "        \n",
    "    def init_hidden(self):\n",
    "        return (torch.zeros(2, 1, self.hidden_dim).cuda())\n",
    "\n",
    "        \n",
    "    def _forward_alg(self, feats):\n",
    "        \n",
    "        # Do the forward algorithm to compute the partition function\n",
    "        init_alphas = torch.full((1, self.tagset_size+2), -10000.).cuda()\n",
    "        init_alphas[0][0] = 0.\n",
    "\n",
    "        forward_var = init_alphas\n",
    "\n",
    "        # Iterate through the sentence\n",
    "        for feat in feats:\n",
    "            alphas_t = []  # The forward tensors at this timestep\n",
    "            for next_tag in range(self.tagset_size+2):\n",
    "                # broadcast the emission score: it is the same regardless of\n",
    "                # the previous tag\n",
    "                emit_score = feat[next_tag].view(1, -1).expand(1, self.tagset_size+2)\n",
    "                # the ith entry of trans_score is the score of transitioning to\n",
    "                # next_tag from i\n",
    "                trans_score = self.transitions[next_tag].view(1, -1)\n",
    "                # The ith entry of next_tag_var is the value for the\n",
    "                # edge (i -> next_tag) before we do log-sum-exp\n",
    "                \n",
    "                next_tag_var = forward_var + trans_score + emit_score\n",
    "                # The forward variable for this tag is log-sum-exp of all the\n",
    "                # scores.\n",
    "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
    "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
    "            \n",
    "        terminal_var = forward_var  + self.transitions[29]\n",
    "        alpha = log_sum_exp(terminal_var)\n",
    "        return alpha\n",
    "    \n",
    "    def _get_gru_features(self, sentence):\n",
    "        \n",
    "        self.hidden = self.init_hidden()\n",
    "        gru_out, self.hidden = self.gru(sentence, self.hidden)\n",
    "        gru_out = self.gru_postp(gru_out)\n",
    "        gru_out = gru_out.view(len(sentence), 100)\n",
    "        gru_feats = self.hidden2tag(gru_out)\n",
    "        return gru_feats\n",
    "    \n",
    "    def _score_sentence(self, feats, tags):\n",
    "        # Gives the score of a provided tag sequence\n",
    "        score = torch.zeros(1).cuda()\n",
    "        tags = np.append(0,tags)\n",
    "        \n",
    "        my_feats = feats\n",
    "        for i, feat in enumerate(my_feats):\n",
    "            score = score + \\\n",
    "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
    "\n",
    "                \n",
    "        score = score + self.transitions[29][tags[i+1]]\n",
    "        \n",
    "        return score\n",
    "    \n",
    "    def neg_log_likelihood(self, sentence, tags):\n",
    "        \n",
    "        feats = self._get_gru_features(sentence)\n",
    "        forward_score = self._forward_alg(feats)\n",
    "        \n",
    "        gold_score = self._score_sentence(feats, tags)\n",
    "        return forward_score - gold_score\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    def _viterbi_decode(self, feats):\n",
    "        backpointers = []\n",
    "\n",
    "        # Initialize the viterbi variables in log space\n",
    "        init_vvars = torch.full((1, 30), -10000.).cuda()\n",
    "        init_vvars[0][0] = 0\n",
    "\n",
    "        # forward_var at step i holds the viterbi variables for step i-1\n",
    "        forward_var = init_vvars\n",
    "        for feat in feats:\n",
    "            bptrs_t = []  # holds the backpointers for this step\n",
    "            viterbivars_t = []  # holds the viterbi variables for this step\n",
    "\n",
    "            for next_tag in range(self.tagset_size+2):\n",
    "                \n",
    "                next_tag_var = forward_var + self.transitions[next_tag]\n",
    "                best_tag_id = argmax(next_tag_var)\n",
    "                bptrs_t.append(best_tag_id)\n",
    "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
    "            \n",
    "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
    "            backpointers.append(bptrs_t)\n",
    "\n",
    "        \n",
    "        terminal_var = forward_var + self.transitions[29]\n",
    "        best_tag_id = argmax(terminal_var)\n",
    "        path_score = terminal_var[0][best_tag_id]\n",
    "\n",
    "        \n",
    "        best_path = [best_tag_id]\n",
    "        for bptrs_t in reversed(backpointers):\n",
    "            best_tag_id = bptrs_t[best_tag_id]\n",
    "            best_path.append(best_tag_id)\n",
    "        # Pop off the start tag (we dont want to return that to the caller)\n",
    "        start = best_path.pop()\n",
    "        assert start == 0  # Sanity check\n",
    "        best_path.reverse()\n",
    "        return path_score, best_path\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def forward(self, sentence):  # dont confuse this with _forward_alg above.\n",
    "        # Get the emission scores from the BiLSTM\n",
    "        lstm_feats = self._get_gru_features(sentence)\n",
    "\n",
    "        # Find the best path, given the features.\n",
    "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
    "        return score, tag_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class last_sent_net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(last_sent_net, self).__init__()\n",
    "        self.lastnet = nn.Linear(200,100)\n",
    "        \n",
    "    def forward(self,last_hidden_state):\n",
    "        last_w = self.lastnet(last_hidden_state)\n",
    "        return last_w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagset = torch.tensor(np.arange(28),device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentence_1 = makesent_gru(100,True).cuda()\n",
    "last_sent_net1 = last_sent_net().cuda()\n",
    "Bigru_crf1 = BiGru_CRF(tagset,100).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading crf\n",
      "loading last\n",
      "loading last\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if os.path.isfile('/home/jongsu/Desktop/intention_extraction/crf_lstm_parameter/9_Bigru_crf.pth'):\n",
    "    print(\"loading crf\")\n",
    "    Bigru_crf1.load_state_dict(torch.load('/home/jongsu/Desktop/intention_extraction/crf_lstm_parameter/9_Bigru_crf.pth'))\n",
    "\n",
    "if os.path.isfile('/home/jongsu/Desktop/intention_extraction/crf_lstm_parameter/9_last_sent_net.pth'):\n",
    "    print(\"loading last\")\n",
    "    last_sent_net1.load_state_dict(torch.load('/home/jongsu/Desktop/intention_extraction/crf_lstm_parameter/9_last_sent_net.pth'))\n",
    "    \n",
    "if os.path.isfile('/home/jongsu/Desktop/intention_extraction/crf_lstm_parameter/9_sentence_.pth'):\n",
    "    print(\"loading last\")\n",
    "    sentence_1.load_state_dict(torch.load('/home/jongsu/Desktop/intention_extraction/crf_lstm_parameter/9_sentence_.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new iter\n",
      "cal grad..\n",
      "tensor([ 4.6903], device='cuda:0')\n",
      "new iter\n",
      "cal grad..\n",
      "tensor([ 4.5824], device='cuda:0')\n",
      "new iter\n",
      "cal grad..\n",
      "tensor([ 4.4799], device='cuda:0')\n",
      "new iter\n",
      "cal grad..\n",
      "tensor([ 4.3825], device='cuda:0')\n",
      "new iter\n",
      "cal grad..\n",
      "tensor([ 4.2897], device='cuda:0')\n",
      "new iter\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-07d5250d0c5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mresh_stv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msent_to_vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mtorch_make_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmake_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBigru_crf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg_log_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresh_stv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmake_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0;31m## lstm_crf training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-9b12dca92eb8>\u001b[0m in \u001b[0;36mneg_log_likelihood\u001b[0;34m(self, sentence, tags)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_gru_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mforward_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_alg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mgold_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_score_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-9b12dca92eb8>\u001b[0m in \u001b[0;36m_forward_alg\u001b[0;34m(self, feats)\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0;31m# The forward variable for this tag is log-sum-exp of all the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0;31m# scores.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                 \u001b[0malphas_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_sum_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_tag_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0mforward_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malphas_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-3b9f0baf230d>\u001b[0m in \u001b[0;36mlog_sum_exp\u001b[0;34m(vec)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmax_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmax_score_broadcast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmax_score\u001b[0m \u001b[0;34m+\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmax_score_broadcast\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# return the argmax as a python int\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer1 = optim.SGD(Bigru_crf1.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "optimizer2 = optim.SGD(sentence_1.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "optimizer3 = optim.SGD(last_sent_net1.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "epoch = 0\n",
    "\n",
    "save_path = ''\n",
    "while(epoch < 100): \n",
    "    \n",
    "    total_lss = 0\n",
    "    dialogue_idx = 0\n",
    "    print(\"new iter\")\n",
    "    while(dialogue_idx < len(my_dataset)):\n",
    "        \n",
    "        #print(\"dialogue_idx\",dialogue_idx)\n",
    "        per_dialogue = my_dataset[dialogue_idx]\n",
    "        sent_idx = 0\n",
    "        new_sent_to_vec = []\n",
    "        sent_to_vec = torch.tensor(new_sent_to_vec).cuda()\n",
    "        \n",
    "        make_label = []\n",
    "        while(sent_idx < len(per_dialogue['dialogue'][0]) -1): #indexed dialogue\n",
    "            \n",
    "            \n",
    "            \n",
    "            ## sent_lstm training\n",
    "            sent = per_dialogue['dialogue'][0][sent_idx]\n",
    "            sent_len = len(per_dialogue['dialogue'][0][sent_idx]) \n",
    "            \n",
    "            word_idx = 0\n",
    "            vec = []\n",
    "            \n",
    "            while(word_idx < sent_len): \n",
    "                \n",
    "                \n",
    "                encoder_hidden = chr_rnn_1.initHidden()\n",
    "                if per_dialogue['dialogue'][1][sent_idx][word_idx] == 1: #word_to_vec\n",
    "                    word_to_tensor = torch.tensor(wv_model_en.wv[wv_model_en.wv.index2entity[sent[word_idx]]])\n",
    "                    gpu_wt = word_to_tensor.cuda()\n",
    "                    vec.append(gpu_wt) #append known word vec\n",
    "                else: #character model\n",
    "                    for ei in range(len(sent[word_idx])):\n",
    "                        gru_input = torch.tensor(np.zeros(shape = (1, 1, 100), dtype=\"float32\")).cuda()\n",
    "                        gru_input[0][0][ord(sent[word_idx][ei])%100] = 1 #character to onehot vec\n",
    "                        encoder_hidden = chr_rnn_1(gru_input,encoder_hidden)\n",
    "\n",
    "                    last_encoder_hidden = encoder_hidden.view(-1,200)\n",
    "                    last_encoder_hidden_ = last_net_1(last_encoder_hidden) #last hiddenstate and fully c l\n",
    "                    vec.append(last_encoder_hidden_) #append unknown word vec\n",
    "                word_idx = word_idx + 1\n",
    "            \n",
    "            \n",
    "            word_idx = 0 \n",
    "            \n",
    "            sent_hidden = sentence_1.initHidden()\n",
    "            \n",
    "            \n",
    "            while(word_idx<sent_len):\n",
    "\n",
    "                view = vec[word_idx].view(1,1,100)\n",
    "                sent_hidden = sentence_1(view,sent_hidden)\n",
    "                word_idx = word_idx + 1\n",
    "            \n",
    "            # 200 -> 100\n",
    "            \n",
    "            sent_vec = last_sent_net1(sent_hidden.view(-1,200))\n",
    "            sent_to_vec = torch.cat((sent_to_vec,sent_vec),0)\n",
    "            \n",
    "            try:\n",
    "                index1_toint = int(per_dialogue['label'][0][sent_idx*2]) *4\n",
    "                index2_toint = int(per_dialogue['label'][1][sent_idx*2])\n",
    "                make_label.append(index1_toint + index2_toint)\n",
    "            except:\n",
    "                print(\"data_err\")\n",
    "                make_label.append(0)\n",
    "            \n",
    "            sent_idx = sent_idx + 1\n",
    "        \n",
    "\n",
    "        resh_stv = sent_to_vec.view(-1,1,100)\n",
    "        torch_make_label = torch.tensor(make_label).cuda()\n",
    "        loss = Bigru_crf1.neg_log_likelihood(resh_stv, make_label)\n",
    "        ## lstm_crf training\n",
    "        \n",
    "        dialogue_idx = dialogue_idx + 1\n",
    "        \n",
    "        total_lss = total_lss + loss\n",
    "        \n",
    "        if(dialogue_idx % 1 ==0):\n",
    "            print(\"cal grad..\")\n",
    "            Bigru_crf1.zero_grad()\n",
    "            sentence_1.zero_grad()\n",
    "            last_sent_net1.zero_grad()\n",
    "            \n",
    "            total_lss.backward()\n",
    "            \n",
    "            \n",
    "            print(total_lss)\n",
    "            \n",
    "            optimizer1.step()\n",
    "            optimizer2.step()\n",
    "            optimizer3.step()\n",
    "            \n",
    "            total_lss = 0\n",
    "            \n",
    "            torch.save(Bigru_crf1.state_dict(),'/home/jongsu/Desktop/intention_extraction/crf_lstm_parameter/90_Bigru_crf.ckpt')\n",
    "            torch.save(sentence_1.state_dict(),'/home/jongsu/Desktop/intention_extraction/crf_lstm_parameter/90_sentence_.ckpt')\n",
    "            torch.save(last_sent_net1.state_dict(),'/home/jongsu/Desktop/intention_extraction/crf_lstm_parameter/90_last_sent_net.ckpt')\n",
    "\n",
    "            torch.save(Bigru_crf1.state_dict(),'/home/jongsu/Desktop/intention_extraction/crf_lstm_parameter/90_Bigru_crf.pkl')\n",
    "            torch.save(sentence_1.state_dict(),'/home/jongsu/Desktop/intention_extraction/crf_lstm_parameter/90_sentence_.pkl')\n",
    "            torch.save(last_sent_net1.state_dict(),'/home/jongsu/Desktop/intention_extraction/crf_lstm_parameter/90_last_sent_net.pkl')\n",
    "\n",
    "            torch.save(Bigru_crf1.state_dict(),'/home/jongsu/Desktop/intention_extraction/crf_lstm_parameter/90_Bigru_crf.pth')\n",
    "            torch.save(sentence_1.state_dict(),'/home/jongsu/Desktop/intention_extraction/crf_lstm_parameter/90_sentence_.pth')\n",
    "            torch.save(last_sent_net1.state_dict(),'/home/jongsu/Desktop/intention_extraction/crf_lstm_parameter/90_last_sent_net.pth')\n",
    "        \n",
    "    epoch = epoch + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(67.2152, device='cuda:0'), [3, 4, 2, 2, 2, 3, 20, 17, 19, 20])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bigru_crf1(resh_stv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3-4.2.0]",
   "language": "python",
   "name": "conda-env-anaconda3-4.2.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
