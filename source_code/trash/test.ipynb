{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "new_label = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_label = np.append(new_label,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input = torch.zeros(3, 5, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = torch.randn(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    nan,     nan,     nan, -1.1023, -0.7548])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = torch.randn(5)\n",
    "a\n",
    "\n",
    "torch.log(a)\n",
    "tensor([ nan,  nan,  nan,  nan,  nan])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jongsu/.pyenv/versions/anaconda3-4.2.0/lib/python3.5/site-packages/ipykernel/__main__.py:1: RuntimeWarning: divide by zero encountered in log\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([      -inf, 1.38629436, 1.38629436])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "target = torch.tensor([ 0.,  4.,  4.])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   -inf,  1.3863,  1.3863])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  4,  4])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "#import tensorflow as tf\n",
    "\n",
    "import io\n",
    "from gensim.models import word2vec\n",
    "\n",
    "from io import StringIO\n",
    "from pprint import pprint\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "import torch.utils.data\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = torch.tensor([[ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.],\n",
    "        [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.],\n",
    "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.],\n",
    "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.],\n",
    "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.],\n",
    "        [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.],\n",
    "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.],\n",
    "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.],\n",
    "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.],\n",
    "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 28])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "input_v = torch.randn(10,1,100)\n",
    "\n",
    "criterian = nn.MSELoss()\n",
    "\n",
    "class Gru(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_dim):\n",
    "        super(Gru, self).__init__()\n",
    "        self.gru = nn.GRU(100,100,bidirectional = True)\n",
    "        self.inh = torch.zeros(2, 1, 100)\n",
    "        self.nn = nn.Linear(200,100)\n",
    "        self.nn2 = nn.Linear(100,28)\n",
    "        \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(2, 1, 100)\n",
    "   \n",
    "    def forward(self, sentence):  \n",
    "        output,hidden = gru(sentence,self.inh)\n",
    "        output = self.nn(output.view(10,200))\n",
    "        output2 = self.nn2(output)\n",
    "        return output2,hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gru1 = Gru(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 28])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer1 = optim.SGD(gru1.parameters(), lr=0.1, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.00000e-05 *\n",
      "       5.7007)\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "while(i < 1000):\n",
    "    i = i + 1\n",
    "    output,_ = gru1(input_v)\n",
    "    loss = criterian(output,a)\n",
    "    optimizer1.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer1.step()\n",
    "    if i == 1000:\n",
    "        print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'makesent_gru' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-039bb2d44666>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msent_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmakesent_gru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlast_sent_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlast_sent_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mGru1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtagset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'makesent_gru' is not defined"
     ]
    }
   ],
   "source": [
    "sent_1 = makesent_gru(100,True).cuda()\n",
    "last_sent_1 = last_sent_net().cuda()\n",
    "Gru1 = Gru(tagset,100).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fe0d4121cf0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def argmax(vec):\n",
    "    # return the argmax as a python int\n",
    "    _, idx = torch.max(vec, 1)\n",
    "    return idx.item()\n",
    "\n",
    "\n",
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = [to_ix[w] for w in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "\n",
    "# Compute log sum exp in a numerically stable way for the forward algorithm\n",
    "def log_sum_exp(vec):\n",
    "    max_score = vec[0, argmax(vec)]\n",
    "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
    "    return max_score + \\\n",
    "        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BiLSTM_CRF(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim):\n",
    "        super(BiLSTM_CRF, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.tag_to_ix = tag_to_ix\n",
    "        self.tagset_size = len(tag_to_ix)\n",
    "\n",
    "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
    "                            num_layers=1, bidirectional=True)\n",
    "\n",
    "        # Maps the output of the LSTM into tag space.\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
    "\n",
    "        # Matrix of transition parameters.  Entry i,j is the score of\n",
    "        # transitioning *to* i *from* j.\n",
    "        self.transitions = nn.Parameter(\n",
    "            torch.randn(self.tagset_size, self.tagset_size))\n",
    "\n",
    "        # These two statements enforce the constraint that we never transfer\n",
    "        # to the start tag and we never transfer from the stop tag\n",
    "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
    "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
    "\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return (torch.randn(2, 1, self.hidden_dim // 2),\n",
    "                torch.randn(2, 1, self.hidden_dim // 2))\n",
    "\n",
    "    def _forward_alg(self, feats):\n",
    "        # Do the forward algorithm to compute the partition function\n",
    "        init_alphas = torch.full((1, self.tagset_size), -10000.)\n",
    "        # START_TAG has all of the score.\n",
    "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
    "\n",
    "        # Wrap in a variable so that we will get automatic backprop\n",
    "        forward_var = init_alphas\n",
    "\n",
    "        # Iterate through the sentence\n",
    "        for feat in feats:\n",
    "            alphas_t = []  # The forward tensors at this timestep\n",
    "            for next_tag in range(self.tagset_size):\n",
    "                # broadcast the emission score: it is the same regardless of\n",
    "                # the previous tag\n",
    "                emit_score = feat[next_tag].view(\n",
    "                    1, -1).expand(1, self.tagset_size)\n",
    "                # the ith entry of trans_score is the score of transitioning to\n",
    "                # next_tag from i\n",
    "                trans_score = self.transitions[next_tag].view(1, -1)\n",
    "                # The ith entry of next_tag_var is the value for the\n",
    "                # edge (i -> next_tag) before we do log-sum-exp\n",
    "                next_tag_var = forward_var + trans_score + emit_score\n",
    "                # The forward variable for this tag is log-sum-exp of all the\n",
    "                # scores.\n",
    "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
    "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
    "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
    "        alpha = log_sum_exp(terminal_var)\n",
    "        return alpha\n",
    "\n",
    "    def _get_lstm_features(self, sentence):\n",
    "        self.hidden = self.init_hidden()\n",
    "        embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
    "        lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n",
    "        lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n",
    "        lstm_feats = self.hidden2tag(lstm_out)\n",
    "        return lstm_feats\n",
    "\n",
    "    def _score_sentence(self, feats, tags):\n",
    "        # Gives the score of a provided tag sequence\n",
    "        score = torch.zeros(1)\n",
    "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long), tags])\n",
    "        for i, feat in enumerate(feats):\n",
    "            score = score + \\\n",
    "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
    "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
    "        return score\n",
    "\n",
    "    def _viterbi_decode(self, feats):\n",
    "        backpointers = []\n",
    "\n",
    "        # Initialize the viterbi variables in log space\n",
    "        init_vvars = torch.full((1, self.tagset_size), -10000.)\n",
    "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
    "\n",
    "        # forward_var at step i holds the viterbi variables for step i-1\n",
    "        forward_var = init_vvars\n",
    "        for feat in feats:\n",
    "            bptrs_t = []  # holds the backpointers for this step\n",
    "            viterbivars_t = []  # holds the viterbi variables for this step\n",
    "\n",
    "            for next_tag in range(self.tagset_size):\n",
    "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
    "                # previous step, plus the score of transitioning\n",
    "                # from tag i to next_tag.\n",
    "                # We don't include the emission scores here because the max\n",
    "                # does not depend on them (we add them in below)\n",
    "                next_tag_var = forward_var + self.transitions[next_tag]\n",
    "                best_tag_id = argmax(next_tag_var)\n",
    "                bptrs_t.append(best_tag_id)\n",
    "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
    "            # Now add in the emission scores, and assign forward_var to the set\n",
    "            # of viterbi variables we just computed\n",
    "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
    "            backpointers.append(bptrs_t)\n",
    "\n",
    "        # Transition to STOP_TAG\n",
    "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
    "        best_tag_id = argmax(terminal_var)\n",
    "        path_score = terminal_var[0][best_tag_id]\n",
    "\n",
    "        # Follow the back pointers to decode the best path.\n",
    "        best_path = [best_tag_id]\n",
    "        for bptrs_t in reversed(backpointers):\n",
    "            best_tag_id = bptrs_t[best_tag_id]\n",
    "            best_path.append(best_tag_id)\n",
    "        # Pop off the start tag (we dont want to return that to the caller)\n",
    "        start = best_path.pop()\n",
    "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
    "        best_path.reverse()\n",
    "        return path_score, best_path\n",
    "\n",
    "    def neg_log_likelihood(self, sentence, tags):\n",
    "        feats = self._get_lstm_features(sentence)\n",
    "        forward_score = self._forward_alg(feats)\n",
    "        gold_score = self._score_sentence(feats, tags)\n",
    "        return forward_score - gold_score\n",
    "\n",
    "    def forward(self, sentence):  # dont confuse this with _forward_alg above.\n",
    "        # Get the emission scores from the BiLSTM\n",
    "        lstm_feats = self._get_lstm_features(sentence)\n",
    "\n",
    "        # Find the best path, given the features.\n",
    "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
    "        return score, tag_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B', 'I', 'O', 'O', 'O', 'O', 'B']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_to_ix[STOP_TAG]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(9.2679), [1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "tensor([ 0.4140])\n",
      "tensor([ 12.1252])\n",
      "tensor([ 6.4185])\n",
      "tensor([ 12.1535])\n",
      "tensor([ 6.2530])\n",
      "tensor([ 12.1136])\n",
      "tensor([ 6.1449])\n",
      "tensor([ 11.6606])\n",
      "tensor([ 5.9908])\n",
      "tensor([ 11.7309])\n",
      "tensor([ 6.1294])\n",
      "tensor([ 11.5203])\n",
      "tensor([ 5.7167])\n",
      "tensor([ 11.4807])\n",
      "tensor([ 5.9719])\n",
      "tensor([ 11.1596])\n",
      "tensor([ 5.7693])\n",
      "tensor([ 11.1812])\n",
      "tensor([ 5.9796])\n",
      "tensor([ 10.9413])\n",
      "tensor([ 5.8421])\n",
      "tensor([ 10.9456])\n",
      "tensor([ 5.5421])\n",
      "tensor([ 10.9473])\n",
      "tensor([ 5.8403])\n",
      "tensor([ 10.7281])\n",
      "tensor([ 5.5389])\n",
      "tensor([ 10.4887])\n",
      "tensor([ 5.5332])\n",
      "tensor([ 10.3875])\n",
      "tensor([ 5.5609])\n",
      "tensor([ 10.1276])\n",
      "tensor([ 5.6570])\n",
      "tensor([ 10.1859])\n",
      "tensor([ 5.2119])\n",
      "tensor([ 9.9699])\n",
      "tensor([ 5.2201])\n",
      "tensor([ 10.0854])\n",
      "tensor([ 5.6123])\n",
      "tensor([ 9.7510])\n",
      "tensor([ 5.5170])\n",
      "tensor([ 9.7477])\n",
      "tensor([ 5.1390])\n",
      "tensor([ 9.8829])\n",
      "tensor([ 5.1448])\n",
      "tensor([ 9.7941])\n",
      "tensor([ 4.9904])\n",
      "tensor([ 9.5157])\n",
      "tensor([ 5.2309])\n",
      "tensor([ 9.4689])\n",
      "tensor([ 4.8448])\n",
      "tensor([ 9.5186])\n",
      "tensor([ 4.9510])\n",
      "tensor([ 9.5698])\n",
      "tensor([ 4.9223])\n",
      "tensor([ 9.2297])\n",
      "tensor([ 4.7118])\n",
      "tensor([ 9.1265])\n",
      "tensor([ 4.6763])\n",
      "tensor([ 8.9981])\n",
      "tensor([ 4.7453])\n",
      "tensor([ 8.9728])\n",
      "tensor([ 4.6053])\n",
      "tensor([ 8.9466])\n",
      "tensor([ 4.7839])\n",
      "tensor([ 8.7679])\n",
      "tensor([ 5.2122])\n",
      "tensor([ 8.9760])\n",
      "tensor([ 4.5978])\n",
      "tensor([ 8.6688])\n",
      "tensor([ 4.3746])\n",
      "tensor([ 8.6508])\n",
      "tensor([ 4.8004])\n",
      "tensor([ 8.4273])\n",
      "tensor([ 4.5365])\n",
      "tensor([ 8.7982])\n",
      "tensor([ 4.3975])\n",
      "tensor([ 8.5770])\n",
      "tensor([ 4.3477])\n",
      "tensor([ 8.5458])\n",
      "tensor([ 4.3241])\n",
      "tensor([ 8.4353])\n",
      "tensor([ 4.5619])\n",
      "tensor([ 8.3948])\n",
      "tensor([ 4.2551])\n",
      "tensor([ 8.3578])\n",
      "tensor([ 4.3726])\n",
      "tensor([ 8.1370])\n",
      "tensor([ 4.2461])\n",
      "tensor([ 8.2079])\n",
      "tensor([ 4.7795])\n",
      "tensor([ 8.0740])\n",
      "tensor([ 4.5162])\n",
      "tensor([ 8.1919])\n",
      "tensor([ 4.4553])\n",
      "tensor([ 7.7565])\n",
      "tensor([ 4.4739])\n",
      "tensor([ 7.7087])\n",
      "tensor([ 4.2045])\n",
      "tensor([ 8.0725])\n",
      "tensor([ 3.9714])\n",
      "tensor([ 7.6741])\n",
      "tensor([ 4.1529])\n",
      "tensor([ 7.9384])\n",
      "tensor([ 3.9441])\n",
      "tensor([ 7.7695])\n",
      "tensor([ 3.8368])\n",
      "tensor([ 7.8490])\n",
      "tensor([ 3.9799])\n",
      "tensor([ 7.4294])\n",
      "tensor([ 3.8133])\n",
      "tensor([ 7.4308])\n",
      "tensor([ 3.8320])\n",
      "tensor([ 7.6587])\n",
      "tensor([ 3.8982])\n",
      "tensor([ 7.4088])\n",
      "tensor([ 4.1206])\n",
      "tensor([ 7.6341])\n",
      "tensor([ 3.7745])\n",
      "tensor([ 7.2851])\n",
      "tensor([ 3.5842])\n",
      "tensor([ 7.2647])\n",
      "tensor([ 4.3268])\n",
      "tensor([ 7.1526])\n",
      "tensor([ 3.8504])\n",
      "tensor([ 7.3193])\n",
      "tensor([ 3.5042])\n",
      "tensor([ 7.2967])\n",
      "tensor([ 3.4734])\n",
      "tensor([ 7.1351])\n",
      "tensor([ 3.7165])\n",
      "tensor([ 7.1976])\n",
      "tensor([ 3.7039])\n",
      "tensor([ 7.1549])\n",
      "tensor([ 3.3984])\n",
      "tensor([ 7.1359])\n",
      "tensor([ 3.2226])\n",
      "tensor([ 7.0658])\n",
      "tensor([ 3.6752])\n",
      "tensor([ 6.5833])\n",
      "tensor([ 3.3897])\n",
      "tensor([ 6.6745])\n",
      "tensor([ 3.1308])\n",
      "tensor([ 6.9026])\n",
      "tensor([ 3.3394])\n",
      "tensor([ 6.7174])\n",
      "tensor([ 3.4368])\n",
      "tensor([ 6.8131])\n",
      "tensor([ 3.3539])\n",
      "tensor([ 6.6650])\n",
      "tensor([ 2.9167])\n",
      "tensor([ 6.8067])\n",
      "tensor([ 3.3845])\n",
      "tensor([ 6.5391])\n",
      "tensor([ 3.1390])\n",
      "tensor([ 6.6507])\n",
      "tensor([ 3.0213])\n",
      "tensor([ 6.6109])\n",
      "tensor([ 3.3617])\n",
      "tensor([ 6.8383])\n",
      "tensor([ 2.9552])\n",
      "tensor([ 6.5238])\n",
      "tensor([ 2.9554])\n",
      "tensor([ 6.3291])\n",
      "tensor([ 3.3144])\n",
      "tensor([ 6.1463])\n",
      "tensor([ 2.9069])\n",
      "tensor([ 6.0761])\n",
      "tensor([ 3.1386])\n",
      "tensor([ 5.9671])\n",
      "tensor([ 3.1566])\n",
      "tensor([ 6.3085])\n",
      "tensor([ 3.0739])\n",
      "tensor([ 6.0782])\n",
      "tensor([ 2.8808])\n",
      "tensor([ 5.9040])\n",
      "tensor([ 2.7405])\n",
      "tensor([ 6.2331])\n",
      "tensor([ 2.6770])\n",
      "tensor([ 5.8029])\n",
      "tensor([ 2.7182])\n",
      "tensor([ 6.4105])\n",
      "tensor([ 2.6714])\n",
      "tensor([ 6.2242])\n",
      "tensor([ 2.6515])\n",
      "tensor([ 5.9152])\n",
      "tensor([ 2.7993])\n",
      "tensor([ 5.8748])\n",
      "tensor([ 3.2095])\n",
      "tensor([ 5.8168])\n",
      "tensor([ 2.6710])\n",
      "tensor([ 5.5525])\n",
      "tensor([ 2.4924])\n",
      "tensor([ 5.5827])\n",
      "tensor([ 2.4215])\n",
      "tensor([ 5.7426])\n",
      "tensor([ 2.4040])\n",
      "tensor([ 5.5332])\n",
      "tensor([ 2.5239])\n",
      "tensor([ 5.5858])\n",
      "tensor([ 2.3369])\n",
      "tensor([ 5.9829])\n",
      "tensor([ 2.5373])\n",
      "tensor([ 5.3313])\n",
      "tensor([ 2.4382])\n",
      "tensor([ 5.2006])\n",
      "tensor([ 2.4455])\n",
      "tensor([ 5.5648])\n",
      "tensor([ 2.4292])\n",
      "tensor([ 5.2366])\n",
      "tensor([ 2.6507])\n",
      "tensor([ 5.5453])\n",
      "tensor([ 2.2816])\n",
      "tensor([ 5.4189])\n",
      "tensor([ 2.0109])\n",
      "tensor([ 5.2907])\n",
      "tensor([ 2.1068])\n",
      "tensor([ 4.9361])\n",
      "tensor([ 2.2720])\n",
      "tensor([ 4.9944])\n",
      "tensor([ 2.2927])\n",
      "tensor([ 5.0934])\n",
      "tensor([ 2.0188])\n",
      "tensor([ 5.3807])\n",
      "tensor([ 2.0395])\n",
      "tensor([ 4.5279])\n",
      "tensor([ 2.1843])\n",
      "tensor([ 5.4159])\n",
      "tensor([ 2.3519])\n",
      "tensor([ 4.9631])\n",
      "tensor([ 1.8997])\n",
      "tensor([ 5.0213])\n",
      "tensor([ 2.5785])\n",
      "tensor([ 4.8745])\n",
      "tensor([ 1.9689])\n",
      "tensor([ 5.2105])\n",
      "tensor([ 2.0347])\n",
      "tensor([ 4.9975])\n",
      "tensor([ 2.5039])\n",
      "tensor([ 4.7342])\n",
      "tensor([ 1.9495])\n",
      "tensor([ 4.4897])\n",
      "tensor([ 1.8957])\n",
      "tensor([ 4.8529])\n",
      "tensor([ 1.7351])\n",
      "tensor([ 4.5206])\n",
      "tensor([ 1.7422])\n",
      "tensor([ 5.1107])\n",
      "tensor([ 2.1224])\n",
      "tensor([ 4.1098])\n",
      "tensor([ 1.9392])\n",
      "tensor([ 4.9471])\n",
      "tensor([ 1.7557])\n",
      "tensor([ 4.5250])\n",
      "tensor([ 1.7832])\n",
      "tensor([ 4.3077])\n",
      "tensor([ 1.9878])\n",
      "tensor([ 4.1392])\n",
      "tensor([ 1.8360])\n",
      "tensor([ 4.3839])\n",
      "tensor([ 1.7903])\n",
      "tensor([ 4.0431])\n",
      "tensor([ 1.7191])\n",
      "tensor([ 4.0574])\n",
      "tensor([ 1.7261])\n",
      "tensor([ 3.8015])\n",
      "tensor([ 1.6818])\n",
      "tensor([ 4.5376])\n",
      "tensor([ 1.9202])\n",
      "tensor([ 4.5465])\n",
      "tensor([ 1.6439])\n",
      "tensor([ 3.8306])\n",
      "tensor([ 1.5268])\n",
      "tensor([ 4.3984])\n",
      "tensor([ 1.8938])\n",
      "tensor([ 3.7725])\n",
      "tensor([ 1.5483])\n",
      "tensor([ 3.7821])\n",
      "tensor([ 2.4868])\n",
      "tensor([ 3.8342])\n",
      "tensor([ 1.5051])\n",
      "tensor([ 3.5446])\n",
      "tensor([ 1.5128])\n",
      "tensor([ 3.9371])\n",
      "tensor([ 1.4575])\n",
      "tensor([ 3.4875])\n",
      "tensor([ 1.4014])\n",
      "tensor([ 3.9864])\n",
      "tensor([ 1.6188])\n",
      "tensor([ 3.5322])\n",
      "tensor([ 1.2011])\n",
      "tensor([ 3.6465])\n",
      "tensor([ 1.3301])\n",
      "tensor([ 3.4666])\n",
      "tensor([ 1.2637])\n",
      "tensor([ 3.2282])\n",
      "tensor([ 1.2406])\n",
      "tensor([ 3.2113])\n",
      "tensor([ 1.3682])\n",
      "tensor([ 3.3377])\n",
      "tensor([ 1.4565])\n",
      "tensor([ 3.3106])\n",
      "tensor([ 1.1205])\n",
      "tensor([ 3.3622])\n",
      "tensor([ 1.2099])\n",
      "tensor([ 3.1414])\n",
      "tensor([ 1.1696])\n",
      "tensor([ 3.7087])\n",
      "tensor([ 1.1787])\n",
      "tensor([ 4.0067])\n",
      "tensor([ 1.6253])\n",
      "tensor([ 3.0515])\n",
      "tensor([ 1.4310])\n",
      "tensor([ 3.1544])\n",
      "tensor([ 1.1096])\n",
      "tensor([ 3.2310])\n",
      "tensor([ 1.1602])\n",
      "tensor([ 3.1173])\n",
      "tensor([ 1.0947])\n",
      "tensor([ 3.7422])\n",
      "tensor([ 1.5247])\n",
      "tensor([ 3.2013])\n",
      "tensor([ 1.3918])\n",
      "tensor([ 3.1394])\n",
      "tensor([ 1.0312])\n",
      "tensor([ 3.3962])\n",
      "tensor([ 1.0067])\n",
      "tensor([ 2.6988])\n",
      "tensor([ 1.3302])\n",
      "tensor([ 2.9762])\n",
      "tensor([ 1.0200])\n",
      "tensor([ 2.9578])\n",
      "tensor([ 0.9439])\n",
      "tensor([ 2.7946])\n",
      "tensor([ 1.1054])\n",
      "tensor([ 3.0293])\n",
      "tensor([ 0.9993])\n",
      "tensor([ 2.8375])\n",
      "tensor([ 0.9728])\n",
      "tensor([ 2.7521])\n",
      "tensor([ 1.3580])\n",
      "tensor([ 2.7927])\n",
      "tensor([ 2.0344])\n",
      "tensor([ 2.5696])\n",
      "tensor([ 1.1576])\n",
      "tensor([ 2.5633])\n",
      "tensor([ 1.5481])\n",
      "tensor([ 2.5920])\n",
      "tensor([ 1.3889])\n",
      "tensor([ 2.6270])\n",
      "tensor([ 0.7807])\n",
      "tensor([ 2.4850])\n",
      "tensor([ 0.8529])\n",
      "tensor([ 2.3161])\n",
      "tensor([ 0.8978])\n",
      "tensor([ 2.3123])\n",
      "tensor([ 0.9530])\n",
      "tensor([ 2.8119])\n",
      "tensor([ 0.8117])\n",
      "tensor([ 2.5919])\n",
      "tensor([ 0.7761])\n",
      "tensor([ 2.7004])\n",
      "tensor([ 0.9629])\n",
      "tensor([ 2.2568])\n",
      "tensor([ 0.7796])\n",
      "tensor([ 2.4820])\n",
      "tensor([ 0.8817])\n",
      "tensor([ 2.6853])\n",
      "tensor([ 0.7809])\n",
      "tensor([ 2.3830])\n",
      "tensor([ 1.1183])\n",
      "tensor([ 2.1903])\n",
      "tensor([ 0.9591])\n",
      "tensor([ 2.2244])\n",
      "tensor([ 1.0840])\n",
      "tensor([ 2.2648])\n",
      "tensor([ 1.0573])\n",
      "tensor([ 2.0452])\n",
      "tensor([ 0.7569])\n",
      "tensor([ 2.1278])\n",
      "tensor([ 0.7279])\n",
      "tensor([ 2.1779])\n",
      "tensor([ 0.8292])\n",
      "tensor([ 2.0420])\n",
      "tensor([ 0.9741])\n",
      "tensor([ 2.0229])\n",
      "tensor([ 0.6206])\n",
      "tensor([ 2.5870])\n",
      "tensor([ 0.8660])\n",
      "tensor([ 2.0594])\n",
      "tensor([ 0.7903])\n",
      "tensor([ 1.8952])\n",
      "tensor([ 0.6448])\n",
      "tensor([ 1.9827])\n",
      "tensor([ 0.9251])\n",
      "tensor([ 2.0168])\n",
      "tensor([ 0.7537])\n",
      "tensor([ 2.3939])\n",
      "tensor([ 0.5863])\n",
      "tensor([ 2.3761])\n",
      "tensor([ 0.6491])\n",
      "tensor([ 2.0810])\n",
      "tensor([ 0.7558])\n",
      "tensor([ 2.2477])\n",
      "tensor([ 1.1660])\n",
      "tensor([ 1.8102])\n",
      "tensor([ 0.5833])\n",
      "tensor([ 1.9121])\n",
      "tensor([ 0.6687])\n",
      "tensor([ 1.8587])\n",
      "tensor([ 0.6151])\n",
      "tensor([ 1.6832])\n",
      "tensor([ 0.5960])\n",
      "tensor([ 2.1290])\n",
      "tensor([ 0.9553])\n",
      "tensor([ 1.8122])\n",
      "tensor([ 0.5854])\n",
      "tensor([ 1.7701])\n",
      "tensor([ 0.6137])\n",
      "tensor([ 1.7141])\n",
      "tensor([ 0.7604])\n",
      "tensor([ 1.6793])\n",
      "tensor([ 0.7114])\n",
      "tensor([ 1.7181])\n",
      "tensor([ 0.5805])\n",
      "tensor([ 1.6775])\n",
      "tensor([ 0.5371])\n",
      "tensor([ 1.5659])\n",
      "tensor([ 0.5796])\n",
      "tensor([ 1.7077])\n",
      "tensor([ 0.6144])\n",
      "tensor([ 1.5749])\n",
      "tensor([ 0.6278])\n",
      "tensor([ 1.8756])\n",
      "tensor([ 0.5266])\n",
      "tensor([ 1.6030])\n",
      "tensor([ 0.5252])\n",
      "tensor([ 1.5449])\n",
      "tensor([ 0.7025])\n",
      "tensor([ 1.5736])\n",
      "tensor([ 0.8168])\n",
      "tensor([ 1.6233])\n",
      "tensor([ 0.5059])\n",
      "tensor([ 1.5714])\n",
      "tensor([ 0.4813])\n",
      "tensor([ 1.5080])\n",
      "tensor([ 0.6096])\n",
      "tensor([ 1.5588])\n",
      "tensor([ 0.5322])\n",
      "tensor([ 1.6953])\n",
      "tensor([ 0.5297])\n",
      "tensor([ 1.4272])\n",
      "tensor([ 0.4739])\n",
      "tensor([ 1.7704])\n",
      "tensor([ 0.5736])\n",
      "tensor([ 1.7917])\n",
      "tensor([ 0.5332])\n",
      "tensor([ 1.9734])\n",
      "tensor([ 0.4547])\n",
      "tensor([ 1.4057])\n",
      "tensor([ 0.4379])\n",
      "tensor([ 1.4281])\n",
      "tensor([ 0.4688])\n",
      "tensor([ 1.3283])\n",
      "tensor([ 0.4027])\n",
      "tensor([ 1.5912])\n",
      "tensor([ 0.5628])\n",
      "tensor([ 1.3709])\n",
      "tensor([ 0.4709])\n",
      "tensor([ 1.3944])\n",
      "tensor([ 0.5562])\n",
      "tensor([ 1.4006])\n",
      "tensor([ 0.4257])\n",
      "tensor([ 2.1293])\n",
      "tensor([ 0.4998])\n",
      "tensor([ 1.2933])\n",
      "tensor([ 0.4938])\n",
      "tensor([ 1.3386])\n",
      "tensor([ 0.6257])\n",
      "tensor([ 1.2691])\n",
      "tensor([ 0.4099])\n",
      "tensor([ 1.3018])\n",
      "tensor([ 0.4637])\n",
      "tensor([ 1.3003])\n",
      "tensor([ 0.4737])\n",
      "tensor([ 1.3034])\n",
      "tensor([ 0.4064])\n",
      "tensor([ 1.2986])\n",
      "tensor([ 0.5365])\n",
      "tensor([ 1.2166])\n",
      "tensor([ 0.3936])\n",
      "tensor([ 1.3099])\n",
      "tensor([ 1.9355])\n",
      "tensor([ 1.2774])\n",
      "tensor([ 0.4140])\n",
      "tensor([ 1.1722])\n",
      "tensor([ 0.4252])\n",
      "tensor([ 1.2500])\n",
      "tensor([ 0.4490])\n",
      "tensor([ 1.2418])\n",
      "tensor([ 0.3715])\n",
      "tensor([ 1.5881])\n",
      "tensor([ 0.3314])\n",
      "tensor([ 1.3897])\n",
      "tensor([ 0.3990])\n",
      "tensor([ 1.1338])\n",
      "tensor([ 0.3480])\n",
      "tensor([ 1.2159])\n",
      "tensor([ 0.3515])\n",
      "tensor([ 1.1383])\n",
      "tensor([ 0.5168])\n",
      "tensor([ 1.3605])\n",
      "tensor([ 0.3786])\n",
      "tensor([ 1.0485])\n",
      "tensor([ 0.3651])\n",
      "tensor([ 1.0289])\n",
      "tensor([ 0.3844])\n",
      "tensor([ 1.1643])\n",
      "tensor([ 0.4260])\n",
      "tensor([ 1.4665])\n",
      "tensor([ 0.4070])\n",
      "tensor([ 1.0606])\n",
      "tensor([ 0.3266])\n",
      "tensor([ 1.0587])\n",
      "tensor([ 0.3084])\n",
      "tensor([ 1.1142])\n",
      "tensor([ 0.4176])\n",
      "tensor([ 1.1013])\n",
      "tensor([ 0.5308])\n",
      "tensor([ 1.3301])\n",
      "tensor([ 0.3462])\n",
      "tensor([ 1.1320])\n",
      "tensor([ 0.3360])\n",
      "tensor([ 1.1594])\n",
      "tensor([ 0.3115])\n",
      "tensor([ 1.1831])\n",
      "tensor([ 0.4722])\n",
      "tensor([ 1.0238])\n",
      "tensor([ 0.4001])\n",
      "tensor([ 1.0378])\n",
      "tensor([ 0.4230])\n",
      "tensor([ 1.0189])\n",
      "tensor([ 0.4143])\n",
      "tensor([ 1.0148])\n",
      "tensor([ 0.3429])\n",
      "tensor([ 1.1704])\n",
      "tensor([ 0.3718])\n",
      "tensor([ 0.9683])\n",
      "tensor([ 0.3366])\n",
      "tensor([ 0.9768])\n",
      "tensor([ 0.3276])\n",
      "tensor([ 1.2299])\n",
      "tensor([ 0.4097])\n",
      "tensor([ 0.9971])\n",
      "tensor([ 0.3469])\n",
      "tensor([ 0.9290])\n",
      "tensor([ 0.3164])\n",
      "tensor([ 0.9398])\n",
      "tensor([ 0.3187])\n",
      "tensor([ 1.0193])\n",
      "tensor([ 0.3636])\n",
      "tensor([ 0.9624])\n",
      "tensor([ 0.4211])\n",
      "tensor([ 0.8988])\n",
      "tensor([ 0.5434])\n",
      "tensor([ 0.9757])\n",
      "tensor([ 0.2915])\n",
      "tensor([ 1.1268])\n",
      "tensor([ 0.3121])\n",
      "tensor([ 1.0243])\n",
      "tensor([ 0.3504])\n",
      "tensor([ 1.0730])\n",
      "tensor([ 0.3181])\n",
      "tensor([ 1.0463])\n",
      "tensor([ 0.2655])\n",
      "tensor([ 1.0119])\n",
      "tensor([ 0.3041])\n",
      "tensor([ 0.8756])\n",
      "tensor([ 0.6524])\n",
      "tensor([ 1.1624])\n",
      "tensor([ 0.2808])\n",
      "tensor([ 0.8994])\n",
      "tensor([ 0.3951])\n",
      "tensor([ 0.9226])\n",
      "tensor([ 0.2930])\n",
      "tensor([ 1.0646])\n",
      "tensor([ 0.3937])\n",
      "tensor([ 0.9709])\n",
      "tensor([ 0.2644])\n",
      "tensor([ 0.9833])\n",
      "tensor([ 0.2893])\n",
      "tensor([ 0.8247])\n",
      "tensor([ 0.3747])\n",
      "tensor([ 0.8704])\n",
      "tensor([ 0.2920])\n",
      "tensor([ 0.8535])\n",
      "tensor([ 0.2999])\n",
      "tensor([ 0.9226])\n",
      "tensor([ 0.3842])\n",
      "tensor([ 0.8729])\n",
      "(tensor(25.6223), [0, 1, 1, 1, 2, 2, 2, 0, 1, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "START_TAG = \"<START>\"\n",
    "STOP_TAG = \"<STOP>\"\n",
    "EMBEDDING_DIM = 5\n",
    "HIDDEN_DIM = 4\n",
    "\n",
    "# Make up some training data\n",
    "training_data = [(\n",
    "    \"the wall street journal reported today that apple corporation made money\".split(),\n",
    "    \"B I I I O O O B I O O\".split()\n",
    "), (\n",
    "    \"georgia tech is a university in georgia\".split(),\n",
    "    \"B I O O O O B\".split()\n",
    ")]\n",
    "\n",
    "word_to_ix = {}\n",
    "for sentence, tags in training_data:\n",
    "    for word in sentence:\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix)\n",
    "\n",
    "tag_to_ix = {\"B\": 0, \"I\": 1, \"O\": 2, START_TAG: 3, STOP_TAG: 4}\n",
    "\n",
    "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "\n",
    "# Check predictions before training\n",
    "with torch.no_grad():\n",
    "    precheck_sent = prepare_sequence(training_data[0][0], word_to_ix)\n",
    "    precheck_tags = torch.tensor([tag_to_ix[t] for t in training_data[0][1]], dtype=torch.long)\n",
    "    print(model(precheck_sent))\n",
    "\n",
    "# Make sure prepare_sequence from earlier in the LSTM section is loaded\n",
    "for epoch in range(\n",
    "        300):  # again, normally you would NOT do 300 epochs, it is toy data\n",
    "    for sentence, tags in training_data:\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 2. Get our inputs ready for the network, that is,\n",
    "        # turn them into Tensors of word indices.\n",
    "        sentence_in = prepare_sequence(sentence, word_to_ix)\n",
    "        targets = torch.tensor([tag_to_ix[t] for t in tags], dtype=torch.long)\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        print(loss)\n",
    "        loss = model.neg_log_likelihood(sentence_in, targets)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        # calling optimizer.step()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Check predictions after training\n",
    "with torch.no_grad():\n",
    "    precheck_sent = prepare_sequence(training_data[0][0], word_to_ix)\n",
    "    print(model(precheck_sent))\n",
    "# We got it!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new iter\n",
    "cal grad..\n",
    "tensor([ 794.2930], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 768.5750], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 772.2324], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 767.0294], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 704.7906], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 648.1509], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 681.5404], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 751.5012], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 814.5165], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 910.2877], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 817.8049], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 755.5457], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 876.5235], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 684.6308], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 721.4899], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 815.0453], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 895.7427], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 797.1152], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 614.3089], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 799.6542], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 693.3326], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 702.2778], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 857.0112], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 771.6944], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 753.4550], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 870.4523], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 796.2069], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 805.6575], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 843.3562], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 769.8610], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 787.8606], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 696.3002], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 662.7785], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 696.6882], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 733.8537], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 686.6923], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 676.2560], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 735.0876], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 831.0984], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 803.6078], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 783.6475], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 854.4816], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 722.3654], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 716.2682], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 727.2023], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 704.2264], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 807.2324], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 775.9112], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 848.8185], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 953.9637], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 887.9122], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 903.1782], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 871.9648], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 809.6415], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 763.5831], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 805.4323], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 767.7202], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 827.7583], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 780.3875], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 717.5980], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 650.4529], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 742.5225], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 823.7081], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 839.6797], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 698.2926], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 911.0435], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 808.4606], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 804.3620], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 795.7551], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 808.2845], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 792.5273], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 844.9972], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 803.4642], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 699.0540], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 828.3943], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 724.0145], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 745.1006], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 782.4451], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 741.9065], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 839.9814], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 859.3087], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 697.8011], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 770.9048], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 760.1619], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 780.3185], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 738.9421], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 818.8733], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 830.8091], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 811.5193], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 824.3984], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 659.7209], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 701.9001], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 829.2281], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 794.6914], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 752.9245], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 872.0611], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 914.0952], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 723.4525], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 687.8282], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 780.0715], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 927.1405], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 826.3940], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 629.0449], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 839.7452], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 792.7134], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 774.7518], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 777.9472], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 823.4719], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 807.8542], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 817.1769], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 865.3553], device='cuda:0')\n",
    "new iter\n",
    "cal grad..\n",
    "tensor([ 812.3110], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 784.7684], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 777.5480], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 770.4006], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 704.0202], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 656.6118], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 693.8492], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 754.5069], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 799.5516], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 858.1715], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 762.9025], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 684.0759], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 861.0009], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 693.5399], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 735.8182], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 813.3685], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 904.3801], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 873.4323], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 691.0052], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 817.4833], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 687.5128], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 678.9813], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 830.1082], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 717.7280], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 712.3713], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 831.5644], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 701.6025], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 729.9919], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 806.1777], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 758.7400], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 795.6081], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 709.7166], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 670.4403], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 703.3572], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 751.3612], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 707.6416], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 682.2617], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 741.4466], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 844.6535], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 841.9928], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 812.9803], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 922.0214], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 802.0226], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 711.0294], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 722.8704], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 707.9772], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 799.9745], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 763.4428], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 834.6397], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 939.1743], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 865.8109], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 901.2737], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 871.6179], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 805.5805], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 758.4474], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 799.3937], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 761.4286], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 823.4767], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 778.1305], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 716.4442], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 648.7668], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 740.1150], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 819.9764], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 837.0349], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 694.8442], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 907.4980], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 803.0899], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 799.2672], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 792.0714], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 804.0610], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 787.2267], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 841.5878], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 799.8630], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 695.8910], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 823.0544], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 718.8376], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 741.4748], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 779.2692], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 738.5728], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 836.1926], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 855.9437], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 694.7621], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 768.2972], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 758.2587], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 777.9860], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 736.2917], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 814.9377], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 827.2020], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 809.0521], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 821.2297], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 655.7739], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 698.9956], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 825.8769], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 792.5885], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 749.9053], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 869.1137], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 909.3021], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 720.6742], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 684.8234], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 775.6119], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 920.7389], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 820.8165], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 624.7427], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 836.6601], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 787.7929], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 771.4266], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 774.7710], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 820.4644], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 805.1578], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 813.7911], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 862.0755], device='cuda:0')\n",
    "new iter\n",
    "cal grad..\n",
    "tensor([ 810.7137], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 781.6011], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 774.4418], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 769.1010], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 701.7961], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 659.0839], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 697.5904], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 753.8912], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 798.8121], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 853.4874], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 756.8504], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 676.4562], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 865.9045], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 728.5597], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 779.3145], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 824.0349], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 905.6815], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 869.0866], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 665.7833], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 804.8256], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 681.0598], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 675.9633], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 825.9305], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 716.0402], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 708.9673], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 828.1786], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 713.4258], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 754.6530], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 828.4990], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 776.5013], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 803.3712], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 705.4869], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 660.7144], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 691.6296], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 735.0331], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 684.5385], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 669.3327], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 724.4340], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 822.5150], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 799.7844], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 772.0730], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 866.6682], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 739.1825], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 713.2479], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 721.0527], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 702.0795], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 800.2786], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 771.4858], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 843.7920], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 946.6672], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 874.6909], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 900.4178], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 867.2540], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 801.3623], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 756.9683], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 798.1226], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 758.8547], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 818.6080], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 773.4132], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 711.1499], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 644.1742], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 736.3234], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 815.2866], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 831.8230], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 689.6272], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 901.3661], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 797.9456], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 795.7722], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 789.8690], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 801.1751], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 783.8111], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 839.1475], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 796.8414], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 693.7114], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 819.4617], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 715.4850], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 737.9924], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 777.3370], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 735.3282], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 832.9305], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 853.1224], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 692.3531], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 765.1219], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 754.7258], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 774.2453], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 733.7541], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 811.2035], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 823.9106], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 807.5023], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 818.9177], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 653.1818], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 696.5618], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 822.7280], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 788.8186], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 746.0325], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 865.7122], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 904.4100], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 717.4634], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 681.4001], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 771.1631], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 915.3925], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 816.6349], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 621.0255], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 833.3591], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 783.3322], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 768.2134], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 771.8727], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 817.4695], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 802.5568], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 811.1536], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 859.2676], device='cuda:0')\n",
    "new iter\n",
    "cal grad..\n",
    "tensor([ 807.0493], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 776.9702], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 770.6295], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 766.8334], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 699.4906], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 661.2234], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 701.9105], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 753.0790], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 798.6251], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 849.4792], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 753.0320], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 673.5775], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 874.2253], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 761.5740], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 807.4838], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 824.0927], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 894.8410], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 835.1879], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 633.0226], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 790.4144], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 675.8404], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 672.0871], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 822.5725], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 713.5005], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 705.7325], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 825.2354], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 717.0671], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 760.8139], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 828.4405], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 771.9101], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 797.0662], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 698.8149], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 654.8073], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 686.7063], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 730.0911], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 678.4540], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 665.8056], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 719.3838], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 817.6150], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 793.1920], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 768.3682], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 849.5177], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 716.7332], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 706.9028], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 718.2142], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 694.4294], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 795.2200], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 768.2627], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 839.1055], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 942.1742], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 872.3578], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 900.7438], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 865.1172], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 798.7148], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 754.0490], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 795.5426], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 756.4938], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 815.1652], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 770.0632], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 707.9734], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 641.0272], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 733.6548], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 812.8312], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 829.5146], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 687.4554], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 898.6711], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 795.2928], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 793.5947], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 788.6101], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 798.7196], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 780.6952], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 837.0511], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 793.9055], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 691.6257], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 816.0581], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 712.3866], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 734.6429], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 775.5750], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 732.2691], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 829.7743], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 850.1251], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 689.8839], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 762.0426], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 751.6131], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 770.8386], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 731.2797], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 807.8104], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 820.7771], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 806.0094], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 816.7054], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 650.7134], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 694.0115], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 819.4715], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 785.1557], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 742.4697], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 862.4937], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 899.7634], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 714.7154], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 678.4197], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 767.1401], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 910.1931], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 812.6218], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 617.7137], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 830.2373], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 779.2676], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 765.2501], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 769.1678], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 814.5136], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 800.0908], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 808.4917], device='cuda:0')\n",
    "cal grad..\n",
    "tensor([ 856.5182], device='cuda:0')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3-4.2.0]",
   "language": "python",
   "name": "conda-env-anaconda3-4.2.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
