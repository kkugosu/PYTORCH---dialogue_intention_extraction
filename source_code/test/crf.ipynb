{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "#import tensorflow as tf\n",
    "\n",
    "import io\n",
    "from gensim.models import word2vec\n",
    "\n",
    "from io import StringIO\n",
    "from pprint import pprint\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import types\n",
    "from IPython import get_ipython #for import notebook\n",
    "from nbformat import read #for import notebook\n",
    "from IPython.core.interactiveshell import InteractiveShell #for import notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_notebook(fullname, path=None): #for import notebook\n",
    "    \"\"\"find a notebook, given its fully qualified name and an optional path\n",
    "\n",
    "    This turns \"foo.bar\" into \"foo/bar.ipynb\"\n",
    "    and tries turning \"Foo_Bar\" into \"Foo Bar\" if Foo_Bar\n",
    "    does not exist.\n",
    "    \"\"\"\n",
    "    name = fullname.rsplit('.', 1)[-1]\n",
    "    if not path:\n",
    "        path = ['']\n",
    "    for d in path:\n",
    "        nb_path = os.path.join(d, name + \".ipynb\")\n",
    "        if os.path.isfile(nb_path):\n",
    "            return nb_path\n",
    "        # let import Notebook_Name find \"Notebook Name.ipynb\"\n",
    "        nb_path = nb_path.replace(\"_\", \" \")\n",
    "        if os.path.isfile(nb_path):\n",
    "            return nb_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NotebookLoader(object): #for import notebook\n",
    "    \"\"\"Module Loader for Jupyter Notebooks\"\"\"\n",
    "    def __init__(self, path=None):\n",
    "        self.shell = InteractiveShell.instance()\n",
    "        self.path = path\n",
    "\n",
    "    def load_module(self, fullname):\n",
    "        \"\"\"import a notebook as a module\"\"\"\n",
    "        path = find_notebook(fullname, self.path)\n",
    "\n",
    "        print (\"importing Jupyter notebook from %s\" % path)\n",
    "\n",
    "        # load the notebook object\n",
    "        with io.open(path, 'r', encoding='utf-8') as f:\n",
    "            nb = read(f, 4)\n",
    "\n",
    "\n",
    "        # create the module and add it to sys.modules\n",
    "        # if name in sys.modules:\n",
    "        #    return sys.modules[name]\n",
    "        mod = types.ModuleType(fullname)\n",
    "        mod.__file__ = path\n",
    "        mod.__loader__ = self\n",
    "        mod.__dict__['get_ipython'] = get_ipython\n",
    "        sys.modules[fullname] = mod\n",
    "\n",
    "        # extra work to ensure that magics that would affect the user_ns\n",
    "        # actually affect the notebook module's ns\n",
    "        save_user_ns = self.shell.user_ns\n",
    "        self.shell.user_ns = mod.__dict__\n",
    "\n",
    "        try:\n",
    "          for cell in nb.cells:\n",
    "            if cell.cell_type == 'code':\n",
    "                # transform the input to executable Python\n",
    "                code = self.shell.input_transformer_manager.transform_cell(cell.source)\n",
    "                # run the code in themodule\n",
    "                exec(code, mod.__dict__)\n",
    "        finally:\n",
    "            self.shell.user_ns = save_user_ns\n",
    "        return mod\n",
    "class NotebookFinder(object):\n",
    "    \"\"\"Module finder that locates Jupyter Notebooks\"\"\"\n",
    "    def __init__(self):\n",
    "        self.loaders = {}\n",
    "\n",
    "    def find_module(self, fullname, path=None):\n",
    "        nb_path = find_notebook(fullname, path)\n",
    "        if not nb_path:\n",
    "            return\n",
    "\n",
    "        key = path\n",
    "        if path:\n",
    "            # lists aren't hashable\n",
    "            key = os.path.sep.join(path)\n",
    "\n",
    "        if key not in self.loaders:\n",
    "            self.loaders[key] = NotebookLoader(path)\n",
    "        return self.loaders[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.meta_path.append(NotebookFinder())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "import torch.utils.data\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from pre_process.ipynb\n",
      "\n",
      " [[1561, 1, 1089, 1, 102, 33, 74, 14, 7, 229, 3510, 218, 354, 4], [32, 39, 16, 10, 4904, 43, 10, 68, 44, 60, 14, 81, 2579, 0], [29, 21, 3, 225, 4, 41, 35, 93, 149, 6, 1314, 0], [71, 3, 68, 38, 40, 4, 2, 64, 0, 41, 35, 51, 106, 149, 1473, 8, 2582, 1735, 0, 1409, 177, 61, 4], [2, 325, 3, 19, 6800, 57, 654, 30, 21, 4, 2, 64, 207, 24, 1492, 36, 224, 0], [2, 746, 7, 547, 144, 6, 5, 1215, 230, 30, 23, 348, 4963, 8, 273, 56, 12, 81, 358, 0], [97, 7, 60, 228, 0, 2, 318, 476, 8, 2153, 364, 47, 46, 6, 348, 'pingpong.Perhaps', 30, 23, 106, 7, 'foursome', 28, 99, 0], [609, 133, 6, 20, 17, 140, 88, 19, 1180, 1, 30, 121, 250, 99, 6, 47, 1383, 28, 'us.That', 10, 771, 645, 8, 449, 1, 78, 0], ['Good.Let', 161, 34, 47, 92, 0], [219, 55, 0], []]\n",
      "\n",
      " [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1], [0, 1, 1, 1, 1, 1], [1, 1, 1], []]\n",
      "\n",
      " 0 0 0 0 0 0 4 4 4 4\n",
      "\n",
      " 3 4 2 2 2 3 4 1 3 4\n",
      "\n",
      " [[108, 3, 21, 5877, 4], [263, 160, 2, 23, 0, 72, 7, 953, 12, 1108, 17, 2262, 9, 85, 44, 1, 2, 23, 21, 908, 5877, 7, 498, 0], [287, 4, 2, 38, 201, 2176, 17], [32, 225, 908, 5877, 4], [165, 17], [72, 394, 0, 140, 3, 21, 645, 1595, 1, 3, 23, 106, 9, 1, 78, 0], []]\n",
      "\n",
      " [[1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], []]\n",
      "\n",
      " 0 0 6 0 0 0\n",
      "\n",
      " 2 1 2 2 1 1\n",
      "\n",
      " [[108, 3, 644, 28, 5, 1621, 25, 4], [65, 1, 2, 893, 6, 1697, 453, 0], [29, 10, 5, 1005, 4], [63, 1621, 115, 78, 157, 'comerials', 0], [97, 419, 1, 43, 119, 3, 15, 6, 196, 7, 1263, 1275, 0], []]\n",
      "\n",
      " [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 0, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], []]\n",
      "\n",
      " 0 0 0 0 0\n",
      "\n",
      " 2 1 2 1 1\n",
      "\n",
      " [[137, 3, 50, 55, 4], [2, 35, 22, 50, 55, 295, 0, 2, 48, 5380, 113, 2, 1746, 99, 1299, 84, 5, 4763, 0], [269, 'worry.He', 10, 80, 'acrobat', 3056], [2, 54, 0], []]\n",
      "\n",
      " [[1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 0, 1, 1, 0, 1], [1, 1, 1], []]\n",
      "\n",
      " 0 0 0 0\n",
      "\n",
      " 2 1 1 1\n"
     ]
    }
   ],
   "source": [
    "import pre_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_dataset = pre_process.transformed_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class chr_rnn(nn.Module):\n",
    "    def __init__(self, hidden_size, bidirectional):\n",
    "        super(chr_rnn, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        if(bidirectional == True):\n",
    "            self.bidirectional = 2\n",
    "        else:\n",
    "            self.bidirectional = 1\n",
    "        self.chr_rnn = nn.GRU(100, 100, bidirectional = bidirectional)\n",
    "        \n",
    "        \n",
    "    def forward(self,char,h0):\n",
    "        _,h0 = self.chr_rnn(char,h0)\n",
    "        return h0\n",
    "        \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(self.bidirectional , 1, self.hidden_size, device=device)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "class last_net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(last_net, self).__init__()\n",
    "        self.lastnet = nn.Linear(200,100)\n",
    "        \n",
    "    def forward(self,last_hidden_state):\n",
    "        last_w = self.lastnet(last_hidden_state)\n",
    "        return last_w\n",
    "  \n",
    "    \n",
    "chr_rnn_1 = chr_rnn(100, True).cuda()\n",
    "last_net_1 = last_net().cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading chr\n",
      "loading last\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile('/home/jongsu/Desktop/persona_dialogue/chr_parameter/my_character_rnn_526.pth'):\n",
    "    print(\"loading chr\")\n",
    "    chr_rnn_1.load_state_dict(torch.load('/home/jongsu/Desktop/persona_dialogue/chr_parameter/my_character_rnn_526.pth'))\n",
    "\n",
    "if os.path.isfile('/home/jongsu/Desktop/persona_dialogue/chr_parameter/my_character_linear_526.pth'):\n",
    "    print(\"loading last\")\n",
    "    last_net_1.load_state_dict(torch.load('/home/jongsu/Desktop/persona_dialogue/chr_parameter/my_character_linear_526.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wv_model_en = word2vec.Word2Vec(size=100, window=5, min_count=5, workers=4)\n",
    "wv_model_en = word2vec.Word2Vec.load('/home/jongsu/Desktop/persona_dialogue/wv_parameter/dialogue_wv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class makesent_gru(nn.Module):\n",
    "    def __init__(self, hidden_size, bidirectional):\n",
    "        super(makesent_gru, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        if(bidirectional == True):\n",
    "            self.bidirectional = 2\n",
    "        else:\n",
    "            self.bidirectional = 1\n",
    "        self.gru = nn.GRU(100, 100, bidirectional = bidirectional)\n",
    "        \n",
    "        \n",
    "    def forward(self,char,h0):\n",
    "        gru,h0 = self.gru(char,h0)\n",
    "        return h0\n",
    "        \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(self.bidirectional , 1, self.hidden_size, device=device)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_sum_exp(vec):\n",
    "    max_score = vec[0, argmax(vec)]\n",
    "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
    "    return max_score + \\\n",
    "        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n",
    "def argmax(vec):\n",
    "    # return the argmax as a python int\n",
    "    _, idx = torch.max(vec, 1)\n",
    "    return idx.item()\n",
    "\n",
    "\n",
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = [to_ix[w] for w in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BiGru_CRF(nn.Module):\n",
    "    def __init__(self, tagset_set ,hidden_dim):\n",
    "        super(BiGru_CRF, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.tagset_size = len(tagset_set)\n",
    "\n",
    "        \n",
    "        self.gru = nn.GRU(100, 100, bidirectional=True)\n",
    "        self.gru_postp = nn.Linear(200,100)\n",
    "        \n",
    "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size+2)\n",
    "        self.transitions = nn.Parameter(torch.randn(self.tagset_size + 2, self.tagset_size + 2))\n",
    "        self.hidden = self.init_hidden()\n",
    "        \n",
    "        self.transitions.data[0, :] = -10000\n",
    "        self.transitions.data[:, 29] = -10000\n",
    "        \n",
    "    def init_hidden(self):\n",
    "        return (torch.zeros(2, 1, self.hidden_dim).cuda())\n",
    "\n",
    "        \n",
    "    def _forward_alg(self, feats):\n",
    "        \n",
    "        # Do the forward algorithm to compute the partition function\n",
    "        init_alphas = torch.full((1, self.tagset_size+2), -10000.).cuda()\n",
    "        init_alphas[0][0] = 0.\n",
    "\n",
    "        forward_var = init_alphas\n",
    "\n",
    "        # Iterate through the sentence\n",
    "        for feat in feats:\n",
    "            alphas_t = []  # The forward tensors at this timestep\n",
    "            for next_tag in range(self.tagset_size+2):\n",
    "                # broadcast the emission score: it is the same regardless of\n",
    "                # the previous tag\n",
    "                emit_score = feat[next_tag].view(1, -1).expand(1, self.tagset_size+2)\n",
    "                # the ith entry of trans_score is the score of transitioning to\n",
    "                # next_tag from i\n",
    "                trans_score = self.transitions[next_tag].view(1, -1)\n",
    "                # The ith entry of next_tag_var is the value for the\n",
    "                # edge (i -> next_tag) before we do log-sum-exp\n",
    "                \n",
    "                next_tag_var = forward_var + trans_score + emit_score\n",
    "                # The forward variable for this tag is log-sum-exp of all the\n",
    "                # scores.\n",
    "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
    "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
    "            \n",
    "        terminal_var = forward_var  + self.transitions[29]\n",
    "        alpha = log_sum_exp(terminal_var)\n",
    "        return alpha\n",
    "    \n",
    "    def _get_gru_features(self, sentence):\n",
    "        \n",
    "        self.hidden = self.init_hidden()\n",
    "        #gru_out, self.hidden = self.gru(sentence, self.hidden)\n",
    "        #gru_out = self.gru_postp(gru_out)\n",
    "        gru_out = sentence.view(len(sentence), 100)\n",
    "        gru_feats = self.hidden2tag(gru_out)\n",
    "        return gru_feats\n",
    "    \n",
    "    def _score_sentence(self, feats, tags):\n",
    "        # Gives the score of a provided tag sequence\n",
    "        score = torch.zeros(1).cuda()\n",
    "        tags = np.append(0,tags)\n",
    "        \n",
    "        my_feats = feats\n",
    "        for i, feat in enumerate(my_feats):\n",
    "            score = score + \\\n",
    "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
    "        \n",
    "        return score\n",
    "    \n",
    "    def neg_log_likelihood(self, sentence, tags):\n",
    "        \n",
    "        feats = self._get_gru_features(sentence)\n",
    "        forward_score = self._forward_alg(feats)\n",
    "        \n",
    "        gold_score = self._score_sentence(feats, tags)\n",
    "        return forward_score - gold_score\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    def _viterbi_decode(self, feats):\n",
    "        backpointers = []\n",
    "\n",
    "        # Initialize the viterbi variables in log space\n",
    "        init_vvars = torch.full((1, 30), -10000.)\n",
    "        init_vvars[0][0] = 0\n",
    "\n",
    "        # forward_var at step i holds the viterbi variables for step i-1\n",
    "        forward_var = init_vvars\n",
    "        for feat in feats:\n",
    "            bptrs_t = []  # holds the backpointers for this step\n",
    "            viterbivars_t = []  # holds the viterbi variables for this step\n",
    "\n",
    "            for next_tag in range(self.tagset_size+2):\n",
    "                \n",
    "                next_tag_var = forward_var + self.transitions[next_tag]\n",
    "                best_tag_id = argmax(next_tag_var)\n",
    "                bptrs_t.append(best_tag_id)\n",
    "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
    "            \n",
    "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
    "            backpointers.append(bptrs_t)\n",
    "\n",
    "        \n",
    "        terminal_var = forward_var + self.transitions[29]\n",
    "        best_tag_id = argmax(terminal_var)\n",
    "        path_score = terminal_var[0][best_tag_id]\n",
    "\n",
    "        \n",
    "        best_path = [best_tag_id]\n",
    "        for bptrs_t in reversed(backpointers):\n",
    "            best_tag_id = bptrs_t[best_tag_id]\n",
    "            best_path.append(best_tag_id)\n",
    "        # Pop off the start tag (we dont want to return that to the caller)\n",
    "        start = best_path.pop()\n",
    "        assert start == 0  # Sanity check\n",
    "        best_path.reverse()\n",
    "        return path_score, best_path\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def forward(self, sentence):  # dont confuse this with _forward_alg above.\n",
    "        # Get the emission scores from the BiLSTM\n",
    "        lstm_feats = self._get_gru_features(sentence)\n",
    "\n",
    "        # Find the best path, given the features.\n",
    "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
    "        return score, tag_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class last_sent_net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(last_sent_net, self).__init__()\n",
    "        self.lastnet = nn.Linear(200,100)\n",
    "        \n",
    "    def forward(self,last_hidden_state):\n",
    "        last_w = self.lastnet(last_hidden_state)\n",
    "        return last_w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagset = torch.tensor(np.arange(28),device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence_1 = makesent_gru(100,True).cuda()\n",
    "last_sent_net1 = last_sent_net().cuda()\n",
    "Bigru_crf1 = BiGru_CRF(tagset,100).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading crf\n",
      "loading last\n",
      "loading last\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if os.path.isfile('/home/jongsu/Desktop/persona_dialogue/crf_lstm_parameter/crf1.pth'):\n",
    "    print(\"loading crf\")\n",
    "    Bigru_crf1.load_state_dict(torch.load('/home/jongsu/Desktop/persona_dialogue/crf_lstm_parameter/crf1.pth'))\n",
    "\n",
    "if os.path.isfile('/home/jongsu/Desktop/persona_dialogue/crf_lstm_parameter/crf2.pth'):\n",
    "    print(\"loading last\")\n",
    "    sentence_1.load_state_dict(torch.load('/home/jongsu/Desktop/persona_dialogue/crf_lstm_parameter/crf2.pth'))\n",
    "\n",
    "if os.path.isfile('/home/jongsu/Desktop/persona_dialogue/crf_lstm_parameter/crf3.pth'):\n",
    "    print(\"loading last\")\n",
    "    last_sent_net1.load_state_dict(torch.load('/home/jongsu/Desktop/persona_dialogue/crf_lstm_parameter/crf3.pth'))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new iter\n",
      "cal grad..\n",
      "tensor([ 156.0618], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 137.1423], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 126.0625], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 138.1004], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 106.7880], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([-18.4861], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 51.9405], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 191.9272], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 191.6957], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 334.3360], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 173.1140], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 26.5188], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 296.8061], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 91.6075], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 181.0750], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 257.3882], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 327.5539], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 196.1014], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([-28.6332], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 144.9202], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 26.6877], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 57.3719], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 271.0370], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 179.6045], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 109.9501], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 245.8140], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 31.9296], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 134.7594], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 238.8328], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 147.9222], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 165.9202], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([-2.5944], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 4.0186], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 46.5362], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 104.5633], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 65.8261], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 9.5526], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 89.9639], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 197.8918], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 209.9884], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 224.0232], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 317.9274], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 147.1029], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 110.3216], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 97.9426], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 79.1420], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 204.4501], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 97.7103], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 187.0291], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 347.6379], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 190.2026], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 320.4032], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 321.6411], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 148.2287], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 151.2412], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 161.8623], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 141.3011], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 264.1924], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 193.3794], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 115.4463], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([-32.8644], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 108.8192], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 213.9202], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 228.3384], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 35.1581], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 377.6236], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 166.7622], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 154.1473], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 179.0131], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 246.1128], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 192.1251], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 222.3880], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 219.6081], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 57.4699], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 159.8803], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 98.4899], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 85.8165], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 163.6413], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 113.1123], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 258.9510], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 294.3542], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 49.5581], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 123.8904], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 112.7607], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 143.1332], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 95.2047], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 223.8061], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 220.5000], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 177.3316], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 218.8142], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 27.7819], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 16.8990], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 241.6961], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 145.8177], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 107.3929], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 226.0008], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 299.5700], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 83.3056], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 23.9647], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 134.0638], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 345.1126], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 180.4508], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([-42.5876], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 220.2057], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 139.5273], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 104.7228], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 113.6588], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 219.4350], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 195.4959], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 251.1356], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 297.3884], device='cuda:0')\n",
      "new iter\n",
      "cal grad..\n",
      "tensor([ 213.9552], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 151.0461], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 127.0625], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 129.3070], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 95.4402], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([-34.2626], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 39.5435], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 186.3029], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 166.9109], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 272.8926], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 173.6906], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 21.7312], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 285.9791], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 83.5425], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 177.0101], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 245.1548], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 313.1895], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 192.5852], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([-32.4739], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 133.0219], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 22.0781], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 54.1097], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 257.8567], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 175.3340], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 98.3843], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 230.5258], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 19.4124], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 124.5476], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 225.1074], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 134.8647], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 151.8809], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([-17.5013], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([-11.4428], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 32.5600], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 93.5999], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 44.4869], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([-9.2972], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 76.7149], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 188.1963], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 202.9059], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 222.0810], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 302.2135], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 133.7202], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 98.3141], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 85.9270], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 64.9456], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 188.1042], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 80.1228], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 171.2211], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 328.3059], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 164.8915], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 290.4560], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 303.7357], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 124.7260], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 136.3132], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 145.4449], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 124.3913], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 246.6855], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 175.4072], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 93.2641], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([-52.3627], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 89.0682], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 198.5233], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 210.3315], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 17.4344], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 365.6762], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 150.7687], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 136.2263], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 162.7163], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 230.8772], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 176.3338], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 205.1255], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 204.2386], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 42.1743], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 143.6042], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 82.6777], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 70.0859], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 148.1634], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 97.9152], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 244.8960], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 280.8780], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 35.2498], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 108.2644], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 97.1808], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 127.8943], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 80.2230], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 210.2605], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 206.4849], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 162.9555], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 204.6594], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 13.3239], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 0.1882], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 225.0297], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 121.9238], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 93.0345], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 213.0242], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 284.4909], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 69.3203], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 8.1374], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 118.0063], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 330.2630], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 164.9123], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([-59.4256], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 204.2731], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 123.8037], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 88.7958], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 95.8146], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 203.8362], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 178.1906], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 225.6025], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 274.3591], device='cuda:0')\n",
      "new iter\n",
      "cal grad..\n",
      "tensor([ 195.0960], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 135.6275], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 112.0481], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 116.2038], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 81.4741], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([-48.8723], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 26.0599], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 172.6176], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 153.7370], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 258.1031], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 165.5836], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 15.8320], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 270.4072], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 62.8087], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 160.7350], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 233.9235], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 298.8629], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 188.7621], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([-40.8532], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 121.2890], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 8.7186], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 41.6378], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 244.6736], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 161.7464], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 83.4479], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 215.3732], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 5.7969], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 110.5419], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 210.6672], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 123.6809], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 138.0529], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([-33.5454], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([-27.4081], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 18.0545], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 79.7846], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 29.4243], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([-25.1613], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 60.9886], device='cuda:0')\n",
      "cal grad..\n",
      "tensor([ 176.8595], device='cuda:0')\n",
      "cal grad..\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-1b5f283facbc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mlast_sent_net1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mtotal_lss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_lss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jongsu/.pyenv/versions/anaconda3-4.2.0/lib/python3.5/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jongsu/.pyenv/versions/anaconda3-4.2.0/lib/python3.5/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     87\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     88\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer1 = optim.SGD(Bigru_crf1.parameters(), lr=0.0001, weight_decay=1e-4)\n",
    "optimizer2 = optim.SGD(sentence_1.parameters(), lr=0.0001, weight_decay=1e-4)\n",
    "optimizer3 = optim.SGD(last_sent_net1.parameters(), lr=0.0001, weight_decay=1e-4)\n",
    "\n",
    "epoch = 0\n",
    "\n",
    "while(epoch < 100): \n",
    "    \n",
    "    total_lss = 0\n",
    "    dialogue_idx = 0\n",
    "    print(\"new iter\")\n",
    "    while(dialogue_idx < len(my_dataset)):\n",
    "        \n",
    "        #print(\"dialogue_idx\",dialogue_idx)\n",
    "        per_dialogue = my_dataset[dialogue_idx]\n",
    "        sent_idx = 0\n",
    "        new_sent_to_vec = []\n",
    "        sent_to_vec = torch.tensor(new_sent_to_vec).cuda()\n",
    "        \n",
    "        make_label = []\n",
    "        while(sent_idx < len(per_dialogue['dialogue'][0]) -1): #indexed dialogue\n",
    "            \n",
    "            \n",
    "            \n",
    "            ## sent_lstm training\n",
    "            sent = per_dialogue['dialogue'][0][sent_idx]\n",
    "            sent_len = len(per_dialogue['dialogue'][0][sent_idx]) \n",
    "            \n",
    "            word_idx = 0\n",
    "            vec = []\n",
    "            \n",
    "            while(word_idx < sent_len): \n",
    "                \n",
    "                \n",
    "                encoder_hidden = chr_rnn_1.initHidden()\n",
    "                if per_dialogue['dialogue'][1][sent_idx][word_idx] == 1: #word_to_vec\n",
    "                    word_to_tensor = torch.tensor(wv_model_en.wv[wv_model_en.wv.index2entity[sent[word_idx]]])\n",
    "                    gpu_wt = word_to_tensor.cuda()\n",
    "                    vec.append(gpu_wt) #append known word vec\n",
    "                else: #character model\n",
    "                    for ei in range(len(sent[word_idx])):\n",
    "                        gru_input = torch.tensor(np.zeros(shape = (1, 1, 100), dtype=\"float32\")).cuda()\n",
    "                        gru_input[0][0][ord(sent[word_idx][ei])%100] = 1 #character to onehot vec\n",
    "                        encoder_hidden = chr_rnn_1(gru_input,encoder_hidden)\n",
    "\n",
    "                    last_encoder_hidden = encoder_hidden.view(-1,200)\n",
    "                    last_encoder_hidden_ = last_net_1(last_encoder_hidden) #last hiddenstate and fully c l\n",
    "                    vec.append(last_encoder_hidden_) #append unknown word vec\n",
    "                word_idx = word_idx + 1\n",
    "            \n",
    "            \n",
    "            word_idx = 0 \n",
    "            \n",
    "            sent_hidden = sentence_1.initHidden()\n",
    "            \n",
    "            \n",
    "            while(word_idx<sent_len):\n",
    "\n",
    "                view = vec[word_idx].view(1,1,100)\n",
    "                sent_hidden = sentence_1(view,sent_hidden)\n",
    "                word_idx = word_idx + 1\n",
    "            \n",
    "            # 200 -> 100\n",
    "            \n",
    "            sent_vec = last_sent_net1(sent_hidden.view(-1,200))\n",
    "            sent_to_vec = torch.cat((sent_to_vec,sent_vec),0)\n",
    "            \n",
    "            try:\n",
    "                index1_toint = int(per_dialogue['label'][0][sent_idx*2]) *4\n",
    "                index2_toint = int(per_dialogue['label'][1][sent_idx*2])\n",
    "                make_label.append(index1_toint + index2_toint)\n",
    "            except:\n",
    "                print(\"data_err\")\n",
    "                make_label.append(0)\n",
    "            \n",
    "            sent_idx = sent_idx + 1\n",
    "        \n",
    "\n",
    "        resh_stv = sent_to_vec.view(-1,1,100)\n",
    "        torch_make_label = torch.tensor(make_label).cuda()\n",
    "        loss = Bigru_crf1.neg_log_likelihood(resh_stv, make_label)\n",
    "        ## lstm_crf training\n",
    "        \n",
    "        dialogue_idx = dialogue_idx + 1\n",
    "        \n",
    "        total_lss = total_lss + loss\n",
    "        \n",
    "        if(dialogue_idx % 100 ==0):\n",
    "            print(\"cal grad..\")\n",
    "            Bigru_crf1.zero_grad()\n",
    "            sentence_1.zero_grad()\n",
    "            last_sent_net1.zero_grad()\n",
    "            \n",
    "            total_lss.backward()\n",
    "            print(total_lss)\n",
    "            \n",
    "            optimizer1.step()\n",
    "            optimizer2.step()\n",
    "            optimizer3.step()\n",
    "            \n",
    "            total_lss = 0\n",
    "            \n",
    "            torch.save(Bigru_crf1.state_dict(),'/home/jongsu/Desktop/persona_dialogue/crf_lstm_parameter/crf1_final.ckpt')\n",
    "            torch.save(sentence_1.state_dict(),'/home/jongsu/Desktop/persona_dialogue/crf_lstm_parameter/crf2_final.ckpt')\n",
    "            torch.save(last_sent_net1.state_dict(),'/home/jongsu/Desktop/persona_dialogue/crf_lstm_parameter/crf3_final.ckpt')\n",
    "\n",
    "            torch.save(Bigru_crf1.state_dict(),'/home/jongsu/Desktop/persona_dialogue/crf_lstm_parameter/crf1_final.pkl')\n",
    "            torch.save(sentence_1.state_dict(),'/home/jongsu/Desktop/persona_dialogue/crf_lstm_parameter/crf2_final.pkl')\n",
    "            torch.save(last_sent_net1.state_dict(),'/home/jongsu/Desktop/persona_dialogue/crf_lstm_parameter/crf3_final.pkl')\n",
    "\n",
    "            torch.save(Bigru_crf1.state_dict(),'/home/jongsu/Desktop/persona_dialogue/crf_lstm_parameter/crf1_final.pth')\n",
    "            torch.save(sentence_1.state_dict(),'/home/jongsu/Desktop/persona_dialogue/crf_lstm_parameter/crf2_final.pth')\n",
    "            torch.save(last_sent_net1.state_dict(),'/home/jongsu/Desktop/persona_dialogue/crf_lstm_parameter/crf3_final.pth')\n",
    "        \n",
    "    epoch = epoch + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3-4.2.0]",
   "language": "python",
   "name": "conda-env-anaconda3-4.2.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
