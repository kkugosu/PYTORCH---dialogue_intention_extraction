{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_fields={'dial': ('Text', data.Field(sequential=True)),\n",
    "        'emo': ('labels_1', data.Field(sequential=False)),\n",
    "        'act': ('labels_2', data.Field(sequential=False))}\n",
    "\n",
    "test = my_TabularDataset.splits(path = working_path, train = 'data_jsonfile/full_data_test.json',\n",
    "                          fields=my_fields) \n",
    "test = sorted(test, key = lambda  x: cal_dialogue(x))\n",
    "test = sorted(test, key = lambda  x: -len(x.Text)) #reordering training dataset with number of sentences\n",
    "# low index has much sentence because afterwards we use torch pad_sequence\n",
    "print(len(test))\n",
    "dataseq = torch.arange(end = len(train),dtype=torch.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cal_accuracy(model_predict, real_tag):\n",
    "    '''\n",
    "    Args:\n",
    "        model_predict\n",
    "            model predicted tags\n",
    "        real_tag\n",
    "            real tags\n",
    "        tag_len\n",
    "            tag len\n",
    "        \n",
    "    Yields:\n",
    "        accuracy\n",
    "        \n",
    "    Example:\n",
    "        \n",
    "    real = torch.tensor([  0,   2,   1,   2,   1,   1,   1,   1,   1,   2,   1,   1, 1,   1,  29], device='cuda:0')\n",
    "    model = [2, 1, 2, 1, 17, 1, 17, 1, 3, 1, 17, 1, 17, 29]\n",
    "    taglen = len(model)\n",
    "    \n",
    "    (npreal[tagseq+1]//4) real emotion\n",
    "    (model_predict[tagseq]//4) model emotion\n",
    "    \n",
    "    (npreal[tagseq+1]%4) real action\n",
    "    (model_predict[tagseq]%4) model action\n",
    "    \n",
    "    emotion err = 0.3076923076923077\n",
    "    action err = 0.07692307692307693\n",
    "    accuracy = 0.8076923076923077\n",
    "    '''\n",
    "    tag_len = len(model_predict)\n",
    "    npreal = real_tag.cpu().numpy()\n",
    "    tagseq = 0\n",
    "    emotiontag = []\n",
    "    actiontag = []\n",
    "    emoerr = 0\n",
    "    acterr = 0\n",
    "    while(tagseq < tag_len-1):\n",
    "      \n",
    "        emotiontag = np.append(emotiontag, npreal[tagseq+1]//4)\n",
    "        actiontag = np.append(actiontag, npreal[tagseq+1]%4)\n",
    "        \n",
    "        \n",
    "        if((npreal[tagseq+1]//4) != (model_predict[tagseq]//4)):\n",
    "            emoerr = emoerr + 1\n",
    "\n",
    "        \n",
    "        if((npreal[tagseq+1]%4) != (model_predict[tagseq]%4)):\n",
    "            acterr = acterr + 1\n",
    "\n",
    "        tagseq = tagseq + 1\n",
    "\n",
    "    return(1-(emoerr/tagseq + acterr/tagseq)/2)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_func(test_data, shared_model , comp_model, dataseq, batch_size):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "            test_data: \n",
    "                test data\n",
    "                \n",
    "            shared_model:\n",
    "                shared model\n",
    "                \n",
    "            comp_model:\n",
    "                comp model\n",
    "                \n",
    "            dataseq:\n",
    "                data sort sequence\n",
    "                \n",
    "            batch_size:\n",
    "                batchsize\n",
    "            \n",
    "\n",
    "\n",
    "    Yields:\n",
    "            accuracy:\n",
    "                accuracy of all data\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    k = 0\n",
    "    accuracy = 0\n",
    "    for batch_data in batchload(test_data, repeat=True, batchsize = batch_size, data_seq = dataseq ):\n",
    "        #load txt data from jsonfile\n",
    "\n",
    "\n",
    "        new_dial, new_tag, dial_leng = all_preprocess(shared_model, batch_data)\n",
    "        #load batch*(dialogue_length*sent_vec(float)) -> new_dial\n",
    "        #load batch*tag -> new_tag\n",
    "        #load batch * dial_leng\n",
    "\n",
    "        \n",
    "        dummy_input = [make_mask(dial_leng),new_dial]\n",
    "        unuselist = [new_dial, new_tag, dial_leng]\n",
    "        del unuselist\n",
    "        print(\"tag = \",new_tag[7])\n",
    "        print(\"expect = \",comp_model(BATCH_SIZE,dummy_input,seq=7)[1])\n",
    "        print(\"accuracy = \", cal_accuracy(comp_model(BATCH_SIZE,dummy_input,seq=7)[1],new_tag[7]))\n",
    "        \n",
    "        tag_num = 0\n",
    "        batch_acc = 0\n",
    "        while(tag_num < 100):\n",
    "            batch_acc = batch_acc + cal_accuracy(comp_model(BATCH_SIZE,dummy_input,seq=tag_num)[1],new_tag[tag_num])\n",
    "            tag_num = tag_num + 1\n",
    "        batch_acc = batch_acc/100\n",
    "        accuracy = accuracy + batch_acc\n",
    "        print(batch_acc)\n",
    "        if k == int(len(train)/BATCH_SIZE):\n",
    "            break\n",
    "            \n",
    "        k = k + 1\n",
    "        print(k)\n",
    "\n",
    "    \n",
    "    return accuracy/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "test_func(\n",
    "    test_data = test, \n",
    "    shared_model = sent_to_vextor_bigru_net, \n",
    "    comp_model = my_grucrf_model,\n",
    "    dataseq = dataseq,  \n",
    "    batch_size = 100)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3-4.2.0]",
   "language": "python",
   "name": "conda-env-anaconda3-4.2.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
