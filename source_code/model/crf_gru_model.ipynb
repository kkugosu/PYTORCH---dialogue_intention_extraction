{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "import torch.utils.data\n",
    "from torch.utils.data import DataLoader\n",
    "import io,os\n",
    "from torch import nn\n",
    "from gensim.models import word2vec\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from torchtext import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "tag_to_ix = {'start_tag':0,'stop_tag':29,'pad_tag':30}\n",
    "\n",
    "working_path = '/home/jongsu/jupyter/pytorch_dialogue_ie/'\n",
    "WV_PATH = '/home/jongsu/jupyter/pytorch_dialogue_ie/parameter/dialogue_wv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# basic functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def argmax(vec):\n",
    "    '''\n",
    "    return the argmax as a python int\n",
    "    '''\n",
    "    \n",
    "    _, idx = torch.max(vec, 1)\n",
    "    return idx.item()\n",
    "\n",
    "\n",
    "def sent_loader(sentence): \n",
    "    '''\n",
    "    pre_process per sentence\n",
    "    '''\n",
    "    \n",
    "    result = []\n",
    "    for elem in sentence.split(' '):\n",
    "        if elem != '':\n",
    "            result = np.append(result, elem)\n",
    "    return result,len(result)\n",
    "\n",
    "\n",
    "\n",
    "def batchload(dataset, repeat, batchsize, data_seq):\n",
    "    '''\n",
    "    load data as much as batch\n",
    "    \n",
    "    Args:\n",
    "    \n",
    "        dataset:\n",
    "            data to load\n",
    "        repeat:\n",
    "            True if repeat load data\n",
    "        batchsize:\n",
    "            batchsize\n",
    "        data_seq:\n",
    "            order of data to load\n",
    "        \n",
    "    Yields:\n",
    "    \n",
    "        Batch data\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    while True:\n",
    "        i = batchsize\n",
    "        while(i <= len(data_seq)):\n",
    "            batch = []\n",
    "            batch_seq = 0\n",
    "            batchnum = data_seq[i-batchsize:i]\n",
    "            \n",
    "            while(batch_seq < batchsize):\n",
    "                batch.append(dataset[batchnum[batch_seq]])\n",
    "                batch_seq = batch_seq + 1\n",
    "            print(\"batchnum = \",i)\n",
    "            yield batch\n",
    "            i = i + batchsize\n",
    "        \n",
    "        if repeat == False:\n",
    "            break\n",
    "\n",
    "    \n",
    "def pad_batch(minibatch):\n",
    "    i = 0\n",
    "    new_batch = []\n",
    "    leng_set = []\n",
    "    maxleng = 1\n",
    "    sentnum_per_dialogue = []\n",
    "    while(i < len(minibatch)): #almost equal to BATCH_SIZE\n",
    "        j = 0\n",
    "        temp = []\n",
    "        sentnum_per_dialogue.append(len(minibatch[i].Text)) #'' = stoptag\n",
    "        #save sentnum per dialogue\n",
    "        while(j < len(minibatch[i].Text)-1):\n",
    "            sent, leng = sent_loader(minibatch[i].Text[j])  \n",
    "            \n",
    "            #convert text to word_list, word_list_length\n",
    "            leng_set.append(leng)\n",
    "            if leng > maxleng:\n",
    "                maxleng = leng\n",
    "\n",
    "            temp.append(sent)\n",
    "            j = j + 1\n",
    "        \n",
    "        temp.append([\"<stop_tag>\"])\n",
    "        leng_set.append(1) #stoptag\n",
    "        new_batch.append(temp)\n",
    "\n",
    "        i = i + 1\n",
    "\n",
    "    i = 0\n",
    "    while (i < len(minibatch)): #almost equal to BATCH_SIZE\n",
    "        j = 0\n",
    "        while (j < len(new_batch[i])):\n",
    "\n",
    "            while(len(new_batch[i][j]) < maxleng):\n",
    "                new_batch[i][j] = np.append(new_batch[i][j],\"<pad>\")\n",
    "\n",
    "            j = j + 1\n",
    "        i = i + 1\n",
    "    #batch * sentnum * (word_list+pad) -> new_batch\n",
    "    #batch * sentnum * (word_list_length) -> leng_set\n",
    "    #batch * (sentnum) -> sentnum_per_dialogue\n",
    "\n",
    "    return new_batch, leng_set ,sentnum_per_dialogue\n",
    "\n",
    "\n",
    "wv_model = word2vec.Word2Vec(size = 100, window = 5, min_count = 5, workers = 4)\n",
    "wv_model = word2vec.Word2Vec.load(WV_PATH)\n",
    "\n",
    "def numerize_sent(sent, len_sent):\n",
    "    i = 0\n",
    "    n_sent = []\n",
    "    while(i < len_sent):\n",
    "        if(sent[i] == '<pad>'):\n",
    "            n_sent.append(np.zeros(100))\n",
    "            \n",
    "        elif(sent[i] == '<stop_tag>'):\n",
    "            n_sent.append(np.ones(100))\n",
    "        else:\n",
    "            try:\n",
    "                n_sent.append(wv_model.wv[sent[i]])\n",
    "            except:\n",
    "                n_sent.append(np.zeros(100))\n",
    "\n",
    "        i = i + 1\n",
    "    return n_sent\n",
    "\n",
    "def batch_numerical(sent_set):\n",
    "    numeric_batch = []#numerized batch\n",
    "    i = 0\n",
    "    while(i < len(sent_set) ): #BATCH_SIZE\n",
    "        dial = []#numerized dialogue\n",
    "        j = 0\n",
    "        while(j < len(sent_set[i])): #per dialogue\n",
    "            '''\n",
    "            sent_set[i][j] ['Is' 'this' 'your' 'new' 'teacher' '?' '<pad>']\n",
    "            sent_set[i][j] ['Yes' ',' 'it' 'is' '.' '<pad>' '<pad>']\n",
    "            sent_set[i][j] ['Is' 'she' 'short' '?' '<pad>' '<pad>' '<pad>']\n",
    "            sent_set[i][j] ['No' ',' 'she' '’' 's' 'average' '.']\n",
    "            sent_set[i][j] ['What' 'color' 'are' 'her' 'eyes' '?' '<pad>']\n",
    "            sent_set[i][j] ['They' '’' 're' 'dark' 'gray' '.' '<pad>']\n",
    "            sent_set[i][j] ['What' 'color' 'is' 'her' 'hair' '?' '<pad>']\n",
    "            sent_set[i][j] ['It' '’' 's' 'blond' '.' '<pad>' '<pad>']\n",
    "            sent_set[i][j] ['And' 'how' 'old' 'is' 'she' '?' '<pad>']\n",
    "            sent_set[i][j] ['I' 'don' '’' 't' 'know' '.' '<pad>']\n",
    "            sent_set[i][j] ['<stop_tag>' '<pad>' '<pad>' '<pad>' '<pad>' '<pad>' '<pad>']\n",
    "            '''\n",
    "            dial.append(numerize_sent(sent_set[i][j], len(sent_set[i][j]))) #numerized_sentence\n",
    "            j = j + 1\n",
    "        numeric_batch.append(dial)\n",
    "        i = i + 1\n",
    "    #batch * sent_num * sent_leng * wv -> numeric_batch\n",
    "    return numeric_batch\n",
    "\n",
    "def make_batch2sent(new):\n",
    "    for_sentmodel = []\n",
    "    batchnum = 0\n",
    "    while (batchnum < len(new)): #BATCH_SIZE\n",
    "        for_sentmodel = for_sentmodel + new[batchnum]\n",
    "        batchnum = batchnum + 1\n",
    "    sentbatch_len = len(for_sentmodel)\n",
    "    #batch * sent_num * sent_leng * wv -> all_sent_num * sent_leng * wv\n",
    "    return sentbatch_len, for_sentmodel\n",
    "\n",
    "def pad_dial(last_v):\n",
    "    leng_set = []\n",
    "    i = 0\n",
    "    while(i < len(last_v)):#BATCH_SIZE\n",
    "        leng_set.append(len(last_v[i]))#sentence num\n",
    "        i = i + 1\n",
    "    padded_dial = pad_sequence(last_v, batch_first = True)#append padtag vector\n",
    "    #print('max_dialogue_length',len(padded_dial[0]))\n",
    "    \n",
    "    return padded_dial, leng_set\n",
    "\n",
    "def sent_loader(sentence): #pre_process per sentence\n",
    "    result = []\n",
    "    for elem in sentence.split(' '):\n",
    "        if elem != '':\n",
    "            result = np.append(result, elem)\n",
    "    return result,len(result)\n",
    "\n",
    "def pad_cat_tag(emotion, act): \n",
    "    i = 0\n",
    "    new_tag = []\n",
    "    while(i < len(emotion)): #BATCH_SIZE\n",
    "        emo, lenge = sent_loader(emotion[i][0])\n",
    "        ac, lenga = sent_loader(act[i][0])\n",
    "        j = 0\n",
    "        inte = []\n",
    "        inte.append(tag_to_ix['start_tag']) #append stop tag\n",
    "        while(j < len(emo)): #sent length\n",
    "            inte.append(int(emo[j]) * 4 + int(ac[j]))\n",
    "            j = j + 1\n",
    "        inte.append(tag_to_ix['stop_tag']) #append stop tag\n",
    "        torch_inte = torch.tensor(inte)\n",
    "        new_tag.append(torch_inte) #str to int\n",
    "        i = i + 1\n",
    "\n",
    "            \n",
    "    padded_tag = pad_sequence(new_tag, batch_first = True, padding_value = tag_to_ix['pad_tag'])\n",
    "    \n",
    "    #emotion+action string -> emotion+action numb + padding\n",
    "    #batch*tag\n",
    "    return padded_tag\n",
    "\n",
    "def make_mask(leng):\n",
    "    '''\n",
    "    make one-hot vector of mask from lengset\n",
    "    '''\n",
    "\n",
    "    var = np.zeros(shape = (len(leng), leng[0])) #len(leng) = BATCH_SIZE, leng[0]+1= largest dialogue + stop\n",
    "    i = 0\n",
    "    while(i < len(leng)):#BATCH_SIZE\n",
    "        j = 0\n",
    "        while(j < leng[0]): \n",
    "            if(j < leng[i]): # <= stop tag\n",
    "                var[i][j] = 1\n",
    "            j = j + 1\n",
    "        \n",
    "        i = i + 1\n",
    "\n",
    "    return var\n",
    "\n",
    "def log_sum_exp(x):\n",
    "    max_score, _ = torch.max(x, -1)\n",
    "    max_score_broadcast = max_score.unsqueeze(-1).expand_as(x)\n",
    "    return max_score + torch.log(torch.sum(torch.exp(x - max_score_broadcast), -1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# class for load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Example(object):\n",
    "    @classmethod\n",
    "    def fromdict(cls, data, fields):\n",
    "        ex = cls()\n",
    "        for key, vals in fields.items():\n",
    "            if key not in data:\n",
    "                raise ValueError(\"Specified key {} was not found in \"\n",
    "                                 \"the input data\".format(key))\n",
    "            if vals is not None:\n",
    "                if not isinstance(vals, list):\n",
    "                    vals = [vals]\n",
    "                for val in vals:\n",
    "                    name, field = val\n",
    "                    setattr(ex, name, field.preprocess(data[key]))\n",
    "        return ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    sort_key = None\n",
    "\n",
    "    def __init__(self, examples, fields, filter_pred=None):\n",
    "        self.examples = examples\n",
    "\n",
    "        self.fields = dict(fields)\n",
    "\n",
    "        # Unpack field tuples\n",
    "        for n, f in list(self.fields.items()):\n",
    "            if isinstance(n, tuple):\n",
    "                self.fields.update(zip(n, f))\n",
    "                del self.fields[n]\n",
    "        self.pp = tuple(d for d in self.examples if d is not None)\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def splits(cls, path=None, root='.data', train=None, **kwargs):\n",
    "\n",
    "        train_data = cls(os.path.join(path, train), **kwargs)\n",
    "        #print(train_data.examples) #여기엔 field example둘다 들어있음\n",
    "        #print(tuple(d for d in train_data if d is not None)) #여기엔 example만 나열된 튜플이됨\n",
    "        return tuple(d for d in train_data if d is not None)\n",
    "\n",
    "    def split(self, split_ratio=0.7, stratified=False, strata_field='label',\n",
    "              random_state=None):\n",
    "        \n",
    "        train_ratio, test_ratio, val_ratio = check_split_ratio(split_ratio)\n",
    "\n",
    "        # For the permutations\n",
    "        rnd = RandomShuffler(random_state)\n",
    "        if not stratified:\n",
    "            train_data, test_data, val_data = rationed_split(self.examples, train_ratio,\n",
    "                                                             test_ratio, val_ratio, rnd)\n",
    "        else:\n",
    "            if strata_field not in self.fields:\n",
    "                raise ValueError(\"Invalid field name for strata_field {}\"\n",
    "                                 .format(strata_field))\n",
    "            strata = stratify(self.examples, strata_field)\n",
    "            train_data, test_data, val_data = [], [], []\n",
    "            for group in strata:\n",
    "                # Stratify each group and add together the indices.\n",
    "                group_train, group_test, group_val = rationed_split(group, train_ratio,\n",
    "                                                                    test_ratio, val_ratio,\n",
    "                                                                    rnd)\n",
    "                train_data += group_train\n",
    "                test_data += group_test\n",
    "                val_data += group_val\n",
    "\n",
    "        splits = tuple(Dataset(d, self.fields)\n",
    "                       for d in (train_data, val_data, test_data) if d)\n",
    "\n",
    "        # In case the parent sort key isn't none\n",
    "        if self.sort_key:\n",
    "            for subset in splits:\n",
    "                subset.sort_key = self.sort_key\n",
    "        return splits\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.examples[i]\n",
    "\n",
    "    def __len__(self):\n",
    "        try:\n",
    "            return len(self.examples)\n",
    "        except TypeError:\n",
    "            return 2 ** 32\n",
    "\n",
    "    def __iter__(self):\n",
    "        for x in self.examples:\n",
    "            yield x\n",
    "\n",
    "    def __getattr__(self, attr):\n",
    "        if attr in self.fields:\n",
    "            for x in self.examples:\n",
    "                yield getattr(x, attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class my_TabularDataset(Dataset):\n",
    "\n",
    "    def __init__(self, path,  fields,  **kwargs):\n",
    "\n",
    "\n",
    "        with open(path, encoding=\"utf8\") as f:\n",
    "            for line in f:\n",
    "                examples = [Example.fromdict(per_data, fields) for per_data in json.loads(line)]\n",
    "\n",
    "\n",
    "        if isinstance(fields, dict):\n",
    "            fields, field_dict = [], fields\n",
    "            for field in field_dict.values():\n",
    "                if isinstance(field, list):\n",
    "                    fields.extend(field)\n",
    "                else:\n",
    "                    fields.append(field)\n",
    "\n",
    "\n",
    "        super(my_TabularDataset, self).__init__(examples, fields, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model_1 (shared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class makesent_gru(nn.Module):\n",
    "    def __init__(self, hidden_size, bidirectional):\n",
    "        super(makesent_gru, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        if (bidirectional == True):\n",
    "            self.bidirectional = 2\n",
    "        else:\n",
    "            self.bidirectional = 1\n",
    "        self.gru = nn.GRU(100, 100, bidirectional=bidirectional)\n",
    "        self.lastnet = nn.Linear(200, 100)\n",
    "        \n",
    "    def masking_f(self, new_sent, all_seq_len):\n",
    "        remake = torch.transpose(new_sent, 0, 1)\n",
    "        #remake [326, 7, 200]\n",
    "        \n",
    "        i = 0\n",
    "        while(i < len(remake)):\n",
    "            if i == 0:\n",
    "                # all_seq_len[0]-1 -> 5\n",
    "                tensor = remake[0][all_seq_len[0]-1].view(1,200)\n",
    "            else:\n",
    "                tensor = torch.cat((tensor, remake[i][all_seq_len[i]-1].view(1,200)), 0)\n",
    "            i = i + 1\n",
    "        return tensor\n",
    "    \n",
    "    def forward(self, char, h0, masking_v):\n",
    "        #char 7,326,100 [6][0] = 0000....<pad>\n",
    "        gru_out, h0 = self.gru(char, h0)\n",
    "        #gru 7,326,200\n",
    "        \n",
    "        last_hidden_state = self.masking_f(gru_out, masking_v)\n",
    "        #[326,200]\n",
    "        \n",
    "        last_w = self.lastnet(last_hidden_state)\n",
    "        #[326,100]\n",
    "        \n",
    "        return last_w\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(self.bidirectional, 1, self.hidden_size, device=device, requires_grad=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model_2 \n",
    "\n",
    "## compare crf-gru with crf , bi-gru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CRF_(nn.Module):\n",
    "    def __init__(self, tag_to_ix, hidden_dim):\n",
    "        super(BiGru_CRF, self).__init__()\n",
    "\n",
    "        self.gru = nn.GRU(100, 100, bidirectional=True) # default requires_grad = true\n",
    "        self.hidden2tag = nn.Linear(100, 31) # default requires_grad = true\n",
    "        self.transitions = nn.Parameter(torch.randn(31, 31))# [a,b] trans from b to a,  requires_grad = true\n",
    "        self.transitions.data[0, :] = -10000 #all to start\n",
    "        self.transitions.data[:, 29] = -10000 #stop to all\n",
    "        self.transitions.data[:, 30] = -10000 #pad to all\n",
    "        self.transitions.data[30][30] = 0 #pad to pad\n",
    "        self.transitions.data[29][30] = 0 #stop to pad\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.tag_to_ix = tag_to_ix\n",
    "        \n",
    "\n",
    "    def init_hidden(self,batch):\n",
    "        return Variable(torch.zeros(2, batch, 100).cuda()) # default requires_grad = false \n",
    "    \n",
    "    def _get_gru_features(self, batch, sentence_set):\n",
    "        \n",
    "        hidden = self.init_hidden(batch)\n",
    "        #gru_out, hidden = self.gru(sentence_set, hidden)\n",
    "\n",
    "        gru_feats = self.hidden2tag(sentence_set)\n",
    "\n",
    "        return gru_feats\n",
    "\n",
    "    def for_score(self, pre_mask, feats):\n",
    "        score = Variable(torch.zeros((BATCH_SIZE, 31)).fill_(-10000.).cuda()) #default requires_grad = false \n",
    "        score[:, self.tag_to_ix['start_tag']] = 0. #start to all is 0\n",
    "        \n",
    "        mask = Variable(torch.Tensor(pre_mask).cuda()) # default requires_grad = false \n",
    "        \n",
    "        for t in range(feats.size(0)):  # 안에서 연산하는데이터들은 batch*featuresize*featuresize\n",
    "            \n",
    "            mask_t = mask[:, t].unsqueeze(-1).expand_as(score) #batch_size -> batch_size*featuresize\n",
    "            \n",
    "            score_t = score.unsqueeze(1).expand(-1, *self.transitions.size()) #batch_size*f -> batch_size*f*f\n",
    "            \n",
    "            emit = feats[t].unsqueeze(-1).expand_as(score_t) #b*f-> b*f*f\n",
    "            \n",
    "            trans = self.transitions.unsqueeze(0).expand_as(score_t) #b*f*f\n",
    "            \n",
    "            score_t = log_sum_exp(score_t + emit + trans)\n",
    "            \n",
    "            score = score_t * mask_t + score * (1 - mask_t) #no updating in masked score,all b*f\n",
    "\n",
    "        score = log_sum_exp(score)\n",
    "        return score\n",
    "\n",
    "    def cal_score(self, mask, feats, tag):\n",
    "        score = Variable(torch.FloatTensor(BATCH_SIZE).fill_(0.).cuda()) # default requires_grad = false \n",
    "        \n",
    "        temp_tag = Variable(tag.cuda()) # default requires_grad = false \n",
    "        mask_tensor = torch.transpose(torch.FloatTensor(mask), 0, 1) #seq*batch\n",
    "        mask_tensor = Variable(mask_tensor.cuda()) # default requires_grad = false \n",
    "        \n",
    "        \n",
    "        for i, feat in enumerate(feats): #seq*batch*feat->batch*feat\n",
    "            \n",
    "            transit = torch.cat(\n",
    "                [torch.tensor([self.transitions[temp_tag[batch][i + 1], temp_tag[batch][i]]]) for batch in range(BATCH_SIZE)])\n",
    "            \n",
    "            transit = transit.cuda()\n",
    "            \n",
    "            transit = transit * mask_tensor[i] #batch*batch->batch\n",
    "\n",
    "            emit = torch.cat([feat[batch][temp_tag[batch][i + 1]].view(1, -1) for batch in range(BATCH_SIZE)]).squeeze(1)\n",
    "\n",
    "            emit = emit * mask_tensor[i]#batch*batch->batch\n",
    "\n",
    "            score = score + transit + emit\n",
    "\n",
    "        return score\n",
    "\n",
    "    def neg_log_likelihood(self, mask, sentence, tags, batch):\n",
    "\n",
    "        feats = self._get_gru_features(batch, sentence)\n",
    "        \n",
    "        forward_score = self.for_score(mask, feats)\n",
    "\n",
    "        gold_score = self.cal_score(mask, feats, tags)\n",
    "        '''\n",
    "        newt = self.transitions.data.cpu().numpy()\n",
    "        newt[0,:] = 0\n",
    "        newt[:,29] = 0\n",
    "        newt[:,30] = 0\n",
    "        x = np.tile(np.arange(1, 32), (31, 1))\n",
    "        y = x.transpose()\n",
    "        z = newt #for visdom\n",
    "        print(z)\n",
    "        \n",
    "        \n",
    "        x = np.tile(np.arange(1, 32), (31, 1))\n",
    "        y = x.transpose()\n",
    "        z = (x + y)/20\n",
    "        \n",
    "        # surface\n",
    "        viz.surf(X=z, opts=dict(colormap='Hot'))\n",
    "        '''\n",
    "        return forward_score - gold_score\n",
    "\n",
    "    def _viterbi_decode(self, mask, feats):\n",
    "        backpointers = []\n",
    "\n",
    "        # Initialize the viterbi variables in log space\n",
    "        init_vvars = Variable(torch.full((1, 31), -10000.).cuda()) # default requires_grad = false \n",
    "        init_vvars[0][0] = 0\n",
    "\n",
    "        # forward_var at step i holds the viterbi variables for step i-1\n",
    "        forward_var = init_vvars\n",
    "\n",
    "        for i, feat in enumerate(feats):\n",
    "            if mask[i] == 0:\n",
    "                print('breaked')\n",
    "                break\n",
    "            bptrs_t = []  # holds the backpointers for this step\n",
    "            viterbivars_t = []  # holds the viterbi variables for this step\n",
    "\n",
    "            for next_tag in range(31):\n",
    "                next_tag_var = forward_var + self.transitions[next_tag]\n",
    "                best_tag_id = argmax(next_tag_var)\n",
    "                bptrs_t.append(best_tag_id)\n",
    "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
    "\n",
    "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
    "            backpointers.append(bptrs_t)\n",
    "\n",
    "        #terminal_var = forward_var  + self.transitions[self.tag_to_ix['stop_tag']]\n",
    "        best_tag_id = argmax(forward_var) #not terminal_var\n",
    "        path_score = forward_var[0][best_tag_id]\n",
    "\n",
    "        best_path = [best_tag_id]\n",
    "        for bptrs_t in reversed(backpointers):\n",
    "            best_tag_id = bptrs_t[best_tag_id]\n",
    "            best_path.append(best_tag_id)\n",
    "        # Pop off the start tag (we dont want to return that to the caller)\n",
    "        start = best_path.pop()\n",
    "        assert start == 0  # Sanity check\n",
    "        best_path.reverse()\n",
    "        return path_score, best_path\n",
    "\n",
    "    def forward(self,batch, dummy_input, seq):  # dont confuse this with _forward_alg above.\n",
    "        # Get the emission scores from the BiLSTM\n",
    "        lstm_feats = self._get_gru_features(batch,dummy_input[1])\n",
    "        \n",
    "        lstm_feats = torch.transpose(lstm_feats,0,1)\n",
    "        mask = dummy_input[0]\n",
    "        #print(self.transitions)\n",
    "        # Find the best path, given thue features.\n",
    "        score, tag_seq = self._viterbi_decode(mask[seq], lstm_feats[seq])\n",
    "        return score, tag_seq\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BiGru_(nn.Module):\n",
    "    def __init__(self, tag_to_ix, hidden_dim):\n",
    "        super(BiGru_CRF, self).__init__()\n",
    "\n",
    "        self.gru = nn.GRU(100, 100, bidirectional=True) # default requires_grad = true\n",
    "        self.hidden2tag = nn.Linear(200, 31) # default requires_grad = true\n",
    " \n",
    "\n",
    "        self.tag_to_ix = tag_to_ix\n",
    "        \n",
    "    def _get_gru_features(self, batch, sentence_set):\n",
    "        \n",
    "        hidden = self.init_hidden(batch)\n",
    "        gru_out, hidden = self.gru(sentence_set, hidden)\n",
    "\n",
    "        gru_feats = self.hidden2tag(gru_out)\n",
    "\n",
    "        return gru_feats\n",
    "\n",
    "\n",
    "    def forward(self,batch, dummy_input, seq):  # dont confuse this with _forward_alg above.\n",
    "        feats = self._get_gru_features(batch, sentence)\n",
    "        \n",
    "      \n",
    "        return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BiGru_CRF(nn.Module):\n",
    "    def __init__(self, tag_to_ix, hidden_dim):\n",
    "        super(BiGru_CRF, self).__init__()\n",
    "\n",
    "        self.gru = nn.GRU(100, 100, bidirectional=True) # default requires_grad = true\n",
    "        self.hidden2tag = nn.Linear(200, 31) # default requires_grad = true\n",
    "        self.transitions = nn.Parameter(torch.randn(31, 31))# [a,b] trans from b to a,  requires_grad = true\n",
    "        self.transitions.data[0, :] = -10000 #all to start\n",
    "        self.transitions.data[:, 29] = -10000 #stop to all\n",
    "        self.transitions.data[:, 30] = -10000 #pad to all\n",
    "        self.transitions.data[30][30] = 0 #pad to pad\n",
    "        self.transitions.data[29][30] = 0 #stop to pad\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.tag_to_ix = tag_to_ix\n",
    "        \n",
    "\n",
    "    def init_hidden(self,batch):\n",
    "        return Variable(torch.zeros(2, batch, 100).cuda()) # default requires_grad = false \n",
    "    \n",
    "    def _get_gru_features(self, batch, sentence_set):\n",
    "        \n",
    "        hidden = self.init_hidden(batch)\n",
    "        gru_out, hidden = self.gru(sentence_set, hidden)\n",
    "\n",
    "        gru_feats = self.hidden2tag(gru_out)\n",
    "\n",
    "        return gru_feats\n",
    "\n",
    "    def for_score(self, pre_mask, feats):\n",
    "        \n",
    "        score = Variable(torch.zeros((BATCH_SIZE, 31)).fill_(-10000.).cuda()) #default requires_grad = false \n",
    "        score[:, self.tag_to_ix['start_tag']] = 0. #start to all is 0\n",
    "        \n",
    "        mask = Variable(torch.Tensor(pre_mask).cuda()) # default requires_grad = false \n",
    "        \n",
    "        for t in range(feats.size(0)):  # 안에서 연산하는데이터들은 batch*featuresize*featuresize\n",
    "            \n",
    "            mask_t = mask[:, t].unsqueeze(-1).expand_as(score) #batch_size -> batch_size*featuresize\n",
    "            \n",
    "            score_t = score.unsqueeze(1).expand(-1, *self.transitions.size()) #batch_size*f -> batch_size*f*f\n",
    "            \n",
    "            emit = feats[t].unsqueeze(-1).expand_as(score_t) #b*f-> b*f*f\n",
    "            \n",
    "            trans = self.transitions.unsqueeze(0).expand_as(score_t) #b*f*f\n",
    "            \n",
    "            score_t = log_sum_exp(score_t + emit + trans)\n",
    "            \n",
    "            score = score_t * mask_t + score * (1 - mask_t) #no updating in masked score,all b*f\n",
    "\n",
    "        score = log_sum_exp(score)\n",
    "        return score\n",
    "\n",
    "    def cal_score(self, mask, feats, tag):\n",
    "        score = Variable(torch.FloatTensor(BATCH_SIZE).fill_(0.).cuda()) # default requires_grad = false \n",
    "        \n",
    "        temp_tag = Variable(tag.cuda()) # default requires_grad = false \n",
    "        mask_tensor = torch.transpose(torch.FloatTensor(mask), 0, 1) #seq*batch\n",
    "        mask_tensor = Variable(mask_tensor.cuda()) # default requires_grad = false \n",
    "        \n",
    "        \n",
    "        for i, feat in enumerate(feats): #seq*batch*feat->batch*feat\n",
    "            \n",
    "            transit = torch.cat(\n",
    "                [torch.tensor([self.transitions[temp_tag[batch][i + 1], temp_tag[batch][i]]]) for batch in range(BATCH_SIZE)])\n",
    "            \n",
    "            transit = transit.cuda()\n",
    "            \n",
    "            transit = transit * mask_tensor[i] #batch*batch->batch\n",
    "\n",
    "            emit = torch.cat([feat[batch][temp_tag[batch][i + 1]].view(1, -1) for batch in range(BATCH_SIZE)]).squeeze(1)\n",
    "\n",
    "            emit = emit * mask_tensor[i]#batch*batch->batch\n",
    "\n",
    "            score = score + transit + emit\n",
    "\n",
    "        return score\n",
    "\n",
    "    def neg_log_likelihood(self, mask, sentence, tags, batch):\n",
    "\n",
    "        feats = self._get_gru_features(batch, sentence)\n",
    "        \n",
    "        forward_score = self.for_score(mask, feats)\n",
    "\n",
    "        gold_score = self.cal_score(mask, feats, tags)\n",
    "        '''\n",
    "        newt = self.transitions.data.cpu().numpy()\n",
    "        newt[0,:] = 0\n",
    "        newt[:,29] = 0\n",
    "        newt[:,30] = 0\n",
    "        x = np.tile(np.arange(1, 32), (31, 1))\n",
    "        y = x.transpose()\n",
    "        z = newt #for visdom\n",
    "        print(z)\n",
    "        \n",
    "        \n",
    "        x = np.tile(np.arange(1, 32), (31, 1))\n",
    "        y = x.transpose()\n",
    "        z = (x + y)/20\n",
    "        \n",
    "        # surface\n",
    "        viz.surf(X=z, opts=dict(colormap='Hot'))\n",
    "        '''\n",
    "        return forward_score - gold_score\n",
    "\n",
    "    def _viterbi_decode(self, mask, feats):\n",
    "        backpointers = []\n",
    "\n",
    "        # Initialize the viterbi variables in log space\n",
    "        init_vvars = Variable(torch.full((1, 31), -10000.).cuda()) # default requires_grad = false \n",
    "        init_vvars[0][0] = 0\n",
    "\n",
    "        # forward_var at step i holds the viterbi variables for step i-1\n",
    "        forward_var = init_vvars\n",
    "\n",
    "        for i, feat in enumerate(feats):\n",
    "            if mask[i] == 0:\n",
    "                #print('breaked')\n",
    "                break\n",
    "            bptrs_t = []  # holds the backpointers for this step\n",
    "            viterbivars_t = []  # holds the viterbi variables for this step\n",
    "            for next_tag in range(31):\n",
    "                next_tag_var = forward_var + self.transitions[next_tag]\n",
    "                best_tag_id = argmax(next_tag_var)\n",
    "                bptrs_t.append(best_tag_id)\n",
    "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
    " \n",
    "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
    "            backpointers.append(bptrs_t)\n",
    "\n",
    "        #terminal_var = forward_var  + self.transitions[self.tag_to_ix['stop_tag']]\n",
    "        best_tag_id = argmax(forward_var) #not terminal_var\n",
    "        path_score = forward_var[0][best_tag_id]\n",
    "\n",
    "        best_path = [best_tag_id]\n",
    "        for bptrs_t in reversed(backpointers):\n",
    "            best_tag_id = bptrs_t[best_tag_id]\n",
    "            best_path.append(best_tag_id)\n",
    "        # Pop off the start tag (we dont want to return that to the caller)\n",
    "        start = best_path.pop()\n",
    "        assert start == 0  # Sanity check\n",
    "        best_path.reverse()\n",
    "        return path_score, best_path\n",
    "\n",
    "    def forward(self,batch, dummy_input, seq):  # dont confuse this with _forward_alg above.\n",
    "        # Get the emission scores from the BiLSTM\n",
    "        lstm_feats = self._get_gru_features(batch,dummy_input[1])\n",
    "        \n",
    "        lstm_feats = torch.transpose(lstm_feats,0,1)\n",
    "        mask = dummy_input[0]\n",
    "        #print(self.transitions)\n",
    "        # Find the best path, given thue features.\n",
    "        score, tag_seq = self._viterbi_decode(mask[seq], lstm_feats[seq])\n",
    "        return score, tag_seq\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocess function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pad_cat_tag2(emotion, act): \n",
    "    i = 0\n",
    "    new_tag = []\n",
    "    decodesent = []\n",
    "    while(i < len(emotion)): #BATCH_SIZE\n",
    "        emo, lenge = sent_loader(emotion[i][0])\n",
    "        ac, lenga = sent_loader(act[i][0])\n",
    "        j = 0\n",
    "        inte = []\n",
    "        \n",
    "        #inte.append(tag_to_ix['start_tag']) #append stop tag\n",
    "        while(j < len(emo)-1): #sent length\n",
    "            inte.append(int(emo[j]) * 4 + int(ac[j]))\n",
    "            j = j + 1\n",
    "        decodesent.append(int(emo[j]) * 4 + int(ac[j])) #<-for decoding sent\n",
    "        #inte.append(tag_to_ix['stop_tag']) #append stop tag\n",
    "        torch_inte = torch.tensor(inte)\n",
    "        new_tag.append(torch_inte) #str to int\n",
    "        i = i + 1\n",
    "\n",
    "            \n",
    "    padded_tag = pad_sequence(new_tag, batch_first = True, padding_value = tag_to_ix['pad_tag'])\n",
    "    \n",
    "    #emotion+action string -> emotion+action numb + padding\n",
    "    #batch*tag\n",
    "    return padded_tag, decodesent\n",
    "\n",
    "def pad_batch2(minibatch):\n",
    "    i = 0\n",
    "    new_batch = []\n",
    "    decode_newbatch = []\n",
    "    leng_set = []\n",
    "    decode_lengset = []\n",
    "    maxleng = 1\n",
    "    sentnum_per_dialogue = []\n",
    "    while(i < len(minibatch)): #almost equal to BATCH_SIZE\n",
    "        j = 0\n",
    "        temp = []\n",
    "        sentnum_per_dialogue.append(len(minibatch[i].Text)-2) #-stoptag-lastsent\n",
    "        #save sentnum per dialogue\n",
    "        while(j < len(minibatch[i].Text)-2):#-lastsent\n",
    "            sent, leng = sent_loader(minibatch[i].Text[j])  \n",
    "            \n",
    "            #convert text to word_list, word_list_length\n",
    "            leng_set.append(leng)\n",
    "            if leng > maxleng:\n",
    "                maxleng = leng\n",
    "\n",
    "            temp.append(sent)\n",
    "            j = j + 1\n",
    "        sent, leng = sent_loader(minibatch[i].Text[j])\n",
    "        decode_newbatch.append(sent)\n",
    "        decode_lengset.append(leng)\n",
    "        #temp.append([\"<stop_tag>\"])\n",
    "        #leng_set.append(1) #stoptag\n",
    "        new_batch.append(temp)\n",
    "\n",
    "        i = i + 1\n",
    "\n",
    "    i = 0\n",
    "    while (i < len(minibatch)): #almost equal to BATCH_SIZE\n",
    "        j = 0\n",
    "        while (j < len(new_batch[i])):\n",
    "\n",
    "            while(len(new_batch[i][j]) < maxleng):\n",
    "                new_batch[i][j] = np.append(new_batch[i][j],\"<pad>\")\n",
    "\n",
    "            j = j + 1\n",
    "        i = i + 1\n",
    "        \n",
    "    i = 0\n",
    "    while (i < len(minibatch)): #almost equal to BATCH_SIZE\n",
    "        \n",
    "        while(len(decode_newbatch[i]) < maxleng):\n",
    "            decode_newbatch[i] = np.append(decode_newbatch[i],\"<pad>\")\n",
    "\n",
    "\n",
    "        i = i + 1\n",
    "    #batch * sentnum * (word_list+pad) -> new_batch\n",
    "    #batch * sentnum * (word_list_length) -> leng_set\n",
    "    #batch * (sentnum) -> sentnum_per_dialogue\n",
    "\n",
    "    return new_batch, leng_set, sentnum_per_dialogue, decode_newbatch, decode_lengset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_preprocess(sent, batch_data):\n",
    "\n",
    "    \n",
    "    #sorted with dialogue length\n",
    "    #print(batch_data[0].Text)\n",
    "    #######################################################\n",
    "    emotion_set = []\n",
    "    action_set = []\n",
    "    i = 0\n",
    "    while(i < len(batch_data)): #equals to BATCH_SIZE except last dataset\n",
    "        emotion_set.append(batch_data[i].labels_1)\n",
    "        \n",
    "        action_set.append(batch_data[i].labels_2)\n",
    "        \n",
    "        i = i + 1\n",
    "    \n",
    "    new_tag, decodetag = pad_cat_tag2(emotion_set, action_set) #in new preprocess, remake pad cat tag to split last sent\n",
    "    '''\n",
    "    new_tag representation 0 = start_tag, 29 = stop_tag, 30 = pad_tag\n",
    "    \n",
    "    tensor([   2,   1,   2,   1,   2,   1,   2,   1,   2,   1]) except1\n",
    "    tensor([   2,   1,   2,   1,   2,   1,   2,   1,   2,   1]) except1\n",
    "    tensor([  21,   1,   1,   1,  30,  30,  30,  30,  30,  30]) except1\n",
    "    tensor([   2,   1,   2,   1,  30,  30,  30,  30,  30,  30]) except1\n",
    "    tensor([   1,   1,   1,   1,  30,  30,  30,  30,  30,  30]) except1\n",
    "    tensor([   2,   1,   2,   1,  30,  30,  30,  30,  30,  30]) except1\n",
    "    tensor([  17,  17,  17,  30,  30,  30,  30,  30,  30,  30]) except17\n",
    "    tensor([   1,   1,   1,  30,  30,  30,  30,  30,  30,  30]) ..\n",
    "    tensor([   3,   2,  30,  30,  30,  30,  30,  30,  30,  30]) ..\n",
    "    tensor([  17,  17,  30,  30,  30,  30,  30,  30,  30,  30]) ..\n",
    "    tensor([   2,   2,  30,  30,  30,  30,  30,  30,  30,  30]) ..\n",
    "    \n",
    "    decodesent representation\n",
    "    [1, 1, 1, 1, 1, 1, 17, 1, 2, 17, 2...] len = batchsize\n",
    "    \n",
    "    '''\n",
    "   \n",
    "    \n",
    "    #batch*tag\n",
    "    new_tag = Variable(new_tag.cuda())# default requires_grad = false\n",
    "    \n",
    "    #####################################################tag_preprocess\n",
    "    \n",
    "    \n",
    "    new, all_seq_len, sentnum_per_batch, dn, dl = pad_batch2(batch_data) #in new preprocess, remake pad batch to split last sent\n",
    "    #batch * sentnum * (word_list+pad) -> new\n",
    "    #batch * sentnum * (word_list_length) -> all_seq_len\n",
    "    #batch * (sentnum) -> sentnum_per_batch\n",
    "    #batch * (word_list + pad) -> dn\n",
    "    #batch * leng -> dl\n",
    "    '''\n",
    "    print(dn[0])\n",
    "    print(dn[1])\n",
    "    print(dn[2])\n",
    "    print(dl)\n",
    "    \n",
    "    ['Thank' 'you' 'so' 'much' '.' 'You' 'guys' 'are' 'really' 'responsible'\n",
    "     '.' '<pad>' '<pad>' '<pad>' '<pad>' '<pad>' '<pad>' '<pad>' '<pad>'\n",
    "     '<pad>' '<pad>' '<pad>' '<pad>' '<pad>' '<pad>' '<pad>' '<pad>' '<pad>'\n",
    "     '<pad>' '<pad>' '<pad>' '<pad>' '<pad>' '<pad>' '<pad>' '<pad>' '<pad>'\n",
    "     '<pad>' '<pad>' '<pad>' '<pad>' '<pad>' '<pad>' '<pad>' '<pad>' '<pad>'\n",
    "     '<pad>']\n",
    "    ['Alright' ',' 'please' 'show' 'me' 'what' 'you' 'have' '.' '<pad>'\n",
    "     '<pad>' '<pad>' '<pad>' '<pad>' '<pad>' '<pad>' '<pad>' '<pad>' '<pad>'\n",
    "     '<pad>' '<pad>' '<pad>' '<pad>' '<pad>' '<pad>' '<pad>' '<pad>' '<pad>'\n",
    "     '<pad>' '<pad>' '<pad>' '<pad>' '<pad>' '<pad>' '<pad>' '<pad>' '<pad>'\n",
    "     '<pad>' '<pad>' '<pad>' '<pad>' '<pad>' '<pad>' '<pad>' '<pad>' '<pad>'\n",
    "     '<pad>']\n",
    "    ['Bye' '!' '<pad>' '<pad>' '<pad>' '<pad>' '<pad>' '<pad>' '<pad>' '<pad>'\n",
    "     '<pad>' '<pad>' '<pad>' '<pad>' '<pad>' '<pad>' '<pad>' '<pad>' '<pad>'\n",
    "     '<pad>' '<pad>' '<pad>' '<pad>' '<pad>' '<pad>' '<pad>' '<pad>' '<pad>'\n",
    "     '<pad>' '<pad>' '<pad>' '<pad>' '<pad>' '<pad>' '<pad>' '<pad>' '<pad>'\n",
    "     '<pad>' '<pad>' '<pad>' '<pad>' '<pad>' '<pad>' '<pad>' '<pad>' '<pad>'\n",
    "     '<pad>']\n",
    "    [11, 9, 2, 3, 12, 15, 2, 5, 20, 24, 6, 12, 10, 4, 4, 11, 6, 12, 7, 6, 15, \n",
    "    16, 12, 2, 17, 4, 7, 2, 2, 12, 20, 9, 2, 6, 9, 4, 21, 3, 7, 5, 4, 18, 7, \n",
    "    7, 10, 19, 7, 31, 9, 7, 7, 4, 12, 4, 4, 15, 4, 12, 9, 6, 2, 2, 6, 10, 16, \n",
    "    4, 6, 7, 5, 22, 9, 11, 11, 10, 4, 4, 2, 2, 4, 17, 15, 5, 16, 14, 5, 3, 22, \n",
    "    2, 2, 20, 7, 2, 2, 3, 2, 3, 6, 6, 5, 5]\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    new[0]\n",
    "    [array(['Is', 'this', 'your', 'new', 'teacher', '?', '<pad>'], dtype='<U32'), \n",
    "      array(['Yes', ',', 'it', 'is', '.', '<pad>', '<pad>'], dtype='<U32'), \n",
    "      array(['Is', 'she', 'short', '?', '<pad>', '<pad>', '<pad>'], dtype='<U32'), \n",
    "      array(['No', ',', 'she', '’', 's', 'average', '.'], dtype='<U32'), \n",
    "      array(['What', 'color', 'are', 'her', 'eyes', '?', '<pad>'], dtype='<U32'), \n",
    "      array(['They', '’', 're', 'dark', 'gray', '.', '<pad>'], dtype='<U32'), \n",
    "      array(['What', 'color', 'is', 'her', 'hair', '?', '<pad>'], dtype='<U32'),\n",
    "      array(['It', '’', 's', 'blond', '.', '<pad>', '<pad>'], dtype='<U32'), \n",
    "      array(['And', 'how', 'old', 'is', 'she', '?', '<pad>'], dtype='<U32'), \n",
    "      array(['I', 'don', '’', 't', 'know', '.', '<pad>'], dtype='<U32'), \n",
    "      array(['<stop_tag>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], dtype='<U32'), \n",
    "      \n",
    "    all_seq_len[0]\n",
    "    [6, 5, 4, 7, 6, 6, 6, 5, 6, 6, 1, \n",
    "    6, 5, 4, 7, 6, 6, 6, 5, 6, 6, 1, \n",
    "    6, 5, 7, 2, 1, \n",
    "    5, 6, 5, 6, 1, \n",
    "    4, 4, 6, 4, 1, \n",
    "    6, 5, 5, 5, 1, \n",
    "    4, 4, 3, 1, \n",
    "    5, 5, 4, 1, \n",
    "    3, 3, 1, \n",
    "    3, 2, 1, \n",
    "    3, 2, 1, \n",
    "    3, 3, 1, \n",
    "    4, 2, 1, \n",
    "    4, 2, 1, \n",
    "    3, 3, 1, \n",
    "    4, 3, 1, \n",
    "    4, 3, 1, \n",
    "    4, 3, 1, \n",
    "    4, 3, 1, \n",
    "    3, 3, 1, \n",
    "    4, 2, 1, \n",
    "    3, 3, 1, \n",
    "    5, 4, 1, \n",
    "    4, 3, 1, \n",
    "    .\n",
    "    .\n",
    "    .\n",
    "    sentnum_per_batch\n",
    "    [11, 11, 5, 5, 5, 5, 4, 4, 3, 3, 3, 3, .....]\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    new2 = batch_numerical(new)\n",
    "    #batch * sent_num * sent_leng * wv -> new2\n",
    "\n",
    "    \n",
    "    sentbatch_len, for_sentmodel = make_batch2sent(new2)\n",
    "    #batch * sent_num * sent_leng * wv -> all_sent_num(new_batch) * sent_leng * wv\n",
    "    #for_sentmodel2 -> torch.Size([326, 7, 100])\n",
    "    #sentbatch_len -> 326\n",
    "    \n",
    "    hidden_state = torch.tensor(np.zeros((2, sentbatch_len, 100)), dtype=torch.float, device= device, requires_grad=False)\n",
    "    for_sentmodel2 = torch.tensor(np.transpose(for_sentmodel, [1, 0, 2]), dtype=torch.float, device= device, requires_grad=False)\n",
    "    \n",
    "    #for_sentmodel2 -> torch.Size([7, 326, 100])\n",
    "    \n",
    "    pre_crf_gru = sent(for_sentmodel2, hidden_state, all_seq_len) \n",
    "    '''\n",
    "    print(pre_crf_gru[0])\n",
    "    print(pre_crf_gru[1])\n",
    "    print(pre_crf_gru[2])\n",
    "    print(pre_crf_gru[3])\n",
    "    print(pre_crf_gru[4])\n",
    "    print(pre_crf_gru[5])\n",
    "    print(pre_crf_gru[6])\n",
    "    print(pre_crf_gru[7])\n",
    "    print(pre_crf_gru[8])\n",
    "    print(pre_crf_gru[9])\n",
    "    '''\n",
    "    #pre_crf_gru -> torch.Size([326, 100])\n",
    "    \n",
    "    #################################################sent network\n",
    "    #all_sent_num(new_batch) * sent_leng * wv -> all_sent_num(new_batch) * wv\n",
    "    \n",
    "    \n",
    "    \n",
    "    last_var = torch.split(pre_crf_gru, sentnum_per_batch)\n",
    "    #all_sent_num(new_batch) * wv -> batch * sent_num * wv\n",
    "    '''\n",
    "    last_var\n",
    "    \n",
    "    [11,100]\n",
    "    [11,100]\n",
    "    [5,100]\n",
    "    [5,100]\n",
    "    [5,100]\n",
    "    .\n",
    "    .\n",
    "    '''\n",
    "    new_dial, dial_leng = pad_dial(last_var) \n",
    "    #batch * sent_num * wv -> batch * (sent_num + pad) * wv\n",
    "    #save dial_leng for masking\n",
    "    \n",
    "    '''\n",
    "    new_dial\n",
    "    \n",
    "    [11,100]\n",
    "    [11,100]\n",
    "    [11,100]\n",
    "    [11,100]\n",
    "    [11,100]\n",
    "    .\n",
    "    .\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    \n",
    "    #new_dial = torch.transpose(new_dial, 0, 1)\n",
    "    \n",
    "    \n",
    "\n",
    "    return new_dial, new_tag, dial_leng, dn, dl, decodetag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def all_preprocess(sent, batch_data):\n",
    "\n",
    "    \n",
    "    #sorted with dialogue length\n",
    "    #print(batch_data[0].Text)\n",
    "    #######################################################\n",
    "    emotion_set = []\n",
    "    action_set = []\n",
    "    i = 0\n",
    "    while(i < len(batch_data)): #equals to BATCH_SIZE except last dataset\n",
    "        emotion_set.append(batch_data[i].labels_1)\n",
    "        \n",
    "        action_set.append(batch_data[i].labels_2)\n",
    "        \n",
    "        i = i + 1\n",
    "    \n",
    "    new_tag = pad_cat_tag(emotion_set, action_set) #in new preprocess, remake pad cat tag to split last sent\n",
    "    '''\n",
    "    new_tag representation 0 = start_tag, 29 = stop_tag, 30 = pad_tag\n",
    "    \n",
    "    tensor([  0,   2,   1,   2,   1,   2,   1,   2,   1,   2,   1,  29])\n",
    "    tensor([  0,   2,   1,   2,   1,   2,   1,   2,   1,   2,   1,  29])\n",
    "    tensor([  0,  21,   1,   1,   1,  29,  30,  30,  30,  30,  30,  30])\n",
    "    tensor([  0,   2,   1,   2,   1,  29,  30,  30,  30,  30,  30,  30])\n",
    "    tensor([  0,   1,   1,   1,   1,  29,  30,  30,  30,  30,  30,  30])\n",
    "    tensor([  0,   2,   1,   2,   1,  29,  30,  30,  30,  30,  30,  30])\n",
    "    tensor([  0,  17,  17,  17,  29,  30,  30,  30,  30,  30,  30,  30])\n",
    "    tensor([  0,   1,   1,   1,  29,  30,  30,  30,  30,  30,  30,  30])\n",
    "    tensor([  0,   3,   2,  29,  30,  30,  30,  30,  30,  30,  30,  30])\n",
    "    tensor([  0,  17,  17,  29,  30,  30,  30,  30,  30,  30,  30,  30])\n",
    "    tensor([  0,   2,   2,  29,  30,  30,  30,  30,  30,  30,  30,  30])\n",
    "    '''\n",
    "    #batch*tag\n",
    "    new_tag = Variable(new_tag.cuda())# default requires_grad = false\n",
    "    \n",
    "    #####################################################tag_preprocess\n",
    "    \n",
    "    \n",
    "    new, all_seq_len, sentnum_per_batch = pad_batch(batch_data) #in new preprocess, remake pad batch to split last sent\n",
    "    #batch * sentnum * (word_list+pad) -> new\n",
    "    #batch * sentnum * (word_list_length) -> all_seq_len\n",
    "    #batch * (sentnum) -> sentnum_per_batch\n",
    "    '''\n",
    "    new[0]\n",
    "    [array(['Is', 'this', 'your', 'new', 'teacher', '?', '<pad>'], dtype='<U32'), \n",
    "      array(['Yes', ',', 'it', 'is', '.', '<pad>', '<pad>'], dtype='<U32'), \n",
    "      array(['Is', 'she', 'short', '?', '<pad>', '<pad>', '<pad>'], dtype='<U32'), \n",
    "      array(['No', ',', 'she', '’', 's', 'average', '.'], dtype='<U32'), \n",
    "      array(['What', 'color', 'are', 'her', 'eyes', '?', '<pad>'], dtype='<U32'), \n",
    "      array(['They', '’', 're', 'dark', 'gray', '.', '<pad>'], dtype='<U32'), \n",
    "      array(['What', 'color', 'is', 'her', 'hair', '?', '<pad>'], dtype='<U32'),\n",
    "      array(['It', '’', 's', 'blond', '.', '<pad>', '<pad>'], dtype='<U32'), \n",
    "      array(['And', 'how', 'old', 'is', 'she', '?', '<pad>'], dtype='<U32'), \n",
    "      array(['I', 'don', '’', 't', 'know', '.', '<pad>'], dtype='<U32'), \n",
    "      array(['<stop_tag>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], dtype='<U32'), \n",
    "      \n",
    "    all_seq_len[0]\n",
    "    [6, 5, 4, 7, 6, 6, 6, 5, 6, 6, 1, \n",
    "    6, 5, 4, 7, 6, 6, 6, 5, 6, 6, 1, \n",
    "    6, 5, 7, 2, 1, \n",
    "    5, 6, 5, 6, 1, \n",
    "    4, 4, 6, 4, 1, \n",
    "    6, 5, 5, 5, 1, \n",
    "    4, 4, 3, 1, \n",
    "    5, 5, 4, 1, \n",
    "    3, 3, 1, \n",
    "    3, 2, 1, \n",
    "    3, 2, 1, \n",
    "    3, 3, 1, \n",
    "    4, 2, 1, \n",
    "    4, 2, 1, \n",
    "    3, 3, 1, \n",
    "    4, 3, 1, \n",
    "    4, 3, 1, \n",
    "    4, 3, 1, \n",
    "    4, 3, 1, \n",
    "    3, 3, 1, \n",
    "    4, 2, 1, \n",
    "    3, 3, 1, \n",
    "    5, 4, 1, \n",
    "    4, 3, 1, \n",
    "    .\n",
    "    .\n",
    "    .\n",
    "    sentnum_per_batch #contain stop tag\n",
    "    [11, 11, 5, 5, 5, 5, 4, 4, 3, 3, 3, 3, .....]\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    new2 = batch_numerical(new)\n",
    "    #batch * sent_num * sent_leng * wv -> new2\n",
    "\n",
    "    \n",
    "    sentbatch_len, for_sentmodel = make_batch2sent(new2)\n",
    "    #batch * sent_num * sent_leng * wv -> all_sent_num(new_batch) * sent_leng * wv\n",
    "    #for_sentmodel2 -> torch.Size([326, 7, 100])\n",
    "    #sentbatch_len -> 326\n",
    "    \n",
    "    hidden_state = torch.tensor(np.zeros((2, sentbatch_len, 100)), dtype=torch.float, device= device, requires_grad=False)\n",
    "    for_sentmodel2 = torch.tensor(np.transpose(for_sentmodel, [1, 0, 2]), dtype=torch.float, device= device, requires_grad=False)\n",
    "    \n",
    "    #for_sentmodel2 -> torch.Size([7, 326, 100])\n",
    "    \n",
    "    pre_crf_gru = sent(for_sentmodel2, hidden_state, all_seq_len) \n",
    "    '''\n",
    "    print(pre_crf_gru[0])\n",
    "    print(pre_crf_gru[1])\n",
    "    print(pre_crf_gru[2])\n",
    "    print(pre_crf_gru[3])\n",
    "    print(pre_crf_gru[4])\n",
    "    print(pre_crf_gru[5])\n",
    "    print(pre_crf_gru[6])\n",
    "    print(pre_crf_gru[7])\n",
    "    print(pre_crf_gru[8])\n",
    "    print(pre_crf_gru[9])\n",
    "    '''\n",
    "    #pre_crf_gru -> torch.Size([326, 100])\n",
    "    \n",
    "    #################################################sent network\n",
    "    #all_sent_num(new_batch) * sent_leng * wv -> all_sent_num(new_batch) * wv\n",
    "    \n",
    "    \n",
    "    \n",
    "    last_var = torch.split(pre_crf_gru, sentnum_per_batch)\n",
    "    #all_sent_num(new_batch) * wv -> batch * sent_num * wv\n",
    "    '''\n",
    "    last_var\n",
    "    \n",
    "    [11,100]\n",
    "    [11,100]\n",
    "    [5,100]\n",
    "    [5,100]\n",
    "    [5,100]\n",
    "    .\n",
    "    .\n",
    "    '''\n",
    "    new_dial, dial_leng = pad_dial(last_var) \n",
    "    #batch * sent_num * wv -> batch * (sent_num + pad) * wv\n",
    "    #save dial_leng for masking\n",
    "    \n",
    "    '''\n",
    "    new_dial\n",
    "    \n",
    "    [11,100]\n",
    "    [11,100]\n",
    "    [11,100]\n",
    "    [11,100]\n",
    "    [11,100]\n",
    "    .\n",
    "    .\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    \n",
    "    new_dial = torch.transpose(new_dial, 0, 1)\n",
    "    \n",
    "    \n",
    "\n",
    "    return new_dial, new_tag, dial_leng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss_filtering(loss_arr, filtering_value, newary, batchnum):\n",
    "    \"\"\"\n",
    "    function for prevent overfitting\n",
    "    \n",
    "    Args:\n",
    "        loss_arr:\n",
    "            loss array for batch data\n",
    "        \n",
    "        filtering_value:\n",
    "            allowed maximum loss\n",
    "        \n",
    "        newary:\n",
    "            index for big loss data\n",
    "            \n",
    "        batchnum:\n",
    "            current batch count\n",
    "        \n",
    "        \n",
    "    Yields:\n",
    "        loss_arr:\n",
    "            filtered loss array for batch data\n",
    "    \n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    err_count = 0\n",
    "    while i < len(loss_arr):\n",
    "        if loss_arr[i] < filtering_value:\n",
    "            loss_arr[i] = 0\n",
    "        elif loss_arr[i] > (filtering_value*4):\n",
    "            err_count = err_count + 1\n",
    "            newary.append(i + batchnum*100)\n",
    "        i = i + 1\n",
    "    print (\"###############################################errcount\",err_count)\n",
    "    return loss_arr, newary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_func(train_data, shared_model , comp_model, dataseq, filtering_value, iter_num, batch_size, learning_rate):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "            train_data: \n",
    "                train data\n",
    "                \n",
    "            shared_model:\n",
    "                shared model\n",
    "                \n",
    "            comp_model:\n",
    "                comp model\n",
    "                \n",
    "            dataseq:\n",
    "                data sort sequence\n",
    "                \n",
    "            filtering_value:\n",
    "                allowed maximum loss\n",
    "                \n",
    "            iter_num:\n",
    "                train iterate\n",
    "                \n",
    "            batch_size:\n",
    "                batchsize\n",
    "            \n",
    "            learning_rate:\n",
    "                learning_rate\n",
    "\n",
    "    Yields:\n",
    "            newary:\n",
    "                not trained data\n",
    "                which has loss bigger then filtering value\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    optimizer1 = optim.SGD(shared_model.parameters(), lr= learning_rate, weight_decay=1e-4)\n",
    "    optimizer2 = optim.SGD(comp_model.parameters(), lr= learning_rate, weight_decay=1e-4)\n",
    "    \n",
    "    newary_ = []\n",
    "    k = 0\n",
    "    for batch_data in batchload(train_data, repeat=True, batchsize = batch_size, data_seq = dataseq ):\n",
    "        #load txt data from jsonfile\n",
    "\n",
    "        shared_model.zero_grad()\n",
    "        comp_model.zero_grad()\n",
    "\n",
    "        new_dial, new_tag, dial_leng = all_preprocess(shared_model, batch_data)\n",
    "        #load batch*(dialogue_length*sent_vec(float)) -> new_dial\n",
    "        #load batch*tag -> new_tag\n",
    "        #load batch * dial_leng\n",
    "\n",
    "        loss = comp_model.neg_log_likelihood(make_mask(dial_leng), new_dial, new_tag, BATCH_SIZE)\n",
    "        loss,newary_ = loss_filtering(loss,filtering_value, newary_,k)\n",
    "        batch_loss = torch.sum(loss)\n",
    "        batch_loss.backward(retain_graph=False)\n",
    "        optimizer1.step()\n",
    "        optimizer2.step()\n",
    "\n",
    "        unuselist = [new_dial, new_tag, dial_leng]\n",
    "        del unuselist\n",
    "        \n",
    "        k = k + 1\n",
    "        print(k)\n",
    "        if k%10 != 0:\n",
    "            torch.save(shared_model.state_dict(),working_path + 'parameter/shared.pth')\n",
    "            torch.save(comp_model.state_dict(),working_path + 'parameter/crf_gru.pth') #3.53 save with dummy\n",
    "            dummy_input = [make_mask(dial_leng),new_dial]\n",
    "            \n",
    "            print(\"tag = \",new_tag[7])\n",
    "            print(\"expect = \",comp_model(BATCH_SIZE,dummy_input,seq=7)[1])\n",
    "            print(\"accuracy = \", cal_accuracy(comp_model(BATCH_SIZE,dummy_input,seq=7)[1],new_tag[7]))\n",
    "            \n",
    "            print(loss)\n",
    "        if k == int(len(train_data)/BATCH_SIZE)*iter_num:\n",
    "            break\n",
    "            \n",
    "        if k % int(len(train_data)/BATCH_SIZE) == 0:\n",
    "            newary = newary_\n",
    "            newary_ = []\n",
    "    print(newary)\n",
    "    \n",
    "    return newary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cal_accuracy(model_predict, real_tag):\n",
    "    '''\n",
    "    Args:\n",
    "        model_predict\n",
    "            model predicted tags\n",
    "        real_tag\n",
    "            real tags\n",
    "        tag_len\n",
    "            tag len\n",
    "        \n",
    "    Yields:\n",
    "        accuracy\n",
    "        \n",
    "    Example:\n",
    "        \n",
    "    real = torch.tensor([  0,   2,   1,   2,   1,   1,   1,   1,   1,   2,   1,   1, 1,   1,  29], device='cuda:0')\n",
    "    model = [2, 1, 2, 1, 17, 1, 17, 1, 3, 1, 17, 1, 17, 29]\n",
    "    taglen = len(model)\n",
    "    \n",
    "    (npreal[tagseq+1]//4) real emotion\n",
    "    (model_predict[tagseq]//4) model emotion\n",
    "    \n",
    "    (npreal[tagseq+1]%4) real action\n",
    "    (model_predict[tagseq]%4) model action\n",
    "    \n",
    "    emotion err = 0.3076923076923077\n",
    "    action err = 0.07692307692307693\n",
    "    accuracy = 0.8076923076923077\n",
    "    '''\n",
    "    tag_len = len(model_predict)\n",
    "    npreal = real_tag.cpu().numpy()\n",
    "    tagseq = 0\n",
    "    emotiontag = []\n",
    "    actiontag = []\n",
    "    emoerr = 0\n",
    "    acterr = 0\n",
    "    while(tagseq < tag_len-1):\n",
    "      \n",
    "        emotiontag = np.append(emotiontag, npreal[tagseq+1]//4)\n",
    "        actiontag = np.append(actiontag, npreal[tagseq+1]%4)\n",
    "        \n",
    "        \n",
    "        if((npreal[tagseq+1]//4) != (model_predict[tagseq]//4)):\n",
    "            emoerr = emoerr + 1\n",
    "\n",
    "        \n",
    "        if((npreal[tagseq+1]%4) != (model_predict[tagseq]%4)):\n",
    "            acterr = acterr + 1\n",
    "\n",
    "        tagseq = tagseq + 1\n",
    "\n",
    "    return(1-(emoerr/tagseq + acterr/tagseq)/2)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_func(test_data, shared_model , comp_model, dataseq, batch_size):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "            test_data: \n",
    "                test data\n",
    "                \n",
    "            shared_model:\n",
    "                shared model\n",
    "                \n",
    "            comp_model:\n",
    "                comp model\n",
    "                \n",
    "            dataseq:\n",
    "                data sort sequence\n",
    "                \n",
    "            batch_size:\n",
    "                batchsize\n",
    "            \n",
    "\n",
    "\n",
    "    Yields:\n",
    "            accuracy:\n",
    "                accuracy of all data\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    k = 0\n",
    "    accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_data in batchload(test_data, repeat=True, batchsize = batch_size, data_seq = dataseq ):\n",
    "            #load txt data from jsonfile\n",
    "\n",
    "\n",
    "            new_dial, new_tag, dial_leng = all_preprocess(shared_model, batch_data)\n",
    "            #load batch*(dialogue_length*sent_vec(float)) -> new_dial\n",
    "            #load batch*tag -> new_tag\n",
    "            #load batch * dial_leng\n",
    "\n",
    "            unuselist = [new_dial, new_tag, dial_leng]\n",
    "            del unuselist\n",
    "            dummy_input = [make_mask(dial_leng),new_dial]\n",
    "\n",
    "            print(\"tag = \",new_tag[7])\n",
    "            print(\"expect = \",comp_model(batch_size,dummy_input,seq=7)[1])\n",
    "            print(\"accuracy = \", cal_accuracy(comp_model(batch_size,dummy_input,seq=7)[1],new_tag[7]))\n",
    "\n",
    "            tag_num = 0\n",
    "            batch_acc = 0\n",
    "            while(tag_num < batch_size):\n",
    "                batch_acc = batch_acc + cal_accuracy(comp_model(batch_size,dummy_input,seq=tag_num)[1],new_tag[tag_num])\n",
    "                tag_num = tag_num + 1\n",
    "            batch_acc = batch_acc/batch_size\n",
    "            accuracy = accuracy + batch_acc\n",
    "            print(\"batchacc = \",batch_acc)\n",
    "            if k == int(len(test_data)/batch_size):\n",
    "                break\n",
    "\n",
    "            k = k + 1\n",
    "            print(k)\n",
    "\n",
    "    \n",
    "    return accuracy*batch_size/len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def encoder_mask(leng):\n",
    "    '''\n",
    "    make one-hot vector of mask from lengset\n",
    "    '''\n",
    "\n",
    "    var = np.zeros(shape = (len(leng), leng[0])) #len(leng) = BATCH_SIZE, leng[0]+1= largest dialogue + stop\n",
    "    i = 0\n",
    "    while(i < len(leng)):#BATCH_SIZE\n",
    "        j = 0\n",
    "        while(j < leng[0]): \n",
    "            if(j == leng[i]-1): # <= stop tag\n",
    "                var[i][j] = 1\n",
    "            \n",
    "            j = j + 1\n",
    "        \n",
    "        i = i + 1\n",
    "\n",
    "    return var\n",
    "\n",
    "def decoder_mask(leng, maxsize):\n",
    "    '''\n",
    "    make one-hot vector of mask from lengset\n",
    "    '''\n",
    "\n",
    "    var = np.zeros(shape = (len(leng), maxsize)) #len(leng) = BATCH_SIZE, leng[0]+1= largest dialogue + stop\n",
    "    i = 0\n",
    "    while(i < len(leng)):#BATCH_SIZE\n",
    "        j = 0\n",
    "        while(j < maxsize): \n",
    "            if(j < leng[i]): # <= stop tag\n",
    "                var[i][j] = 1\n",
    "            \n",
    "            j = j + 1\n",
    "        \n",
    "        i = i + 1\n",
    "\n",
    "    return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hidden_state_size = 100\n",
    "batch_size = 100\n",
    "\n",
    "class encoder(nn.Module):\n",
    "    def __init__(self, hidden_state_size, is_tag_, tag_size, bidir):\n",
    "        super(encoder, self).__init__()\n",
    "        self.h_size = hidden_state_size\n",
    "        self.is_tag = is_tag_\n",
    "        self.t_size = tag_size\n",
    "        self.bid = bidir\n",
    "        self.gru = nn.GRU(self.h_size, self.h_size, bidirectional = self.bid)\n",
    "        self.embed_tag = nn.Embedding(self.t_size, self.h_size)\n",
    "        self.combinput = nn.Linear(2*self.h_size, self.h_size)\n",
    "        self.comblast_t = nn.Linear(3*self.h_size, 2*self.h_size)\n",
    "        \n",
    "    def forward(self, input_, input_tag, de_len, last_tag):\n",
    "        hidden = self.init_hidden()\n",
    "        de_len = Variable(torch.tensor(de_len).cuda())\n",
    "        last_tag = Variable(torch.tensor(last_tag).cuda())\n",
    "        if self.is_tag == False:\n",
    "            output, hidden_state = self.gru(Variable(input_.cuda()), hidden)\n",
    "        else:\n",
    "            emb_tag = self.embed_tag(Variable(input_tag.cuda()))\n",
    "            newinput = torch.cat((emb_tag, input_),2)\n",
    "            input_ = self.combinput(newinput)\n",
    "            input_ = torch.transpose(input_, 0, 1)\n",
    "            \n",
    "            output, hidden_state = self.gru(input_, hidden) #outputsize [19, 100, 200] hiddensize [2, 100, 100]\n",
    "            len_info = torch.tensor(de_len)\n",
    "            len_info = torch.unsqueeze(len_info,2).type(torch.cuda.FloatTensor)\n",
    "            output = torch.transpose(output, 0, 1)\n",
    "            new_output = torch.mul(output,len_info)\n",
    "            new_output = torch.sum(new_output,1) #100,200\n",
    "  \n",
    "            new_last_tag = self.embed_tag(last_tag) #100,100\n",
    " \n",
    "            cat = torch.cat((new_output, new_last_tag),1) #300,100\n",
    "\n",
    "            lastoutput = self.comblast_t(cat)\n",
    "            lastoutput = torch.reshape(lastoutput, (100, 2, 100))\n",
    "            lastoutput = torch.transpose(lastoutput, 0, 1).contiguous()\n",
    "            \n",
    "            #not hidden state. output post processing need\n",
    "        return lastoutput\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return Variable(torch.zeros(2,100,100,device= device))\n",
    "    \n",
    "    \n",
    "    \n",
    "class decoder(nn.Module): #target padding sos\n",
    "    def __init__(self, hidden_state_size, bidir):\n",
    "        super(decoder, self).__init__()\n",
    "        self.bid = bidir\n",
    "        self.h_size = hidden_state_size\n",
    "        self.comboutput = nn.Linear(2*self.h_size, self.h_size)\n",
    "        self.gru = nn.GRU(self.h_size, self.h_size, bidirectional = self.bid)\n",
    "        \n",
    "    def forward(self, new_input, pre_hidden_state):\n",
    "        input_ = new_input #1,100,100\n",
    "        hidden_state = pre_hidden_state #2,100,100\n",
    "        output, hidden_state = self.gru(input_, hidden_state)\n",
    "        output = self.comboutput(output)\n",
    "        return output, hidden_state\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return Variable(torch.zeros(2,100,100,device= device))\n",
    "\n",
    "    \n",
    "    \n",
    "encoder1 = encoder(hidden_state_size,\n",
    "                   is_tag_ = False,\n",
    "                   tag_size = 31, #???\n",
    "                   bidir = True\n",
    "                  ).cuda()\n",
    "\n",
    "encoder2 = encoder(hidden_state_size,\n",
    "                   is_tag_ = True,\n",
    "                   tag_size = 31, \n",
    "                   bidir = True\n",
    "                  ).cuda()\n",
    "\n",
    "decoder1 = decoder(hidden_state_size,\n",
    "                   bidir = True\n",
    "                  ).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dialogue_maxlen(data):\n",
    "    '''\n",
    "    used in lamda function\n",
    "    \n",
    "    return longest sentence len per dialogue\n",
    "    '''\n",
    "    i = 0\n",
    "    maxleng = 0\n",
    "    while(i < len(data.Text)): # len(data.Text) = dialogue length\n",
    "        \n",
    "        text, leng = sent_loader(data.Text[i])\n",
    "        if leng > maxleng:\n",
    "            maxleng = leng\n",
    "        i = i + 1\n",
    "    return maxleng\n",
    "\n",
    "def dialogue_maxlen_per_batch(batch_len, batchdata):\n",
    "    i = 0\n",
    "    maxlen = 1\n",
    "    while(i < batch_len):\n",
    "\n",
    "        if dialogue_maxlen(batch_data[i]) > maxlen:\n",
    "            maxlen = dialogue_maxlen(batch_data[i])\n",
    "        i = i + 1\n",
    "    return maxlen\n",
    "\n",
    "my_fields={'dial': ('Text', data.Field(sequential=True)),\n",
    "        'emo': ('labels_1', data.Field(sequential=False)),\n",
    "        'act': ('labels_2', data.Field(sequential=False))}\n",
    "\n",
    "train = my_TabularDataset.splits(path = working_path, train = 'data_jsonfile/full_data.json',\n",
    "                          fields=my_fields) \n",
    "train = sorted(train, key = lambda  x: dialogue_maxlen(x))\n",
    "train = train[:-1118] #exclude dialogue which has extremely long sentence (0~11117 => 0~9999)\n",
    "train = sorted(train, key = lambda  x: -len(x.Text)) #reordering training dataset with number of sentences\n",
    "# low index has much sentence because afterwards we use torch pad_sequence\n",
    "dataseq = torch.arange(end = len(train),dtype=torch.int)\n",
    "\n",
    "\n",
    "train_data = train\n",
    "#shared_model = sent_to_vextor_bigru_net\n",
    "#comp_model = my_grucrf_model\n",
    "dataseq = dataseq\n",
    "filtering_value = 3\n",
    "iter_num = 1\n",
    "batch_size = 100\n",
    "learning_rate = 0.00003\n",
    "\n",
    "sent_to_vector_bigru_net = makesent_gru(100, True).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makewv(target):\n",
    "        targetwv = []\n",
    "        batchnum = 0\n",
    "        while(batchnum < batch_size):\n",
    "            wv = numerize_sent(target[batchnum],len(target[batchnum]))\n",
    "            targetwv.append(wv)\n",
    "            \n",
    "            batchnum = batchnum + 1\n",
    "        return targetwv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batchnum =  100\n",
      "1\n",
      "batchnum =  200\n",
      "2\n",
      "torch.Size([44, 100, 100])\n",
      "torch.Size([44, 100, 100])\n"
     ]
    }
   ],
   "source": [
    "k = 1\n",
    "for batch_data in batchload(train_data, repeat=True, batchsize = batch_size, data_seq = dataseq ):\n",
    "    #load txt data from jsonfile\n",
    "    print(k)\n",
    "\n",
    "    '''\n",
    "    batch_data[0].labels_1\n",
    "    ['0 0 0 0 0 0 0 0 0 0 0 0 4 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 4']\n",
    "    ['1 2 3 4 1 2 2 2 2 2 1 1 1 2 1 3 4 2 1 2 1 2 1 2 1 1 1 2 2 2 1 3 4 1 1']\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    k = k + 1\n",
    "    if k == 3:\n",
    "        sent_to_vector_bigru_net.zero_grad()\n",
    "    \n",
    "    \n",
    "        new_dial, new_tag, dial_leng, de_sent, de_len, de_tag = new_preprocess(sent_to_vector_bigru_net, \n",
    "                                                                                    batch_data) #mask??\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        encoder_mask(dial_leng)\n",
    "        [[0. 0. 0. ... 0. 0. 1.]\n",
    "         [0. 0. 0. ... 0. 0. 1.]\n",
    "         [0. 0. 0. ... 0. 0. 1.]\n",
    "         ...\n",
    "         [0. 0. 0. ... 1. 0. 0.]\n",
    "         [0. 0. 0. ... 1. 0. 0.]\n",
    "         [0. 0. 0. ... 1. 0. 0.]]\n",
    "        torch.sum(torch.tensor(encoder_mask(dial_leng)),1) \n",
    "        1111111111...\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        \n",
    "        decoder_hidden = encoder2(new_dial, new_tag, encoder_mask(dial_leng), de_tag) #2,100,100\n",
    "        \n",
    "        decoder_sent = 0\n",
    "        all_output = Variable(torch.zeros(1,100,100,device= device))\n",
    "        out = Variable(torch.zeros(1,100,100,device= device))\n",
    "        seq = 0\n",
    "        while(decoder_sent < dialogue_maxlen_per_batch(batch_size, batch_data)): #all_output = seq*batch*hidden\n",
    "            out, decoder_hidden = decoder1(out, decoder_hidden)\n",
    "            decoder_sent = decoder_sent + 1\n",
    "            if seq != 0:\n",
    "                all_output = torch.cat((all_output,out),0)\n",
    "            else:\n",
    "                all_output = out\n",
    "            seq = seq + 1\n",
    "        de_mask = decoder_mask(de_len,dialogue_maxlen_per_batch(batch_size, batch_data)) #100,44\n",
    "        demask = torch.tensor(de_mask)\n",
    "        demask = torch.unsqueeze(demask,2).type(torch.cuda.FloatTensor)\n",
    "        demask = torch.transpose(demask, 0, 1)\n",
    "        \n",
    "        all_output = torch.mul(demask,all_output)\n",
    "        \n",
    "        targetwv = makewv(de_sent)\n",
    "        targetwv = torch.transpose(torch.tensor(targetwv), 0, 1).type(torch.cuda.FloatTensor)\n",
    "        \n",
    "        loss = nn.MSELoss()\n",
    "        \n",
    "        mseloss = loss(all_output, targetwv)\n",
    "        mseloss.backward()\n",
    "        print(np.shape(targetwv))\n",
    "        print(all_output.size())\n",
    "        \n",
    "        \n",
    "        #newout, newhidden = decoder(out) #newout, newdial loss\n",
    "        \n",
    "        break\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    shared_model.zero_grad()\n",
    "    comp_model.zero_grad()\n",
    "\n",
    "    new_dial, new_tag, dial_leng = all_preprocess(shared_model, batch_data) #we need split batch_data\n",
    "    #load batch* (dialogue_length*sent_vec(float)) -> new_dial\n",
    "    #load batch* tag -> new_tag\n",
    "    #load batch* dial_leng\n",
    "\n",
    "    loss = comp_model.neg_log_likelihood(make_mask(dial_leng), new_dial, new_tag, BATCH_SIZE)\n",
    "    loss,newary_ = loss_filtering(loss,filtering_value, newary_,k)\n",
    "    batch_loss = torch.sum(loss)\n",
    "    batch_loss.backward(retain_graph=False)\n",
    "    optimizer1.step()\n",
    "    optimizer2.step()\n",
    "\n",
    "    unuselist = [new_dial, new_tag, dial_leng]\n",
    "    del unuselist\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.3534, -0.0571, -0.6270,  1.0470],\n",
      "         [ 1.8247,  0.1644,  1.4346, -0.6674],\n",
      "         [-0.4834,  0.6080, -0.2463, -1.0291]],\n",
      "\n",
      "        [[ 1.6242, -0.0439, -1.2608,  0.0611],\n",
      "         [-0.9631,  0.3465, -1.0810, -0.5787],\n",
      "         [ 0.2873, -0.7777,  0.0336, -0.4647]]])\n",
      "tensor([[-1.1274,  0.7311, -0.1448],\n",
      "        [-1.1653, -0.0840, -1.0307]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (4) must match the size of tensor b (3) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-b67f045538d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (4) must match the size of tensor b (3) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 3, 4)\n",
    "y = torch.randn(2, 3)\n",
    "print(x)\n",
    "print(y)\n",
    "torch.mul(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.shape(torch.cat((x, x, x), 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.shape(torch.cat((x, x, x), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.shape(torch.cat((x, x, x), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = torch.randn(4, 3)\n",
    "torch.sum(a,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3-4.2.0]",
   "language": "python",
   "name": "conda-env-anaconda3-4.2.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
