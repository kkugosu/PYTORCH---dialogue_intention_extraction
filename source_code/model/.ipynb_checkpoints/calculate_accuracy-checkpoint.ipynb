{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import io,os,sys,types\n",
    "from IPython import get_ipython #for import notebook\n",
    "from nbformat import read #for import notebook\n",
    "from IPython.core.interactiveshell import InteractiveShell #for import notebook\n",
    "def find_notebook(fullname, path=None): #for import notebook\n",
    "    \"\"\"find a notebook, given its fully qualified name and an optional path\n",
    "\n",
    "    This turns \"foo.bar\" into \"foo/bar.ipynb\"\n",
    "    and tries turning \"Foo_Bar\" into \"Foo Bar\" if Foo_Bar\n",
    "    does not exist.\n",
    "    \"\"\"\n",
    "    name = fullname.rsplit('.', 1)[-1]\n",
    "    if not path:\n",
    "        path = ['']\n",
    "    for d in path:\n",
    "        nb_path = os.path.join(d, name + \".ipynb\")\n",
    "        if os.path.isfile(nb_path):\n",
    "            return nb_path\n",
    "        # let import Notebook_Name find \"Notebook Name.ipynb\"\n",
    "        nb_path = nb_path.replace(\"_\", \" \")\n",
    "        if os.path.isfile(nb_path):\n",
    "            return nb_path\n",
    "class NotebookLoader(object): #for import notebook\n",
    "    \"\"\"Module Loader for Jupyter Notebooks\"\"\"\n",
    "    def __init__(self, path=None):\n",
    "        self.shell = InteractiveShell.instance()\n",
    "        self.path = path\n",
    "\n",
    "    def load_module(self, fullname):\n",
    "        \"\"\"import a notebook as a module\"\"\"\n",
    "        path = find_notebook(fullname, self.path)\n",
    "\n",
    "        print (\"importing Jupyter notebook from %s\" % path)\n",
    "\n",
    "        # load the notebook object\n",
    "        with io.open(path, 'r', encoding='utf-8') as f:\n",
    "            nb = read(f, 4)\n",
    "\n",
    "\n",
    "        # create the module and add it to sys.modules\n",
    "        # if name in sys.modules:\n",
    "        #    return sys.modules[name]\n",
    "        mod = types.ModuleType(fullname)\n",
    "        mod.__file__ = path\n",
    "        mod.__loader__ = self\n",
    "        mod.__dict__['get_ipython'] = get_ipython\n",
    "        sys.modules[fullname] = mod\n",
    "\n",
    "        # extra work to ensure that magics that would affect the user_ns\n",
    "        # actually affect the notebook module's ns\n",
    "        save_user_ns = self.shell.user_ns\n",
    "        self.shell.user_ns = mod.__dict__\n",
    "\n",
    "        try:\n",
    "          for cell in nb.cells:\n",
    "            if cell.cell_type == 'code':\n",
    "                # transform the input to executable Python\n",
    "                code = self.shell.input_transformer_manager.transform_cell(cell.source)\n",
    "                # run the code in themodule\n",
    "                exec(code, mod.__dict__)\n",
    "        finally:\n",
    "            self.shell.user_ns = save_user_ns\n",
    "        return mod\n",
    "class NotebookFinder(object):\n",
    "    \"\"\"Module finder that locates Jupyter Notebooks\"\"\"\n",
    "    def __init__(self):\n",
    "        self.loaders = {}\n",
    "\n",
    "    def find_module(self, fullname, path=None):\n",
    "        nb_path = find_notebook(fullname, path)\n",
    "        if not nb_path:\n",
    "            return\n",
    "\n",
    "        key = path\n",
    "        if path:\n",
    "            # lists aren't hashable\n",
    "            key = os.path.sep.join(path)\n",
    "\n",
    "        if key not in self.loaders:\n",
    "            self.loaders[key] = NotebookLoader(path)\n",
    "        return self.loaders[key]\n",
    "sys.meta_path.append(NotebookFinder())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from crf_gru_model.ipynb\n"
     ]
    }
   ],
   "source": [
    "#import chr_word_to_vec\n",
    "import crf_gru_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "import torch.utils.data\n",
    "from torch.utils.data import DataLoader\n",
    "import io,os\n",
    "from torch import nn\n",
    "from gensim.models import word2vec\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from torchtext import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cal_dialogue(data):\n",
    "    '''\n",
    "    used in lamda function\n",
    "    \n",
    "    return longest sentence len per dialogue\n",
    "    '''\n",
    "    i = 0\n",
    "    maxleng = 0\n",
    "    while(i < len(data.Text)): # len(data.Text) = dialogue length\n",
    "        if len(data.Text[i]) > maxleng:\n",
    "            maxleng = len(data.Text[i])\n",
    "        i = i + 1\n",
    "    return maxleng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "my_fields={'dial': ('Text', data.Field(sequential=True)),\n",
    "        'emo': ('labels_1', data.Field(sequential=False)),\n",
    "        'act': ('labels_2', data.Field(sequential=False))}\n",
    "BATCH_SIZE = 100\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "tag_to_ix = {'start_tag':0,'stop_tag':29,'pad_tag':30}\n",
    "\n",
    "working_path = '/home/jongsu/jupyter/pytorch_dialogue_ie/'\n",
    "WV_PATH = '/home/jongsu/jupyter/pytorch_dialogue_ie/parameter/dialogue_wv'\n",
    "test = crf_gru_model.my_TabularDataset.splits(path = working_path, train = 'data_jsonfile/full_data_test.json',\n",
    "                          fields=my_fields) \n",
    "test = sorted(test, key = lambda  x: cal_dialogue(x))\n",
    "test = sorted(test, key = lambda  x: -len(x.Text)) #reordering training dataset with number of sentences\n",
    "# low index has much sentence because afterwards we use torch pad_sequence\n",
    "print(len(test))\n",
    "dataseq = torch.arange(end = len(test),dtype=torch.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent_to_vextor_bigru_net = crf_gru_model.makesent_gru(100, True).cuda()\n",
    "#we need convert batch*dialogue -> batch*(dialogue_length*sent_vec(float))\n",
    "\n",
    "my_grucrf_model = crf_gru_model.BiGru_CRF(tag_to_ix,BATCH_SIZE).cuda()\n",
    "#this convert batch*(dialogue_length*sent_vec(float)) -> batch*(dialogue_tag,score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_models(path1,path2):\n",
    "    sent_to_vextor_bigru_net.load_state_dict(torch.load(path1))\n",
    "    my_grucrf_model.load_state_dict(torch.load(path2))\n",
    "    return\n",
    "\n",
    "load_models(working_path + '/parameter/shared.pth',working_path+'/parameter/crf_gru.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batchnum =  50\n",
      "tag =  tensor([  0,   2,   1,   2,   3,   3,   4,   2,   1,   3,   4,   3,\n",
      "          2,   1,   4,   3,   4,   3,  16,   3,  29,  30,  30,  30,\n",
      "         30,  30,  30,  30], device='cuda:0')\n",
      "expect =  [2, 1, 2, 2, 2, 4, 2, 1, 17, 1, 17, 2, 1, 17, 3, 17, 3, 1, 20, 29]\n",
      "accuracy =  0.5789473684210527\n",
      "batchacc =  0.7242564022235075\n",
      "1\n",
      "batchnum =  100\n",
      "tag =  tensor([  0,   3,   4,   3,   3,   4,   2,   1,   2,   1,   2,   1,\n",
      "          2,   1,   1,  29,  30], device='cuda:0')\n",
      "expect =  [3, 2, 17, 2, 4, 2, 1, 2, 1, 2, 1, 1, 17, 1, 29]\n",
      "accuracy =  0.75\n",
      "batchacc =  0.7230586080586082\n",
      "2\n",
      "batchnum =  150\n",
      "tag =  tensor([  0,   2,   1,  26,   1,   2,   1,   1,   1,   2,   1,   2,\n",
      "          1,  29,  30], device='cuda:0')\n",
      "expect =  [2, 1, 2, 1, 2, 1, 1, 1, 2, 1, 2, 1, 29]\n",
      "accuracy =  0.9583333333333334\n",
      "batchacc =  0.7445512820512821\n",
      "3\n",
      "batchnum =  200\n",
      "tag =  tensor([  0,   2,   3,   3,   2,   1,   3,   3,   4,   3,   4,  17,\n",
      "         17,  29], device='cuda:0')\n",
      "expect =  [2, 2, 2, 2, 1, 3, 19, 1, 19, 1, 17, 4, 29]\n",
      "accuracy =  0.5833333333333333\n",
      "batchacc =  0.7038636363636362\n",
      "4\n",
      "batchnum =  250\n",
      "tag =  tensor([  0,   3,   2,   2,   1,   2,   1,   1,  10,   1,   3,   4,\n",
      "         29], device='cuda:0')\n",
      "expect =  [3, 2, 2, 1, 17, 1, 17, 2, 17, 3, 17, 29]\n",
      "accuracy =  0.6818181818181819\n",
      "batchacc =  0.6829090909090907\n",
      "5\n",
      "batchnum =  300\n",
      "tag =  tensor([  0,   3,   1,   1,   2,  23,  25,   1,   2,   1,   1,  29], device='cuda:0')\n",
      "expect =  [3, 4, 3, 2, 1, 17, 1, 2, 17, 3, 29]\n",
      "accuracy =  0.6\n",
      "batchacc =  0.6899999999999997\n",
      "6\n",
      "batchnum =  350\n",
      "tag =  tensor([  0,   3,   2,   1,   2,   1,   2,   1,   3,   4,   3,  29], device='cuda:0')\n",
      "expect =  [3, 2, 1, 2, 1, 2, 1, 19, 1, 20, 29]\n",
      "accuracy =  0.75\n",
      "batchacc =  0.7225555555555556\n",
      "7\n",
      "batchnum =  400\n",
      "tag =  tensor([  0,   2,   2,   1,   3,   4,   3,  24,   3,  24,  29], device='cuda:0')\n",
      "expect =  [2, 2, 1, 3, 4, 2, 4, 2, 20, 29]\n",
      "accuracy =  0.7777777777777778\n",
      "batchacc =  0.67\n",
      "8\n",
      "batchnum =  450\n",
      "tag =  tensor([  0,   2,   2,   1,  25,   1,  25,   1,   1,  29], device='cuda:0')\n",
      "expect =  [2, 2, 17, 1, 17, 1, 17, 1, 29]\n",
      "accuracy =  0.6875\n",
      "batchacc =  0.71875\n",
      "9\n",
      "batchnum =  500\n",
      "tag =  tensor([  0,   2,   2,   3,   4,   2,   1,   3,  20,  29], device='cuda:0')\n",
      "expect =  [2, 2, 2, 4, 2, 1, 17, 4, 29]\n",
      "accuracy =  0.75\n",
      "batchacc =  0.7376785714285715\n",
      "10\n",
      "batchnum =  550\n",
      "tag =  tensor([  0,   6,   5,   7,   2,   1,   3,  20,  29], device='cuda:0')\n",
      "expect =  [2, 20, 1, 18, 1, 3, 4, 29]\n",
      "accuracy =  0.5\n",
      "batchacc =  0.683809523809524\n",
      "11\n",
      "batchnum =  600\n",
      "tag =  tensor([  0,   2,   1,   2,   1,   2,   1,  29], device='cuda:0')\n",
      "expect =  [2, 1, 2, 1, 17, 1, 29]\n",
      "accuracy =  0.8333333333333334\n",
      "batchacc =  0.6749999999999998\n",
      "12\n",
      "batchnum =  650\n",
      "tag =  tensor([  0,   3,   3,   2,   3,   2,   1,  29], device='cuda:0')\n",
      "expect =  [3, 4, 2, 1, 3, 4, 29]\n",
      "accuracy =  0.5\n",
      "batchacc =  0.6583333333333334\n",
      "13\n",
      "batchnum =  700\n",
      "tag =  tensor([  0,   3,   2,   1,   3,  20,  29,  30], device='cuda:0')\n",
      "expect =  [3, 2, 1, 3, 17, 29]\n",
      "accuracy =  0.8\n",
      "batchacc =  0.7066666666666667\n",
      "14\n",
      "batchnum =  750\n",
      "tag =  tensor([  0,  17,   2,  17,   2,  17,  29], device='cuda:0')\n",
      "expect =  [3, 2, 1, 2, 1, 29]\n",
      "accuracy =  0.6\n",
      "batchacc =  0.7055\n",
      "15\n",
      "batchnum =  800\n",
      "tag =  tensor([  0,   2,   1,   3,   4,  29], device='cuda:0')\n",
      "expect =  [2, 17, 2, 4, 29]\n",
      "accuracy =  0.75\n",
      "batchacc =  0.695\n",
      "16\n",
      "batchnum =  850\n",
      "tag =  tensor([  0,   1,   2,   2,   1,  29], device='cuda:0')\n",
      "expect =  [1, 18, 2, 1, 29]\n",
      "accuracy =  0.875\n",
      "batchacc =  0.695\n",
      "17\n",
      "batchnum =  900\n",
      "tag =  tensor([  0,   2,   1,   2,   1,  29], device='cuda:0')\n",
      "expect =  [2, 1, 2, 1, 29]\n",
      "accuracy =  1.0\n",
      "batchacc =  0.67\n",
      "18\n",
      "batchnum =  950\n",
      "tag =  tensor([  0,   2,   1,   2,   1,  29], device='cuda:0')\n",
      "expect =  [2, 17, 2, 1, 29]\n",
      "accuracy =  0.875\n",
      "batchacc =  0.6533333333333331\n",
      "19\n",
      "batchnum =  1000\n",
      "tag =  tensor([  0,   3,   2,   3,  29], device='cuda:0')\n",
      "expect =  [3, 2, 1, 29]\n",
      "accuracy =  0.8333333333333334\n",
      "batchacc =  0.6483333333333334\n",
      "20\n",
      "batchnum =  50\n",
      "tag =  tensor([  0,   2,   1,   2,   3,   3,   4,   2,   1,   3,   4,   3,\n",
      "          2,   1,   4,   3,   4,   3,  16,   3,  29,  30,  30,  30,\n",
      "         30,  30,  30,  30], device='cuda:0')\n",
      "expect =  [2, 1, 2, 2, 2, 4, 2, 1, 17, 1, 17, 2, 1, 17, 3, 17, 3, 1, 20, 29]\n",
      "accuracy =  0.5789473684210527\n",
      "batchacc =  0.7242564022235075\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7316427869644976"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf_gru_model.test_func(\n",
    "    test_data = test, \n",
    "    shared_model = sent_to_vextor_bigru_net, \n",
    "    comp_model = my_grucrf_model,\n",
    "    dataseq = dataseq,  \n",
    "    batch_size = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3-4.2.0]",
   "language": "python",
   "name": "conda-env-anaconda3-4.2.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
